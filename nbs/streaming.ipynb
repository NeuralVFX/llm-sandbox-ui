{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialog Name: unreal/unreal-llm-sandbox/nbs/streaming\n",
      "\n",
      "============================================================\n",
      "../llm_sandbox_ui/cells.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/cells.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['up_arrow_ic', 'down_arrow_ic', 'close_ic', 'swap_ic', 'view_ic', 'clean_ic', 'minimize_ic', 'play_ic', 'stop_ic',\n",
      "           'edit_ic', 'tools_ic', 'label_css', 'cell_button_format', 'interrupt_button', 'BaseCell', 'PromptCell',\n",
      "           'MarkdownCell', 'CodeCell']\n",
      "\n",
      "# %% ../nbs/cells.ipynb 3\n",
      "import json\n",
      "import uuid\n",
      "import re\n",
      "import mistune\n",
      "from fasthtml.common import * \n",
      "from .app_config import PROMPT_SPLIT#, AGENT_CODE_SPLIT\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 4\n",
      "up_arrow_ic = NotStr(\"&#11014\")\n",
      "down_arrow_ic = NotStr(\"&#11015\")\n",
      "close_ic = NotStr(\"&#x274C\")\n",
      "swap_ic = NotStr(\"&#128257\")\n",
      "view_ic =NotStr(\"&#x1F50D\")\n",
      "clean_ic =NotStr(\"&#x1F9F9\")\n",
      "minimize_ic = NotStr(\"&#x25BC\");\n",
      "play_ic = NotStr(\"&#9654\")\n",
      "stop_ic = NotStr(\"&#9209\")\n",
      "edit_ic = NotStr(\"&#x1F4DD\")\n",
      "tools_ic = NotStr(\"&#x1F6E0\")\n",
      "\n",
      "label_css = \"text-xs text-gray-400 px-2 py-1 bg-gray-800\"\n",
      "cell_button_format = 'btn btn-square btn-ghost btn-xs text-xl'\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 5\n",
      "def interrupt_button(cell_id):\n",
      "    \"\"\"Create an interrupt button that aborts the active stream for a cell.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique cell identifier.\n",
      "        \n",
      "    Returns:\n",
      "        Button component that POSTs to /interrupt/{cell_id}.\n",
      "    \"\"\"\n",
      "    return Button(stop_ic, \n",
      "        onClick=f\"\"\"fetch('/interrupt/{cell_id}', {{\n",
      "            method: 'POST', \n",
      "            headers: {{'Content-Type': 'application/json'}}, \n",
      "            body: JSON.stringify({{notebook: document.querySelector('.notebook-name')?.value || 'untitled'}})\n",
      "        }})\"\"\",\n",
      "        cls=cell_button_format)\n",
      "        \n",
      "\n",
      "# %% ../nbs/cells.ipynb 6\n",
      "class BaseCell:\n",
      "    \"\"\"Base class for all notebook cell types.\n",
      "    \n",
      "    Attributes:\n",
      "        cell_type (str): Type identifier ('markdown', 'code', 'llm').\n",
      "        source (str): Cell content/code.\n",
      "        outputs (list): Cell execution outputs (empty for markdown).\n",
      "        cell_id (str): Unique cell identifier.\n",
      "    \"\"\"\n",
      "    cell_type = None  \n",
      "    \n",
      "    def _make_markdown_init_script(self):\n",
      "        \"\"\" Scripts for managing Markdown display updating \"\"\"\n",
      "        return Script(f\"\"\"\n",
      "        (function() {{\n",
      "            const cell = document.querySelector('[data-cell-id=\"{self.cell_id}\"]');\n",
      "            if (!cell) return;  // Safety check\n",
      "            \n",
      "            const textarea = cell.querySelector('textarea.content-edit');\n",
      "            const renderdiv = cell.querySelector('.content-render');\n",
      "            const label = cell.querySelector('.toggle-label');\n",
      "            const checkbox = cell.querySelector('.toggle-edit');\n",
      "            \n",
      "            // Sync textarea to rendered\n",
      "            textarea.addEventListener('input', () => {{\n",
      "                renderdiv.innerHTML = marked.parse(textarea.value);\n",
      "                Prism.highlightAllUnder(renderdiv);\n",
      "            }});\n",
      "            \n",
      "            // Wire label to checkbox\n",
      "            label.addEventListener('click', () => {{ \n",
      "                checkbox.checked = !checkbox.checked; \n",
      "                checkbox.dispatchEvent(new Event('change')); \n",
      "            }});\n",
      "\n",
      "            textarea.style.height = 'auto';\n",
      "            textarea.style.height = Math.min(textarea.scrollHeight, 500) + 'px';\n",
      "            textarea.addEventListener('input', () => {{{{\n",
      "                textarea.style.height = 'auto';\n",
      "                textarea.style.height = Math.min(textarea.scrollHeight, 500) + 'px';\n",
      "            }}}});\n",
      "\n",
      "        }})();\n",
      "        \"\"\")\n",
      "\n",
      "    def __init__(self, source=\"\", outputs=\"\", cell_id=None):\n",
      "        \"\"\"Initialize a cell.\n",
      "        \n",
      "        Args:\n",
      "            source (str): Cell content. Defaults to \"\".\n",
      "            outputs (list, optional): Execution outputs. Defaults to [].\n",
      "            cell_id (str, optional): Unique ID. Generates UUID if None.\n",
      "        \"\"\"\n",
      "        self.source = source\n",
      "        self.cell_id = cell_id or uuid.uuid4().hex[:12]\n",
      "        self.outputs = outputs \n",
      "    \n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "        pass\n",
      "\n",
      "    def build_right_buttons(self):\n",
      "        \"\"\"Build common right buttons (move up/down/delete).\"\"\"\n",
      "        return Div(\n",
      "            Div(\n",
      "                Button(minimize_ic, \n",
      "                    onClick=f\"toggleMinimize('{self.cell_id}')\",\n",
      "                    cls=cell_button_format),\n",
      "                Button(up_arrow_ic,\n",
      "                    cls=cell_button_format,\n",
      "                    onClick=f\"moveUp('{self.cell_id}')\"),\n",
      "                Button(down_arrow_ic,\n",
      "                    cls=cell_button_format,\n",
      "                    onClick=f\"moveDown('{self.cell_id}')\"),\n",
      "                Button(close_ic,\n",
      "                    cls=cell_button_format,\n",
      "                    onClick=f\"deleteCell('{self.cell_id}')\"),\n",
      "                cls='btn-group'\n",
      "            ),\n",
      "            cls='flex justify-end'\n",
      "        )\n",
      "\n",
      "    def build_top_menu(self):\n",
      "        \"\"\"Build complete top menu bar with buttons and title.\"\"\"\n",
      "        display_name = self.cell_type.replace('_', ' ').title() + ' Cell'\n",
      "        return Div(\n",
      "            self.build_left_buttons(),\n",
      "            Div(display_name, style='font-size: 0.75rem; line-height: 1;'),\n",
      "            self.build_right_buttons(),\n",
      "            cls='flex justify-between items-center bg-gray-800 text-white py-0.5 px-2 rounded-t-lg border-b border-gray-700'\n",
      "        )\n",
      "\n",
      "    def build_markdown_source_area(self,source,round_b=True):\n",
      "        \"\"\"Build textarea and rendered markdown display for a cell.\n",
      "        \n",
      "        Args:\n",
      "            source: Markdown text content.\n",
      "            round_b: If True, apply rounded bottom corners.\n",
      "            \n",
      "        Returns:\n",
      "            List of [Textarea, Div] components.\n",
      "        \"\"\"\n",
      "        round_cls = 'rounded-b-lg' if round_b else ''\n",
      "\n",
      "        text_area = Textarea(source,\n",
      "                    placeholder='Enter Markdown Here...', \n",
      "                    rows=1,\n",
      "                    cls=f'w-full text-gray-100 p-4 bg-[#1e1e1e] {round_cls}'\\\n",
      "                    ' max-h-[500px] overflow-y-auto border-0 content-edit')\n",
      "\n",
      "        markdown_display = Div(NotStr(mistune.html(source)), \n",
      "                            cls='w-full markdown-body bg-gray-900 text-gray-100 p-4'\\\n",
      "                            f' {round_cls} max-h-[500px] overflow-y-auto content-render', \n",
      "                            style='list-style-position: inside; min-height: 3.5em;')\n",
      "\n",
      "\n",
      "        return [text_area, markdown_display]\n",
      "\n",
      "    def build_monaco_editor(self,cell_id,source_code='', min_height=20, max_height=500):\n",
      "        \"\"\"Build Monaco editor initialization script for a code cell.\n",
      "        \n",
      "        Args:\n",
      "            cell_id: Unique cell identifier for the editor container.\n",
      "            source_code: Initial code content.\n",
      "            min_height: Minimum editor height in pixels.\n",
      "            max_height: Maximum editor height in pixels.\n",
      "            \n",
      "        Returns:\n",
      "            Script component that initializes Monaco editor.\n",
      "        \"\"\"\n",
      "        monaco_editor_script = Script(f\"\"\"\n",
      "                                \n",
      "                require(['vs/editor/editor.main'], function() {{\n",
      "                    const sourceCode = {json.dumps(source_code)};\n",
      "                    const container = document.getElementById('monaco-{cell_id}');\n",
      "                    if (!container) return;\n",
      "                    \n",
      "                    const editor = monaco.editor.create(container, {{\n",
      "                        value: sourceCode,\n",
      "                        language: 'python',\n",
      "                        theme: 'vs-dark',\n",
      "                        automaticLayout: true,\n",
      "                        scrollBeyondLastLine: false,\n",
      "                        fontSize: 13, \n",
      "                        scrollBeyondLastColumn: 0,\n",
      "                        model: monaco.editor.createModel(sourceCode, 'python', \n",
      "                            monaco.Uri.parse(`inmemory://{cell_id}.py`))\n",
      "                    }});\n",
      "                    \n",
      "                    const lineCount = editor.getModel().getLineCount();\n",
      "                    const newHeight = Math.min(Math.max(lineCount * 19, {min_height}), {max_height});\n",
      "                    container.style.height = newHeight + 'px';\n",
      "                    editor.layout();\n",
      "\n",
      "                    editor.onDidChangeModelContent(() => {{\n",
      "                        const lineCount = editor.getModel().getLineCount();\n",
      "                        const newHeight = Math.min(Math.max(lineCount * 19,{min_height}), {max_height});\n",
      "                        container.style.height = newHeight + 'px';\n",
      "                        editor.layout(); \n",
      "                    }});\n",
      "                }});\n",
      "            \n",
      "                                \"\"\")\n",
      "        return monaco_editor_script\n",
      "\n",
      "    def build_code_output(self, tag='',min_height=100, max_height=300, outputs_json=[], round_b = False):\n",
      "        \"\"\"Build code output display area with hidden storage.\n",
      "        \n",
      "        Args:\n",
      "            tag: Suffix for CSS class names (e.g., '-code').\n",
      "            min_height: Minimum output area height in pixels.\n",
      "            max_height: Maximum output area height in pixels.\n",
      "            outputs_json: JSON string of Jupyter-style outputs.\n",
      "            round_b: If True, apply rounded bottom corners.\n",
      "            \n",
      "        Returns:\n",
      "            List of [Pre (display), Div (store)] components.\n",
      "        \"\"\"\n",
      "        if round_b:\n",
      "            round_button_cls = 'rounded-b-lg' \n",
      "        else:\n",
      "            round_button_cls = ''\n",
      "            \n",
      "        output_area_code = Pre(\n",
      "                          style='font-family: Consolas, Monaco, monospace;'\\\n",
      "                           ' font-size: 13px; background-color: #111827;',\n",
      "                          cls=f'w-full bg-gray-900 text-gray-100 p-4 {round_button_cls}' \\\n",
      "                          f' min-h-[{min_height}px] max-h-[{max_height}px] overflow-y-auto border-0 output-display{tag}')\n",
      "                          \n",
      "        output_store_code = Div(\n",
      "            outputs_json,  # â† Make sure this has content\n",
      "            cls='output-store'+tag, \n",
      "            style='display:none;'\n",
      "        )\n",
      "\n",
      "        return [output_area_code, output_store_code]\n",
      "\n",
      "    def build_llm_output(self, tag='',min_height=100, max_height=300, outputs_json=\"\"):\n",
      "        \"\"\"Build LLM markdown output display area with hidden storage.\n",
      "        \n",
      "        Args:\n",
      "            tag: Suffix for CSS class names (e.g., '-llm').\n",
      "            min_height: Minimum output area height in pixels.\n",
      "            max_height: Maximum output area height in pixels.\n",
      "            outputs_json: Raw markdown string to display.\n",
      "            \n",
      "        Returns:\n",
      "            List of [Div (store), Div (display)] components.\n",
      "        \"\"\"\n",
      "        output_store = Div(\n",
      "            outputs_json,  # â† Make sure this has content\n",
      "            cls='output-store'+tag, \n",
      "            style='display:none;'\n",
      "        )\n",
      "\n",
      "        output_area = Div(\n",
      "                        cls='w-full markdown-body bg-gray-900 text-gray-100 p-4 rounded-b-lg'\\\n",
      "                        f' min-h-[{min_height}px] max-h-[{max_height}px] overflow-y-auto border-0 output-display{tag}',\n",
      "                        style='background-color: #111827;',\n",
      "                        )\n",
      "\n",
      "        return [output_store, output_area]\n",
      "\n",
      "\n",
      "    def build_source_area(self):\n",
      "        \"\"\"Build editable source code/markdown area.\"\"\"\n",
      "        pass\n",
      "\n",
      "    def build_output_area(self):\n",
      "        \"\"\"Build output display area (if applicable).\"\"\"\n",
      "        pass\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\"Convert cell to Jupyter notebook dict format.\"\"\"\n",
      "        pass\n",
      "\n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\"Create cell from Jupyter notebook dict.\n",
      "        \n",
      "        Args:\n",
      "            cell_dict (dict): Jupyter cell structure.\n",
      "            \n",
      "        Returns:\n",
      "            BaseCell: Instantiated cell subclass.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 7\n",
      "class PromptCell(BaseCell):\n",
      "    \"\"\"Cell for LLM prompts with streaming markdown responses.\n",
      "    \n",
      "    Stores user prompt in source and LLM response in outputs.\n",
      "    Serializes to ipynb as markdown with PROMPT_SPLIT separator.\n",
      "    \"\"\"\n",
      "    cell_type = 'prompt'\n",
      "\n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\" Load From Ipynb Dict\"\"\"\n",
      "        \n",
      "        source_txt = ''.join(cell_dict['source'])\n",
      "        if PROMPT_SPLIT in source_txt:\n",
      "            source, outputs = ''.join(source_txt).split(PROMPT_SPLIT)\n",
      "\n",
      "        else:\n",
      "            source = source_txt\n",
      "            outputs = ''\n",
      "\n",
      "        return cls(source=source, \n",
      "                outputs=outputs,\n",
      "                cell_id=cell_dict['id'])\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\" Build Ipynb Dict\"\"\"\n",
      "\n",
      "        out_dict = {\n",
      "            'id':self.cell_id,\n",
      "            'cell_type': 'markdown',\n",
      "            'metadata': {'id': self.cell_id, 'prompt_cell': True}\n",
      "        }\n",
      "        \n",
      "        # Combine source + outputs with separator\n",
      "        if self.outputs:\n",
      "            source_text = self.source + PROMPT_SPLIT + self.outputs\n",
      "        else:\n",
      "            source_text = self.source\n",
      "        \n",
      "        out_dict['source'] = source_text.splitlines(keepends=True)\n",
      "        \n",
      "        return out_dict\n",
      "\n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "        \n",
      "        return Div(\n",
      "                Div(\n",
      "                    Button(play_ic,\n",
      "                            onClick=f\"executePromptCell('{self.cell_id}')\",\n",
      "                            cls=cell_button_format),\n",
      "                    interrupt_button(self.cell_id),\n",
      "                    Button(clean_ic,\n",
      "                            onClick=f\"clearOutput('{self.cell_id}')\",\n",
      "                            cls=cell_button_format),\n",
      "                    Label(edit_ic,\n",
      "                            cls=cell_button_format + ' toggle-label'),\n",
      "                    Label(\n",
      "                        Input(type='checkbox',\n",
      "                            cls=\"hidden tool-toggle\",\n",
      "                            checked=True),\n",
      "                            tools_ic,\n",
      "                            cls=cell_button_format + ' cursor-pointer'),\n",
      "                    Span(cls=\"loading loading-spinner loading-sm text-primary cell-spinner hidden\"),\n",
      "\n",
      "                ),\n",
      "                cls='flex justify-start'\n",
      "                )\n",
      "\n",
      "    def build_output_area(self):\n",
      "        \"\"\"Build output display area (if applicable).\"\"\"\n",
      "        \n",
      "        outputs_json = self.outputs if self.outputs else ''\n",
      "        output_area = self.build_llm_output( tag='',min_height=50, max_height=400, outputs_json=outputs_json)\n",
      "\n",
      "        llm_out = Div(\"LLM Output\", cls=label_css),\n",
      "\n",
      "        return [llm_out,*output_area ]\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "\n",
      "        toggle_input = Input(type='checkbox', cls=\"hidden toggle-edit\")\n",
      "\n",
      "        menu_bar = self.build_top_menu()\n",
      "        source_area = self.build_markdown_source_area(self.source,round_b=False)\n",
      "        output_area = self.build_output_area()\n",
      "        \n",
      "        watch_script = Script(f\"\"\"\n",
      "            setTimeout(() => {{\n",
      "                watchOutputStore('{self.cell_id}');\n",
      "            }}, 50);\n",
      "        \"\"\")\n",
      "\n",
      "        return Div(\n",
      "            watch_script,\n",
      "            toggle_input,\n",
      "            menu_bar,\n",
      "            *source_area,\n",
      "            *output_area,\n",
      "            self._make_markdown_init_script(),\n",
      "            cls='w-full shadow-xl p-2',\n",
      "            data_cell_type=self.cell_type,\n",
      "            data_cell_id=self.cell_id\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 8\n",
      "class MarkdownCell(BaseCell):\n",
      "    \"\"\"Static markdown documentation cell.\n",
      "    \n",
      "    Displays rendered markdown with toggle to edit source.\n",
      "    No execution or outputs - purely for notes and documentation.\n",
      "    \"\"\"\n",
      "    cell_type = 'markdown'\n",
      "\n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\" Load From Ipynb Dict\"\"\"\n",
      "                \n",
      "        source = ''.join(cell_dict['source'])\n",
      "\n",
      "        return cls(source=source,\n",
      "                cell_id=cell_dict['id'])\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\" Build Ipynb Dict\"\"\"\n",
      "        \n",
      "        out_dict = {\n",
      "            'id':self.cell_id,\n",
      "            'cell_type': 'markdown',\n",
      "            'metadata': {'id': self.cell_id},\n",
      "            'source': self.source.splitlines(keepends=True)\n",
      "        }\n",
      "        \n",
      "        return out_dict\n",
      "\n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "\n",
      "        toggle_button = Label(edit_ic, cls=cell_button_format + ' toggle-label')\n",
      "        return Div( toggle_button, cls='flex justify-start')\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "\n",
      "        toggle_input = Input(type='checkbox', cls=\"hidden toggle-edit\")\n",
      "\n",
      "        menu_bar = self.build_top_menu()\n",
      "        source_area = self.build_markdown_source_area(self.source,round_b=True)\n",
      "\n",
      "\n",
      "        return Div(\n",
      "            toggle_input,\n",
      "            menu_bar,\n",
      "            *source_area,\n",
      "            self._make_markdown_init_script(),\n",
      "            cls='w-full shadow-xl p-2',\n",
      "            data_cell_type=self.cell_type,  \n",
      "            data_cell_id=self.cell_id\n",
      "        )\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 9\n",
      "class CodeCell(BaseCell):\n",
      "    \"\"\"Executable Python code cell with Monaco editor.\n",
      "    \n",
      "    Executes code via kernel and displays Jupyter-style outputs\n",
      "    (streams, execute_result, display_data, errors).\n",
      "    \"\"\"\n",
      "    cell_type = 'code'\n",
      "    \n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\" Load From Ipynb Dict\"\"\"\n",
      "                \n",
      "        source = ''.join(cell_dict['source'])\n",
      "        outputs = cell_dict['outputs']\n",
      "\n",
      "        return cls(source=source,\n",
      "                outputs = outputs,\n",
      "                cell_id=cell_dict['id'])\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\" Build Ipynb Dict\"\"\"\n",
      "        \n",
      "        out_dict = {\n",
      "            'id':self.cell_id,\n",
      "            'cell_type': 'code',\n",
      "            'execution_count': 1,\n",
      "            'metadata': {'id': self.cell_id},\n",
      "            'source': self.source.splitlines(keepends=True),\n",
      "            'outputs': self.outputs\n",
      "        }\n",
      "        \n",
      "        return out_dict\n",
      "\n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "        \n",
      "        return Div(\n",
      "                Div(\n",
      "                    Button(play_ic,\n",
      "                            onClick=f\"executeCell('{self.cell_id}')\",\n",
      "                            cls=cell_button_format),\n",
      "                    interrupt_button(self.cell_id),\n",
      "                    Button(clean_ic,\n",
      "                            onClick=f\"clearOutput('{self.cell_id}')\",\n",
      "                            cls=cell_button_format)\n",
      "                ),\n",
      "                cls='flex justify-start'\n",
      "                )\n",
      "\n",
      "    def build_source_area(self):\n",
      "        \"\"\"Build editable source code/markdown area.\"\"\"\n",
      "        \n",
      "        monaco_editor_script = self.build_monaco_editor(self.cell_id,self.source,min_height=20, max_height=500)\n",
      "\n",
      "        editor_div = Div(id=f'monaco-{self.cell_id}', \n",
      "                        style='height: 20px; width: 100%; overflow: hidden',\n",
      "                        cls='monaco-editor')\n",
      "        \n",
      "        return [editor_div, monaco_editor_script]\n",
      "\n",
      "    def build_output_area(self):\n",
      "        \"\"\"Build output display area (if applicable).\"\"\"\n",
      "        \n",
      "        outputs_json = json.dumps(self.outputs) if self.outputs else '[]'\n",
      "        output_area = self.build_code_output(min_height=50, max_height=400, outputs_json=outputs_json , round_b=True)\n",
      "\n",
      "        code_out = Div(\"Code Output\", cls=label_css),\n",
      "\n",
      "        return [code_out,*output_area]\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "\n",
      "        menu_bar = self.build_top_menu()\n",
      "        source_area = self.build_source_area()\n",
      "        output_area = self.build_output_area()\n",
      "\n",
      "        watch_script = Script(f\"\"\"\n",
      "                setTimeout(() => {{\n",
      "                    window.cellOutputs['{self.cell_id}'] = window.cellOutputs['{self.cell_id}'] || [];\n",
      "                    watchOutputStore('{self.cell_id}');\n",
      "                }}, 50);\n",
      "                \"\"\")\n",
      "                  \n",
      "        return Div(\n",
      "            watch_script,\n",
      "            menu_bar,\n",
      "            *source_area,\n",
      "            *output_area,\n",
      "            cls='w-full shadow-xl p-2',\n",
      "            data_cell_type=self.cell_type,\n",
      "            data_cell_id=self.cell_id\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "../llm_sandbox_ui/streaming.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/streaming.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['active_streams', 'SSEStream']\n",
      "\n",
      "# %% ../nbs/streaming.ipynb 3\n",
      "import queue\n",
      "import asyncio\n",
      "import json\n",
      "from starlette.responses import StreamingResponse\n",
      "\n",
      "\n",
      "active_streams = {}\n",
      "\n",
      "\n",
      "class SSEStream:\n",
      "    \"\"\"Unified SSE streaming with queue-based message passing.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique identifier for abort handling.\n",
      "    \"\"\"\n",
      "    def __init__(self, stream_key):\n",
      "        self.stream_key = stream_key  \n",
      "        self.q = queue.Queue()\n",
      "        active_streams[stream_key] = {'abort': False}\n",
      "    \n",
      "    def text(self, content: str):\n",
      "        \"\"\"Send text chunk to stream.\n",
      "        \n",
      "        Args:\n",
      "            content: String to send.\n",
      "        \"\"\"\n",
      "        self.q.put({\"type\": \"text\", \"data\": content})\n",
      "\n",
      "    def tag(self, content: str):\n",
      "        \"\"\"Send control tag to switch stream target.\n",
      "        \n",
      "        Args:\n",
      "            content: Tag name.\n",
      "        \"\"\"\n",
      "        self.q.put({\"type\": \"tag\", \"data\": content})\n",
      "    \n",
      "    def output(self, data):\n",
      "        \"\"\"Send Jupyter-style output dict.\n",
      "        \n",
      "        Args:\n",
      "            data: Output dict/list (may contain ANSI).\n",
      "        \"\"\"\n",
      "        self.q.put({\"type\": \"output\", \"data\": data})\n",
      "        \n",
      "    def done(self):\n",
      "        \"\"\"Signal stream complete and cleanup.\"\"\"\n",
      "        self.q.put(None)\n",
      "        self.cleanup()\n",
      "\n",
      "    def aborted(self):\n",
      "        \"\"\"Check if user requested abort.\n",
      "        \n",
      "        Returns:\n",
      "            True if aborted, False otherwise.\n",
      "        \"\"\"\n",
      "        return active_streams.get(self.stream_key, {}).get('abort', True)\n",
      "\n",
      "    def response(self):\n",
      "        \"\"\"Create async SSE response.\n",
      "        \n",
      "        Returns:\n",
      "            StreamingResponse for FastHTML route.\n",
      "        \"\"\"\n",
      "        async def generator():\n",
      "            while True:\n",
      "                item = await asyncio.to_thread(self.q.get)\n",
      "                if item is None: break\n",
      "                yield f\"data: {json.dumps(item)}\\n\\n\"\n",
      "            self.cleanup()\n",
      "        return StreamingResponse(generator(), media_type='text/event-stream')\n",
      "\n",
      "    def cleanup(self):\n",
      "        \"\"\"Remove cell_id from active_streams.\"\"\"\n",
      "        active_streams.pop(self.stream_key, None)\n",
      "        \n",
      "\n",
      "\n",
      "============================================================\n",
      "../llm_sandbox_ui/llm.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/llm.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['AgenticToolLoop']\n",
      "\n",
      "# %% ../nbs/llm.ipynb 3\n",
      "import json\n",
      "import requests\n",
      "import litellm\n",
      "from litellm import completion\n",
      "\n",
      "from .app_config import MODEL, KERNEL_URL, NOTEBOOK_SYS_PROMPT, UE_TOOL_SYS_PROMPT \n",
      "from .llm_tools import TOOLS, TOOL_SCHEMAS\n",
      "\n",
      "litellm.drop_params = True\n",
      "\n",
      "\n",
      "# %% ../nbs/llm.ipynb 4\n",
      "class AgenticToolLoop():\n",
      "    \"\"\"Agentic loop that calls LLM with tools until completion or max iterations.\n",
      "    \n",
      "    Manages message history, tool execution, and streaming responses for\n",
      "    multi-turn conversations with tool calling capabilities.\n",
      "    \n",
      "    Attributes:\n",
      "        model: LiteLLM model identifier string.\n",
      "        sys_prompt: System prompt for the conversation.\n",
      "        local: If True, use local tools; else call Unreal Engine server.\n",
      "        max_iters: Maximum tool call iterations before stopping.\n",
      "        tools: List of tool schemas for the LLM.\n",
      "        messages: Conversation history.\n",
      "        llm_turn_result: Result dict from the last LLM turn.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self,model, sys_prompt, local=True, max_iters = 30):\n",
      "        \"\"\"Initialize the agentic tool loop.\n",
      "        \n",
      "        Args:\n",
      "            model: LiteLLM model identifier string.\n",
      "            sys_prompt: System prompt for the conversation.\n",
      "            local: If True, use local tools; else call Unreal Engine server.\n",
      "            max_iters: Maximum tool call iterations before stopping.\n",
      "        \"\"\"\n",
      "        self.model = model\n",
      "        self.sys_prompt = sys_prompt\n",
      "        self.local = local\n",
      "        self.max_iters = max_iters\n",
      "\n",
      "        self.tools = self.get_tools(local=local)\n",
      "        self.messages = []\n",
      "\n",
      "        self.llm_turn_result = None\n",
      "\n",
      "    def get_tools(self, local = True):\n",
      "        \"\"\"Fetch available tool schemas.\n",
      "        \n",
      "        Args:\n",
      "            local: If True, return local TOOL_SCHEMAS; else fetch from Unreal.\n",
      "            \n",
      "        Returns:\n",
      "            List of tool schema dicts.\n",
      "        \"\"\"\n",
      "        # Get Tools from Globals\n",
      "        if local:\n",
      "            global TOOL_SCHEMAS\n",
      "            return TOOL_SCHEMAS\n",
      "        # Or Get Tools From Unreal\n",
      "        else:\n",
      "            response = requests.get(f'{KERNEL_URL}/tools')\n",
      "            return response.json()\n",
      "\n",
      "    def run_single_tool(self, raw_tool_args, tool_name, local=True):\n",
      "        \"\"\"Execute a single tool call.\n",
      "        \n",
      "        Args:\n",
      "            raw_tool_args: JSON string of tool arguments.\n",
      "            tool_name: Name of the tool to execute.\n",
      "            local: If True, run locally; else POST to Unreal server.\n",
      "            \n",
      "        Returns:\n",
      "            String result from tool execution or error message.\n",
      "        \"\"\"\n",
      "        args = json.loads(raw_tool_args)\n",
      "\n",
      "        if local:\n",
      "            # Run Local Tool\n",
      "            try:\n",
      "                result = TOOLS[tool_name](**args)\n",
      "                return str(result)\n",
      "            except Exception as e:\n",
      "                return f\"Local tool error: {str(e)}\"\n",
      "        else:\n",
      "            # Send Request to Unreal Server\n",
      "            response = requests.post(\n",
      "                f'{KERNEL_URL}/execute_tool',\n",
      "                json={'function': tool_name, 'arguments': args},\n",
      "                timeout = 10)\n",
      "            \n",
      "            data = response.json()\n",
      "            # Check if there's an error\n",
      "            if 'error' in data:\n",
      "                return f\"Error: {data['error']}\"\n",
      "            \n",
      "            # Check if result exists\n",
      "            if 'result' not in data:\n",
      "                return f\"Unexpected response: {data}\"\n",
      "            return data['result']\n",
      "\n",
      "    def run_tool_calls(self,tool_calls):\n",
      "        \"\"\"Execute a batch of tool calls and update message history.\n",
      "        \n",
      "        Args:\n",
      "            tool_calls: List of dicts with 'tool_id', 'func_name', 'args' keys.\n",
      "            \n",
      "        Yields:\n",
      "            Status strings for each tool execution.\n",
      "        \"\"\"\n",
      "        for tool_call in tool_calls:\n",
      "\n",
      "            # Get Tool Info\n",
      "            tool_id = tool_call['tool_id']\n",
      "            tool_name = tool_call['func_name']\n",
      "            raw_tool_args = tool_call['args']\n",
      "\n",
      "            # Execute Tool\n",
      "            yield f'\\n\\nðŸ”§ Executing Tool: {tool_name}({tool_call['args']})\\n\\n'\n",
      "\n",
      "            # Leaving the possibility of inter-loop switching, local versus Unreal\n",
      "            tool_result = self.run_single_tool(raw_tool_args,\n",
      "                                               tool_name, \n",
      "                                               local=self.local) \n",
      "            \n",
      "            # Append Tool History\n",
      "            self.messages.append({'role': 'tool',\n",
      "                                 'tool_call_id': tool_id,\n",
      "                                 'content': json.dumps(tool_result)})\n",
      "\n",
      "    def llm_turn(self):\n",
      "        \"\"\"Run one LLM completion turn with streaming.\n",
      "        \n",
      "        Accumulates text and tool calls from the stream, updates message\n",
      "        history, and sets llm_turn_result with finish_reason and tool_calls.\n",
      "        \n",
      "        Yields:\n",
      "            Text content chunks from the LLM response.\n",
      "        \"\"\"\n",
      "        llm_stream = completion(\n",
      "                                model=self.model,\n",
      "                                messages = self.messages,\n",
      "                                tools = self.tools,\n",
      "                                stream=True,\n",
      "                                )\n",
      "\n",
      "        text_output = \"\"\n",
      "        tool_name = None\n",
      "        tool_call = \"\"\n",
      "        tool_id = None\n",
      "        tool_index = 0\n",
      "        tool_calls = []\n",
      "\n",
      "        for chunk in llm_stream:\n",
      "            finish_reason = chunk.choices[0].finish_reason\n",
      "            delta = chunk.choices[0].delta\n",
      "\n",
      "            # Tool Arg Accumulation\n",
      "            if delta.tool_calls:\n",
      "                if delta.tool_calls[0].function.name:\n",
      "\n",
      "                    # If Multiple Tool Calls, Stack them Up\n",
      "                    if tool_index != delta.tool_calls[0].index:\n",
      "                        tool_calls.append({'func_name':tool_name,\n",
      "                                            'args':tool_call,\n",
      "                                            'tool_id':tool_id})\n",
      "\n",
      "                        tool_call = \"\"\n",
      "                        tool_index = delta.tool_calls[0].index\n",
      "\n",
      "                    tool_name = delta.tool_calls[0].function.name\n",
      "                    tool_id = delta.tool_calls[0].id\n",
      "\n",
      "                json_piece = delta.tool_calls[0].function.arguments\n",
      "                tool_call += json_piece\n",
      "\n",
      "            # Text Message Accumulation\n",
      "            elif delta.content:\n",
      "                yield delta.content\n",
      "                text_output += delta.content\n",
      "\n",
      "            # Finish \n",
      "            elif finish_reason:\n",
      "                if text_output:\n",
      "                    self.messages.append({'role':'assistant',\n",
      "                                        'content':text_output})  \n",
      "\n",
      "                if finish_reason == 'tool_calls':\n",
      "\n",
      "                    tool_calls.append({'func_name':tool_name,\n",
      "                                        'args':tool_call,\n",
      "                                        'tool_id':tool_id})\n",
      "\n",
      "                    # Build Message History from Tool Call List\n",
      "                    tool_message_list = []\n",
      "                    for tool_call in tool_calls:\n",
      "                        tool_message_list.append({'id':tool_call['tool_id'],\n",
      "                                                'type':'function',\n",
      "                                                'function':{'name':tool_call['func_name'],\n",
      "                                                            'arguments':tool_call['args']}})\n",
      "\n",
      "                    self.messages.append({'role':'assistant',\n",
      "                                        'tool_calls':tool_message_list})\n",
      "\n",
      "                self.llm_turn_result = {'finish_reason':finish_reason,\n",
      "                        'tool_calls':tool_calls}\n",
      "\n",
      "    def call_llm(self, notebook_history, query):\n",
      "        \"\"\"Run the full agentic loop until completion.\n",
      "        \n",
      "        Args:\n",
      "            notebook_history: List of prior conversation messages.\n",
      "            query: User's query string.\n",
      "            \n",
      "        Yields:\n",
      "            Text chunks and tool execution status messages.\n",
      "        \"\"\"\n",
      "        # Build History Including Notebook\n",
      "        self.messages=[\n",
      "                {\"role\": \"system\", \"content\":self.sys_prompt},\n",
      "                *notebook_history,\n",
      "                {\"role\": \"user\", 'content':query}\n",
      "                ]\n",
      "\n",
      "        # Loop until Finish Reason says Stop\n",
      "        finish_reason = 'go'\n",
      "        iters = 0\n",
      "        while finish_reason != 'stop':\n",
      "            if iters > self.max_iters:\n",
      "                yield '\\nReached Max Tool Calls\\n'\n",
      "                break\n",
      "            for chunk in self.llm_turn():\n",
      "                yield chunk\n",
      "\n",
      "            result = self.llm_turn_result\n",
      "            finish_reason = result['finish_reason']\n",
      "\n",
      "            # Execute Tool Calls\n",
      "            if finish_reason == 'tool_calls':\n",
      "                for chunk in self.run_tool_calls(result['tool_calls']):\n",
      "                    yield chunk\n",
      "            iters += 1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "../llm_sandbox_ui/__init__.py\n",
      "============================================================\n",
      "__version__ = \"0.0.3\"\n",
      "\n",
      "\n",
      "============================================================\n",
      "../llm_sandbox_ui/_modidx.py\n",
      "============================================================\n",
      "# Autogenerated by nbdev\n",
      "\n",
      "d = { 'settings': { 'branch': 'main',\n",
      "                'doc_baseurl': '/unreal-llm-sandbox',\n",
      "                'doc_host': 'https://NeuralVFX.github.io',\n",
      "                'git_url': 'https://github.com/NeuralVFX/unreal-llm-sandbox',\n",
      "                'lib_path': 'unreal_llm_sandbox'},\n",
      "  'syms': { 'unreal_llm_sandbox.app_config': {},\n",
      "            'unreal_llm_sandbox.cells': { 'unreal_llm_sandbox.cells.BaseCell': ('cells.html#basecell', 'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.__init__': ( 'cells.html#basecell.__init__',\n",
      "                                                                                          'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell._make_markdown_init_script': ( 'cells.html#basecell._make_markdown_init_script',\n",
      "                                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_code_output': ( 'cells.html#basecell.build_code_output',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_left_buttons': ( 'cells.html#basecell.build_left_buttons',\n",
      "                                                                                                    'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_llm_output': ( 'cells.html#basecell.build_llm_output',\n",
      "                                                                                                  'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_markdown_source_area': ( 'cells.html#basecell.build_markdown_source_area',\n",
      "                                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_monaco_editor': ( 'cells.html#basecell.build_monaco_editor',\n",
      "                                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_output_area': ( 'cells.html#basecell.build_output_area',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_right_buttons': ( 'cells.html#basecell.build_right_buttons',\n",
      "                                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_source_area': ( 'cells.html#basecell.build_source_area',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_top_menu': ( 'cells.html#basecell.build_top_menu',\n",
      "                                                                                                'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.from_ipynb': ( 'cells.html#basecell.from_ipynb',\n",
      "                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.render': ( 'cells.html#basecell.render',\n",
      "                                                                                        'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.to_ipynb': ( 'cells.html#basecell.to_ipynb',\n",
      "                                                                                          'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell': ('cells.html#codecell', 'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.build_left_buttons': ( 'cells.html#codecell.build_left_buttons',\n",
      "                                                                                                    'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.build_output_area': ( 'cells.html#codecell.build_output_area',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.build_source_area': ( 'cells.html#codecell.build_source_area',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.from_ipynb': ( 'cells.html#codecell.from_ipynb',\n",
      "                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.render': ( 'cells.html#codecell.render',\n",
      "                                                                                        'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.to_ipynb': ( 'cells.html#codecell.to_ipynb',\n",
      "                                                                                          'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell': ( 'cells.html#markdowncell',\n",
      "                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell.build_left_buttons': ( 'cells.html#markdowncell.build_left_buttons',\n",
      "                                                                                                        'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell.from_ipynb': ( 'cells.html#markdowncell.from_ipynb',\n",
      "                                                                                                'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell.render': ( 'cells.html#markdowncell.render',\n",
      "                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell.to_ipynb': ( 'cells.html#markdowncell.to_ipynb',\n",
      "                                                                                              'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell': ('cells.html#promptcell', 'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.build_left_buttons': ( 'cells.html#promptcell.build_left_buttons',\n",
      "                                                                                                      'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.build_output_area': ( 'cells.html#promptcell.build_output_area',\n",
      "                                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.from_ipynb': ( 'cells.html#promptcell.from_ipynb',\n",
      "                                                                                              'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.render': ( 'cells.html#promptcell.render',\n",
      "                                                                                          'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.to_ipynb': ( 'cells.html#promptcell.to_ipynb',\n",
      "                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.interrupt_button': ( 'cells.html#interrupt_button',\n",
      "                                                                                         'unreal_llm_sandbox/cells.py')},\n",
      "            'unreal_llm_sandbox.llm': { 'unreal_llm_sandbox.llm.AgenticToolLoop': ('llm.html#agentictoolloop', 'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.AgenticToolLoop.__init__': ( 'llm.html#agentictoolloop.__init__',\n",
      "                                                                                             'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.AgenticToolLoop.call_llm': ( 'llm.html#agentictoolloop.call_llm',\n",
      "                                                                                             'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.AgenticToolLoop.get_tools': ( 'llm.html#agentictoolloop.get_tools',\n",
      "                                                                                              'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.AgenticToolLoop.llm_turn': ( 'llm.html#agentictoolloop.llm_turn',\n",
      "                                                                                             'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.AgenticToolLoop.run_single_tool': ( 'llm.html#agentictoolloop.run_single_tool',\n",
      "                                                                                                    'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.AgenticToolLoop.run_tool_calls': ( 'llm.html#agentictoolloop.run_tool_calls',\n",
      "                                                                                                   'unreal_llm_sandbox/llm.py')},\n",
      "            'unreal_llm_sandbox.llm_tools': { 'unreal_llm_sandbox.llm_tools.get_tools': ( 'llm_tools.html#get_tools',\n",
      "                                                                                          'unreal_llm_sandbox/llm_tools.py'),\n",
      "                                              'unreal_llm_sandbox.llm_tools.read_url': ( 'llm_tools.html#read_url',\n",
      "                                                                                         'unreal_llm_sandbox/llm_tools.py'),\n",
      "                                              'unreal_llm_sandbox.llm_tools.register_tool': ( 'llm_tools.html#register_tool',\n",
      "                                                                                              'unreal_llm_sandbox/llm_tools.py'),\n",
      "                                              'unreal_llm_sandbox.llm_tools.search_web': ( 'llm_tools.html#search_web',\n",
      "                                                                                           'unreal_llm_sandbox/llm_tools.py')},\n",
      "            'unreal_llm_sandbox.main': { 'unreal_llm_sandbox.main.Toolbar': ('main.html#toolbar', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.add_cell': ('main.html#add_cell', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.exe_code': ('main.html#exe_code', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.exe_prompt': ('main.html#exe_prompt', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.get_static': ('main.html#get_static', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.interrupt': ('main.html#interrupt', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.load_notebook': ('main.html#load_notebook', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.save_notebook': ('main.html#save_notebook', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.start_server': ('main.html#start_server', 'unreal_llm_sandbox/main.py')},\n",
      "            'unreal_llm_sandbox.notebook_io': { 'unreal_llm_sandbox.notebook_io.format_for_chat': ( 'notebook_io.html#format_for_chat',\n",
      "                                                                                                    'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.is_ask_cell': ( 'notebook_io.html#is_ask_cell',\n",
      "                                                                                                'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prep_code_cell': ( 'notebook_io.html#prep_code_cell',\n",
      "                                                                                                   'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prep_code_cell_output': ( 'notebook_io.html#prep_code_cell_output',\n",
      "                                                                                                          'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prep_markdown_cell': ( 'notebook_io.html#prep_markdown_cell',\n",
      "                                                                                                       'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prep_prompt_cell': ( 'notebook_io.html#prep_prompt_cell',\n",
      "                                                                                                     'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prepare_chat_history': ( 'notebook_io.html#prepare_chat_history',\n",
      "                                                                                                         'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.reconstruct_cells_from_history': ( 'notebook_io.html#reconstruct_cells_from_history',\n",
      "                                                                                                                   'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.reconstruct_ipynb_cell': ( 'notebook_io.html#reconstruct_ipynb_cell',\n",
      "                                                                                                           'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.seperate_markdown': ( 'notebook_io.html#seperate_markdown',\n",
      "                                                                                                      'unreal_llm_sandbox/notebook_io.py')},\n",
      "            'unreal_llm_sandbox.streaming': { 'unreal_llm_sandbox.streaming.SSEStream': ( 'streaming.html#ssestream',\n",
      "                                                                                          'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.__init__': ( 'streaming.html#ssestream.__init__',\n",
      "                                                                                                   'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.aborted': ( 'streaming.html#ssestream.aborted',\n",
      "                                                                                                  'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.cleanup': ( 'streaming.html#ssestream.cleanup',\n",
      "                                                                                                  'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.done': ( 'streaming.html#ssestream.done',\n",
      "                                                                                               'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.output': ( 'streaming.html#ssestream.output',\n",
      "                                                                                                 'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.response': ( 'streaming.html#ssestream.response',\n",
      "                                                                                                   'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.tag': ( 'streaming.html#ssestream.tag',\n",
      "                                                                                              'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.text': ( 'streaming.html#ssestream.text',\n",
      "                                                                                               'unreal_llm_sandbox/streaming.py')}}}\n",
      "\n",
      "\n",
      "============================================================\n",
      "../llm_sandbox_ui/main.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/main.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['daisy_hdrs', 'app', 'rt', 'get_static', 'interrupt', 'exe_prompt', 'exe_code', 'Toolbar', 'add_cell', 'load_notebook',\n",
      "           'save_notebook', 'start_server']\n",
      "\n",
      "# %% ../nbs/main.ipynb 3\n",
      "import json\n",
      "import asyncio\n",
      "import requests\n",
      "import lisette\n",
      "import time\n",
      "\n",
      "from fasthtml.common import *\n",
      "from fasthtml.jupyter import JupyUvi\n",
      "from starlette.staticfiles import StaticFiles\n",
      "\n",
      "from .app_config import MODEL, KERNEL_URL, NOTEBOOK_SYS_PROMPT, UE_TOOL_SYS_PROMPT\n",
      "from .cells import MarkdownCell, CodeCell, PromptCell #, AgentCell\n",
      "from .streaming import SSEStream, active_streams\n",
      "#from unreal_llm_sandbox.kernel import execute_unreal_code, convert_to_accumulated\n",
      "from .notebook_io import reconstruct_cells_from_history, prepare_chat_history, reconstruct_ipynb_cell\n",
      "from .llm import AgenticToolLoop\n",
      "#from unreal_llm_sandbox.agent import AgentTools, SYS_PROMPT\n",
      "\n",
      "from fasthtml.common import *\n",
      "import importlib.resources\n",
      "import unreal_llm_sandbox\n",
      "\n",
      "\n",
      "def get_static(fname, icon=False):\n",
      "    \"\"\"Read static file content from package resources.\n",
      "    \n",
      "    Args:\n",
      "        fname: Filename to read from unreal_llm_sandbox/static/.\n",
      "        \n",
      "    Returns:\n",
      "        String content of the file.\n",
      "    \"\"\"\n",
      "    ref = importlib.resources.files(unreal_llm_sandbox) / 'static' / fname\n",
      "    if icon:\n",
      "        icon_bytes = (importlib.resources.files(unreal_llm_sandbox) / 'static' / 'Icon128.png').read_bytes()\n",
      "        return base64.b64encode(icon_bytes).decode()\n",
      "    else:\n",
      "        return ref.read_text(encoding='utf-8')\n",
      "\n",
      "\n",
      "daisy_hdrs =[\n",
      "Link(rel=\"icon\", href=f\"data:image/png;base64,{get_static('Icon32.png',icon=True)}\"),\n",
      "Link(href='https://cdn.jsdelivr.net/npm/daisyui@5', rel='stylesheet', type='text/css'),\n",
      "Script(src='https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4'),\n",
      "Link(rel=\"stylesheet\", href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css\"),\n",
      "Link(rel=\"stylesheet\", href=\"https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.5.1/github-markdown.min.css\"),\n",
      "Script (src ='https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js'),\n",
      "Script (src ='https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js'),\n",
      "Script(src='https://cdn.jsdelivr.net/npm/marked/marked.min.js'),\n",
      "Script(get_static('cells.js')),\n",
      "Script(src=\"https://cdn.jsdelivr.net/npm/ansi_up@5/ansi_up.min.js\"),\n",
      "Script(src=\"https://cdn.jsdelivr.net/npm/monaco-editor@latest/min/vs/loader.js\"),\n",
      "Script(\"\"\"\n",
      "require.config({ paths: { 'vs': 'https://cdn.jsdelivr.net/npm/monaco-editor@latest/min/vs' }});\n",
      "\"\"\"),\n",
      "Script(src=\"https://unpkg.com/htmx.org/dist/ext/sse.js\")]\n",
      "\n",
      "\n",
      "app = FastHTML(hdrs=daisy_hdrs)\n",
      "\n",
      "\n",
      "rt = app.route\n",
      "\n",
      "\n",
      "# %% ../nbs/main.ipynb 4\n",
      "@rt('/interrupt/{cell_id}', methods=['POST'])\n",
      "async def interrupt(cell_id: str, request):\n",
      "    \"\"\"Signal abort for an active stream.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique cell identifier.\n",
      "    \n",
      "    Returns:\n",
      "        \"OK\" acknowledgment string.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        data = await request.json()\n",
      "        notebook = data.get('notebook', 'untitled')\n",
      "    except:\n",
      "        notebook = 'untitled'\n",
      "    stream_key = f\"{notebook}:{cell_id}\"\n",
      "    if stream_key in active_streams:\n",
      "        active_streams[stream_key]['abort'] = True\n",
      "    return \"OK\"\n",
      "    \n",
      "\n",
      "# %% ../nbs/main.ipynb 5\n",
      "@rt('/execute_prompt/{cell_id}')\n",
      "async def exe_prompt(cell_id: str, request): \n",
      "    \"\"\"Execute LLM prompt with notebook context via SSE.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique cell identifier.\n",
      "        request: FastHTML request with JSON body containing:\n",
      "            - prompt: User's prompt text.\n",
      "            - context: List of cell dicts for history.\n",
      "    \n",
      "    Returns:\n",
      "        SSE StreamingResponse yielding LLM chunks.\n",
      "    \"\"\"\n",
      "\n",
      "    data = await request.json() \n",
      "\n",
      "    notebook = data.get('notebook', 'untitled')\n",
      "    \n",
      "    stream_key = f\"{notebook}:{cell_id}\" \n",
      "\n",
      "    prompt = data['prompt']\n",
      "    cell_dict_list = data.get('context', [])\n",
      "    use_tools = data.get('use_tools', True) \n",
      "\n",
      "    cells = reconstruct_cells_from_history(cell_dict_list)\n",
      "    ipynb_list = [cell.to_ipynb() for cell in cells]\n",
      "    chat_history = prepare_chat_history(ipynb_list)\n",
      "    \n",
      "    stream = SSEStream(stream_key)\n",
      "    \n",
      "    def run():\n",
      "        sys_prompt = NOTEBOOK_SYS_PROMPT\n",
      "        if use_tools:\n",
      "           sys_prompt = UE_TOOL_SYS_PROMPT\n",
      "\n",
      "        agent = AgenticToolLoop(model=MODEL,\n",
      "                                sys_prompt=sys_prompt, \n",
      "                                local=not use_tools)\n",
      "\n",
      "        for msg in agent.call_llm(chat_history, prompt):\n",
      "            if stream.aborted(): break\n",
      "            stream.text(msg)\n",
      "        stream.done()\n",
      "\n",
      "    \n",
      "    asyncio.create_task(asyncio.to_thread(run))\n",
      "    return stream.response()\n",
      "\n",
      "\n",
      "# %% ../nbs/main.ipynb 6\n",
      "@rt('/execute_code/{cell_id}')\n",
      "async def exe_code(cell_id: str, request):\n",
      "    \"\"\"Execute Python code in Unreal Engine via SSE.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique cell identifier.\n",
      "        request: FastHTML request with JSON body containing:\n",
      "            - code: Python code string to execute.\n",
      "    \n",
      "    Returns:\n",
      "        SSE StreamingResponse yielding kernel output messages.\n",
      "    \"\"\"\n",
      "\n",
      "    data = await request.json()\n",
      "    notebook = data.get('notebook', 'untitled')\n",
      "    stream_key = f\"{notebook}:{cell_id}\" \n",
      "\n",
      "    stream = SSEStream(stream_key)\n",
      "    \n",
      "    def run():\n",
      "        response = requests.post(f'{KERNEL_URL}/execute', json={'code': data['code']}, stream=True, timeout=(5, 60))\n",
      "        for line in response.iter_lines():\n",
      "            if stream.aborted(): break\n",
      "            if line.startswith(b'data: '):\n",
      "                stream.output(json.loads(line[6:]))  # â† output() not raw()\n",
      "        stream.done()\n",
      "    \n",
      "    asyncio.create_task(asyncio.to_thread(run))\n",
      "    return stream.response()\n",
      "\n",
      "\n",
      "# %% ../nbs/main.ipynb 8\n",
      "def Toolbar(title):\n",
      "    \"\"\"Build the notebook toolbar with cell creation buttons.\n",
      "    \n",
      "    Args:\n",
      "        title: Notebook name to display in the editable input.\n",
      "        \n",
      "    Returns:\n",
      "        FastHTML Div containing toolbar elements.\n",
      "    \"\"\"\n",
      "    return Div(\n",
      "\n",
      "        Div(\n",
      "            Input(value=title, cls=\"text-xl font-bold text-white notebook-name bg-transparent border-none outline-none focus:outline-none flex-1\"),\n",
      "            Script(\"\"\"\n",
      "                document.querySelector('.notebook-name').addEventListener('blur', (e) => {\n",
      "                    const name = e.target.value || 'untitled';\n",
      "                    history.replaceState(null, '', `/notebook/${name}.ipynb`);\n",
      "                });\n",
      "            \"\"\"),\n",
      "            cls=\"flex flex-1 items-center\"\n",
      "        ),\n",
      "        Div(\n",
      "            Button(\"âž• Markdown\", \n",
      "                   hx_post=\"/add_cell/markdown\",\n",
      "                   hx_target=\"#notebook-container\",\n",
      "                   hx_swap=\"beforeend\",\n",
      "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"), \n",
      "            Button(\"âž• Code\", \n",
      "                   hx_post=\"/add_cell/code\",\n",
      "                   hx_target=\"#notebook-container\",\n",
      "                   hx_swap=\"beforeend\",\n",
      "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"),  \n",
      "            Button(\"âž• Prompt\", \n",
      "                   hx_post=\"/add_cell/prompt\",\n",
      "                   hx_target=\"#notebook-container\",\n",
      "                   hx_swap=\"beforeend\",\n",
      "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"),  \n",
      "            #Button(\"âž• Agent\", \n",
      "            #       hx_post=\"/add_cell/agent\",\n",
      "            #       hx_target=\"#notebook-container\",\n",
      "            #       hx_swap=\"beforeend\",\n",
      "            #       cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"), \n",
      "            cls=\"flex gap-2\"\n",
      "        ),\n",
      "        cls=\"flex justify-between p-4 bg-[#0d0d0d]\"  # â† Changed from #0d0d0d to pure black\n",
      "    )\n",
      "\n",
      "@rt('/add_cell/{cell_type}')\n",
      "def add_cell(cell_type: str):\n",
      "    \"\"\"Create and return a new cell of the specified type.\n",
      "    \n",
      "    Args:\n",
      "        cell_type: One of 'markdown', 'code', 'prompt', or 'agent'.\n",
      "        \n",
      "    Returns:\n",
      "        Rendered FastHTML cell component.\n",
      "    \"\"\"\n",
      "    if cell_type == 'markdown':\n",
      "        new_cell = MarkdownCell(\"\")\n",
      "    elif cell_type == 'code':\n",
      "        new_cell = CodeCell(\"\")\n",
      "    elif cell_type == 'prompt':\n",
      "        new_cell = PromptCell(\"\")\n",
      "    #elif cell_type == 'agent':\n",
      "    #    new_cell = AgentCell(\"\")\n",
      "    else:\n",
      "        return \"Invalid cell type\"\n",
      "    \n",
      "    return new_cell.render()\n",
      "\n",
      "\n",
      "# %% ../nbs/main.ipynb 9\n",
      "@rt('/notebook/{notebook_file}')\n",
      "def load_notebook(notebook_file:str): \n",
      "    \"\"\"Load a Jupyter Notebook file and render its cells.\n",
      "    \n",
      "    Args:\n",
      "        notebook_file: Path to .ipynb file to load.\n",
      "        \n",
      "    Returns:\n",
      "        Tuple of Title and Body elements for the page.\n",
      "    \"\"\"\n",
      "    if not os.path.exists(notebook_file):\n",
      "        rendered_cells = []\n",
      "        print ('Notebook Not Found:',notebook_file)\n",
      "\n",
      "    else:\n",
      "        cells = []\n",
      "        with open(notebook_file, 'r', encoding='utf-8') as f:\n",
      "            notebook = json.load(f)\n",
      "            cells = notebook['cells']\n",
      "        \n",
      "        cell_objects = [reconstruct_ipynb_cell(cell) for cell in cells]\n",
      "        rendered_cells = [cell.render() for cell in cell_objects]\n",
      "\n",
      "\n",
      "    return Title(\"Unreal LLM Sandbox\"),Body(\n",
      "        Toolbar(notebook_file.split('.ipynb')[0]),\n",
      "        Style(get_static('styles.css')),\n",
      "        Div(  *rendered_cells,\n",
      "            cls='px-5',  \n",
      "            id='notebook-container' \n",
      "        )\n",
      "    )\n",
      "\n",
      "@rt('/save_notebook/{notebook_file}', methods=['POST'])\n",
      "async def save_notebook(notebook_file: str, request):\n",
      "    \"\"\"Save notebook cells to a Jupyter .ipynb file.\n",
      "    \n",
      "    Args:\n",
      "        notebook_file: Filename to save to.\n",
      "        request: Request with JSON body containing 'cells' list.\n",
      "    \n",
      "    Returns:\n",
      "        JSON with status message.\n",
      "    \"\"\"\n",
      "    data = await request.json()\n",
      "    cell_dict_list = data.get('cells', [])\n",
      "    \n",
      "    # Reconstruct cell objects and convert to ipynb format\n",
      "    cells = reconstruct_cells_from_history(cell_dict_list)\n",
      "    ipynb_cells = [cell.to_ipynb() for cell in cells]\n",
      "    \n",
      "    # Build notebook structure\n",
      "    notebook = {\n",
      "        \"nbformat\": 4,\n",
      "        \"nbformat_minor\": 5,\n",
      "        \"metadata\": {\n",
      "            \"kernelspec\": {\n",
      "                \"display_name\": \"Python 3\",\n",
      "                \"language\": \"python\",\n",
      "                \"name\": \"python3\"\n",
      "            }\n",
      "        },\n",
      "        \"cells\": ipynb_cells\n",
      "    }\n",
      "    \n",
      "    with open(notebook_file, 'w', encoding='utf-8') as f:\n",
      "        json.dump(notebook, f, indent=2, ensure_ascii=False)\n",
      "    \n",
      "    return {\"status\": \"saved\", \"file\": notebook_file}\n",
      "    \n",
      "\n",
      "# %% ../nbs/main.ipynb 10\n",
      "import uvicorn\n",
      "\n",
      "def start_server():\n",
      "    uvicorn.run(app,\n",
      "                 host='0.0.0.0',\n",
      "                 port=5001, \n",
      "                 timeout_graceful_shutdown=1)\n",
      "\n",
      "# %% ../nbs/main.ipynb 12\n",
      "#| eval: false\n",
      "if __name__ == \"__main__\":\n",
      "    start_server()\n",
      "\n",
      "\n",
      "============================================================\n",
      "../llm_sandbox_ui/llm_tools.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/llm_tools.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['TOOLS', 'TOOL_SCHEMAS', 'get_tools', 'register_tool', 'search_web', 'read_url']\n",
      "\n",
      "# %% ../nbs/llm_tools.ipynb 3\n",
      "import requests\n",
      "import litellm\n",
      "import json\n",
      "from lisette import lite_mk_func\n",
      "\n",
      "TOOLS = {}\n",
      "TOOL_SCHEMAS = []\n",
      "\n",
      "\n",
      "def get_tools():\n",
      "    \"\"\"Return available tool schemas.\"\"\"\n",
      "    return TOOL_SCHEMAS\n",
      "\n",
      "\n",
      "def register_tool(func):\n",
      "    \"\"\"Register a function as a tool.\"\"\"\n",
      "    TOOLS[func.__name__] = func\n",
      "    schema = lite_mk_func(func)\n",
      "    # Remove old schema if exists\n",
      "    TOOL_SCHEMAS[:] = [s for s in TOOL_SCHEMAS if s['function']['name'] != func.__name__]\n",
      "    TOOL_SCHEMAS.append(schema)\n",
      "    return func\n",
      "\n",
      "\n",
      "@register_tool\n",
      "def search_web(query: str, max_results: int = 10):\n",
      "    \"\"\"Search DuckDuckGo and return top results.\n",
      "    \n",
      "    Args:\n",
      "        query: Search string.\n",
      "        max_results: Maximum number of results to return.\n",
      "        \n",
      "    Returns:\n",
      "        JSON string of results with title, url, snippet.\n",
      "    \"\"\"    \n",
      "    from ddgs import DDGS\n",
      "    \n",
      "    results = DDGS().text(query, max_results=max_results)\n",
      "    return str([{\"title\": r[\"title\"], \"url\": r[\"href\"], \"snippet\": r[\"body\"]} \n",
      "            for r in results])\n",
      "\n",
      "\n",
      "@register_tool\n",
      "def read_url(url:str):\n",
      "    \"\"\"Retrieve webpage HTML content.\n",
      "    \n",
      "    Args:\n",
      "        url: URL to fetch.\n",
      "        \n",
      "    Returns:\n",
      "        Raw HTML string.\n",
      "    \"\"\"    \n",
      "    import requests\n",
      "    response = requests.get(url)\n",
      "    html = response.text\n",
      "    return html\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "../llm_sandbox_ui/app_config.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/app_config.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['KERNEL_URL', 'MODEL', 'PROMPT_SPLIT', 'NOTEBOOK_SYS_PROMPT', 'UE_TOOL_SYS_PROMPT']\n",
      "\n",
      "# %% ../nbs/app_config.ipynb 3\n",
      "KERNEL_URL = 'http://localhost:5002'\n",
      "\n",
      "MODEL = 'gpt-5.2'\n",
      "\n",
      "PROMPT_SPLIT = '\\n\\n##### LLM Response: <!-- LLM -->\\n\\n'\n",
      "\n",
      "NOTEBOOK_SYS_PROMPT = \"\"\"You are an AI assistant, your goal is to help the user build tools.\\n\n",
      "You're in a Jupyter Notebook, which is connected to Unreal Engine 5.6.\\n\n",
      "The users programming language of choice is python.\\n\n",
      "You can search the internet if unsure about an Unreal function\\n\"\"\"\n",
      "\n",
      "UE_TOOL_SYS_PROMPT = \"\"\"You are an AI assistant in a Jupyter Notebook.\\n\n",
      "The TOOLS you have run in Unreal Engine.\\n\n",
      "Your goal is to use TOOLS to:\n",
      "A) Modify the Unreal Scene.\\n\n",
      "or..\n",
      "B) Answer questions ab out the Unreal Scene.\\n\n",
      "**Use the TOOLS** provided to you to accomplish the task.\\n\n",
      "Dont respond by generating blocks of code.\\n\"\"\"\n",
      "\n",
      "\n",
      "============================================================\n",
      "../llm_sandbox_ui/notebook_io.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/notebook_io.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['reconstruct_cells_from_history', 'reconstruct_ipynb_cell', 'prepare_chat_history', 'is_ask_cell', 'prep_prompt_cell',\n",
      "           'seperate_markdown', 'prep_markdown_cell', 'format_for_chat', 'prep_code_cell', 'prep_code_cell_output']\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 3\n",
      "import io\n",
      "import base64\n",
      "import json\n",
      "from PIL import Image\n",
      "from .cells import MarkdownCell, CodeCell, PromptCell#, AgentCell\n",
      "from .app_config import PROMPT_SPLIT\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 4\n",
      "def reconstruct_cells_from_history(notebook_history):\n",
      "    \"\"\"Convert raw JavaScript cell data into rendered cell objects.\n",
      "    \n",
      "    Args:\n",
      "        notebook_history: List of cell dicts from JavaScript with keys:\n",
      "            cell_type, cell_id, source, outputs.\n",
      "    \n",
      "    Returns:\n",
      "        List of cell objects (MarkdownCell, CodeCell, or PromptCell).\n",
      "    \n",
      "    Raises:\n",
      "        ValueError: If cell_type is unknown.\n",
      "    \"\"\"    \n",
      "    cells = []\n",
      "    \n",
      "    for cell_data in notebook_history:\n",
      "        cell_type = cell_data['cell_type']\n",
      "        cell_id = cell_data['cell_id']\n",
      "        source = cell_data['source']\n",
      "        outputs = cell_data.get('outputs')\n",
      "        \n",
      "        if cell_type == 'markdown':\n",
      "            cell = MarkdownCell(source=source, cell_id=cell_id)\n",
      "        \n",
      "        elif cell_type == 'code':\n",
      "            cell = CodeCell(source=source, outputs=outputs or [], cell_id=cell_id)\n",
      "        \n",
      "        elif cell_type == 'prompt':\n",
      "            cell = PromptCell(source=source, outputs=outputs or '', cell_id=cell_id)\n",
      "\n",
      "        #elif cell_type == 'agent':\n",
      "        #    cell = AgentCell(source_prompt=source, source_code=outputs, cell_id=cell_id)\n",
      "        else:\n",
      "            raise ValueError(f\"Unknown cell type: {cell_type}\")\n",
      "        \n",
      "        cells.append(cell)\n",
      "    \n",
      "    return cells\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 5\n",
      "def reconstruct_ipynb_cell(cell):\n",
      "    \"\"\"Convert a Jupyter notebook cell dict to the appropriate cell class.\n",
      "    \n",
      "    Args:\n",
      "        cell: Dict with 'cell_type', 'metadata', and type-specific keys.\n",
      "            Markdown cells may have 'agent_cell' or 'prompt_cell' in metadata.\n",
      "    \n",
      "    Returns:\n",
      "        MarkdownCell, CodeCell, PromptCell, AgentCell, or None if unknown type.\n",
      "    \"\"\"\n",
      "    jup_cell_type = cell['cell_type']\n",
      "\n",
      "    if jup_cell_type == 'markdown':\n",
      "        #if 'agent_cell' in cell['metadata']:\n",
      "        #    cell_type = 'agent'\n",
      "        if 'prompt_cell' in cell['metadata']:\n",
      "            cell_type = 'prompt'\n",
      "        else:\n",
      "            cell_type = 'markdown'\n",
      "    else:\n",
      "        cell_type = jup_cell_type\n",
      "    \n",
      "    \n",
      "    if cell_type == 'markdown':\n",
      "        return MarkdownCell.from_ipynb(cell)\n",
      "    if cell_type == 'code':\n",
      "        return CodeCell.from_ipynb(cell)\n",
      "    elif cell_type == 'prompt':\n",
      "        return PromptCell.from_ipynb(cell)\n",
      "    #elif cell_type == 'agent':\n",
      "    #    return AgentCell.from_ipynb(cell)\n",
      "    \n",
      "    else:\n",
      "        return None\n",
      "\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 6\n",
      "def prepare_chat_history(cell_list):\n",
      "    \"\"\"\n",
      "    Converts a list of notebook cells into a conversation history for the LLM.\n",
      "\n",
      "    Args:\n",
      "        cell_list (list): List of notebook cells.\n",
      "\n",
      "    Returns:\n",
      "        list: A list of message dictionaries (role/content) for the Chat API.\n",
      "    \"\"\"\n",
      "    cell_context = []\n",
      "    for cell in cell_list:\n",
      "        cell_type = cell['cell_type']\n",
      "\n",
      "        if cell_type == 'markdown':\n",
      "\n",
      "            if is_ask_cell(cell):\n",
      "                    question, answer = prep_prompt_cell(cell)\n",
      "                    formatted_q = format_for_chat(question)\n",
      "                    cell_context.append( {\"role\": \"user\", \"content\": formatted_q} )\n",
      "                    formatted_a = format_for_chat(answer)\n",
      "                    cell_context.append( {\"role\": \"assistant\", \"content\": formatted_a} )\n",
      "            else:\n",
      "                formatted = format_for_chat(prep_markdown_cell(cell))\n",
      "                if formatted:\n",
      "\n",
      "                    cell_context.append( {\"role\": \"user\", \"content\": formatted} )\n",
      "\n",
      "        elif cell_type == 'code':\n",
      "\n",
      "            sub_type = 'Code'\n",
      "            response_role = 'user'\n",
      "\n",
      "            formatted = format_for_chat(prep_code_cell(cell,cell_type=sub_type))\n",
      "            if formatted:\n",
      "                cell_context.append( {\"role\": \"user\", \"content\": formatted} )\n",
      "\n",
      "            formatted = format_for_chat(prep_code_cell_output(cell,cell_type=sub_type))\n",
      "            if formatted:\n",
      "                cell_context.append( {\"role\": response_role, \"content\":formatted} )\n",
      "    return cell_context\n",
      "\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 7\n",
      "def is_ask_cell(cell):\n",
      "    \"\"\"Check if a cell is a prompt cell with a response.\n",
      "    \n",
      "    Args:\n",
      "        cell (dict): The JSON dictionary representing a cell.\n",
      "        \n",
      "    Returns:\n",
      "        bool: True if cell contains the prompt/response separator, False otherwise.\n",
      "    \"\"\"\n",
      "    source = cell['source']\n",
      "    try:\n",
      "        split_index =  source.index(PROMPT_SPLIT[2:-1])\n",
      "        return True\n",
      "    except:\n",
      "        return False\n",
      "         \n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 8\n",
      "def prep_prompt_cell(cell):\n",
      "    \"\"\"\n",
      "    Extracts text and embedded images from a markdown cell.\n",
      "\n",
      "    Args:\n",
      "        cell (dict): The JSON dictionary representing a markdown cell.\n",
      "\n",
      "    Returns:\n",
      "        tuple (list): Two lists containing strings (text content) and bytes (decoded image data).\n",
      "    \"\"\"\n",
      "    source = cell['source']\n",
      "    try:\n",
      "        split_index =  source.index(PROMPT_SPLIT[2:-1])\n",
      "        question = seperate_markdown(source[:split_index-1])\n",
      "        answer = seperate_markdown(source[split_index+2:])\n",
      "    except:\n",
      "        question = seperate_markdown(source)\n",
      "        answer = []\n",
      "\n",
      "    formatted_question = ['## User Question Cell\\n']+question\n",
      "    return formatted_question, answer\n",
      "\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 9\n",
      "def seperate_markdown(markdown):\n",
      "    \"\"\"Separate markdown text blocks from embedded base64 images.\n",
      "    \n",
      "    Args:\n",
      "        markdown: List of markdown content strings, potentially containing\n",
      "            embedded base64 images in the format `(data:image/...;base64,...)`.\n",
      "    \n",
      "    Returns:\n",
      "        List containing strings for text blocks and bytes for decoded images.\n",
      "    \"\"\"\n",
      "    out_list = []\n",
      "    for block in markdown:\n",
      "\n",
      "        if \"(data:image/\" in block:\n",
      "            base_64_text = block.split('base64,')[1]\n",
      "            base_64_text = base_64_text.split(')')[0]\n",
      "            output_image_bytes =  base64.b64decode(base_64_text)\n",
      "            out_list.append(output_image_bytes )\n",
      " \n",
      "        else:\n",
      "            out_list.append(block)\n",
      "    return out_list\n",
      "\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 10\n",
      "def prep_markdown_cell(markdown_cell):\n",
      "    \"\"\"\n",
      "    Extracts text and embedded images from a markdown cell.\n",
      "\n",
      "    Args:\n",
      "        markdown_cell (dict): The JSON dictionary representing a markdown cell.\n",
      "\n",
      "    Returns:\n",
      "        list: A list containing strings (text content) and bytes (decoded image data).\n",
      "    \"\"\"\n",
      "    output_list = ['## Markdown Cell\\n']\n",
      "\n",
      "    for block in markdown_cell['source']:\n",
      "        if \"(data:image/\" in block:\n",
      "            base_64_text = block.split('base64,')[1]\n",
      "            base_64_text = base_64_text.split(')')[0]\n",
      "            output_image_bytes =  base64.b64decode(base_64_text)\n",
      "            output_list.append(output_image_bytes )\n",
      " \n",
      "        else:\n",
      "            output_list.append(block)\n",
      "    return output_list\n",
      "    \n",
      "\n",
      "def format_for_chat(items):\n",
      "    \"\"\"\n",
      "    Formats a list of mixed text and image bytes into the OpenAI/LiteLLM message structure.\n",
      "\n",
      "    Args:\n",
      "        items (list): A list containing strings or byte objects.\n",
      "\n",
      "    Returns:\n",
      "        list: A list of dictionaries with 'type' (text/image_url) keys.\n",
      "    \"\"\"\n",
      "    formatted = []\n",
      "    \n",
      "    for item in items:\n",
      "        if isinstance(item,str):\n",
      "            if item != '':\n",
      "                formatted.append( {\"type\": \"text\", \"text\": item})\n",
      "        elif isinstance(item,bytes):\n",
      "            img = Image.open(io.BytesIO(item))\n",
      "            img_format = img.format.lower()\n",
      "            base64_string = base64.b64encode(item).decode('utf-8')\n",
      "            formatted.append( {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/{img_format};base64,{base64_string}\"}})\n",
      "    \n",
      "    return formatted\n",
      "\n",
      "\n",
      "def prep_code_cell(code_cell,cell_type='Code'):\n",
      "    \"\"\"\n",
      "    Extracts and labels source code from a code cell.\n",
      "\n",
      "    Args:\n",
      "        code_cell (dict): The JSON dictionary representing a code cell.\n",
      "        cell_type (str, optional): Label for the cell. Defaults to 'Code'.\n",
      "\n",
      "    Returns:\n",
      "        list: A list containing the labeled header and the source code string.\n",
      "    \"\"\"\n",
      "    output_list = [f'{cell_type} Cell\\n']\n",
      "\n",
      "    code_input = ''.join(code_cell['source'])\n",
      "    output_list.append(code_input)\n",
      "\n",
      "    return output_list\n",
      "\n",
      "\n",
      "def prep_code_cell_output(code_cell,cell_type='Code'):\n",
      "    \"\"\"\n",
      "    Extracts outputs (logs, streams, errors, images) from a code cell.\n",
      "\n",
      "    Args:\n",
      "        code_cell (dict): The JSON dictionary representing a code cell.\n",
      "        cell_type (str, optional): Label for the cell. Defaults to 'Code'.\n",
      "\n",
      "    Returns:\n",
      "        list: A list containing text output, error traces, or image bytes.\n",
      "    \"\"\"\n",
      "    if cell_type == 'Code':\n",
      "        output_list = ['### Code Cell Output\\n']\n",
      "    else:\n",
      "        output_list = []\n",
      "        \n",
      "    for block in code_cell['outputs']:\n",
      "        if block['output_type'] in ['display_data', 'execute_result']:\n",
      "            for key in  block['data'].keys():\n",
      "\n",
      "                out_data = None\n",
      "                block_data = block['data'][key]\n",
      "\n",
      "                if key.endswith('json'):\n",
      "                    try:\n",
      "                        out_data = json.dumps(block_data,indent=4)\n",
      "\n",
      "                    except Exception as e:\n",
      "                        out_data = f'[Un-Serializable JSON Output: {key}]'\n",
      "\n",
      "                elif key.startswith('image'):\n",
      "                    try:\n",
      "                        out_data = base64.b64decode(block_data)\n",
      "\n",
      "                    except Exception as e:\n",
      "                        out_data = f'[Un-Encodable Image Output: {key}]'\n",
      "\n",
      "                elif key.startswith('text'):\n",
      "                    if isinstance(block_data, list):\n",
      "                        out_data = \"\".join(block_data)\n",
      "                    else:\n",
      "                        out_data = block_data\n",
      "                else:\n",
      "                    out_data = f'[Un-Renderable Output Type: {key}]'\n",
      "                \n",
      "                output_list.append(out_data)\n",
      "\n",
      "\n",
      "        elif block['output_type'] == 'stream':\n",
      "            output_list.append(''.join(block['text']))\n",
      "\n",
      "        elif block['output_type'] == 'error' :\n",
      "            output_list.append('#### Error\\n')  \n",
      "            output_list.append(f'evalue:{block[\"evalue\"]}\\n\\n traceback:{block[\"traceback\"]}')  \n",
      "\n",
      "\n",
      "    return output_list\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#| notest\n",
    "#| eval: false\n",
    "#| hide\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../llm_sandbox_ui/')\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "import big_project_helper as bph\n",
    "\n",
    "bph.display_project_contents('llm_sandbox_ui')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cb7f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp streaming\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123fa2eb",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1820818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import queue\n",
    "import asyncio\n",
    "import json\n",
    "from starlette.responses import StreamingResponse\n",
    "\n",
    "\n",
    "active_streams = {}\n",
    "\n",
    "\n",
    "class SSEStream:\n",
    "    \"\"\"Unified SSE streaming with queue-based message passing.\n",
    "    \n",
    "    Args:\n",
    "        cell_id: Unique identifier for abort handling.\n",
    "    \"\"\"\n",
    "    def __init__(self, stream_key):\n",
    "        self.stream_key = stream_key  \n",
    "        self.q = queue.Queue()\n",
    "        active_streams[stream_key] = {'abort': False}\n",
    "    \n",
    "    def text(self, content: str):\n",
    "        \"\"\"Send text chunk to stream.\n",
    "        \n",
    "        Args:\n",
    "            content: String to send.\n",
    "        \"\"\"\n",
    "        self.q.put({\"type\": \"text\", \"data\": content})\n",
    "\n",
    "    def tag(self, content: str):\n",
    "        \"\"\"Send control tag to switch stream target.\n",
    "        \n",
    "        Args:\n",
    "            content: Tag name.\n",
    "        \"\"\"\n",
    "        self.q.put({\"type\": \"tag\", \"data\": content})\n",
    "    \n",
    "    def output(self, data):\n",
    "        \"\"\"Send Jupyter-style output dict.\n",
    "        \n",
    "        Args:\n",
    "            data: Output dict/list (may contain ANSI).\n",
    "        \"\"\"\n",
    "        self.q.put({\"type\": \"output\", \"data\": data})\n",
    "        \n",
    "    def done(self):\n",
    "        \"\"\"Signal stream complete and cleanup.\"\"\"\n",
    "        self.q.put(None)\n",
    "        self.cleanup()\n",
    "\n",
    "    def aborted(self):\n",
    "        \"\"\"Check if user requested abort.\n",
    "        \n",
    "        Returns:\n",
    "            True if aborted, False otherwise.\n",
    "        \"\"\"\n",
    "        return active_streams.get(self.stream_key, {}).get('abort', True)\n",
    "\n",
    "    def response(self):\n",
    "        \"\"\"Create async SSE response.\n",
    "        \n",
    "        Returns:\n",
    "            StreamingResponse for FastHTML route.\n",
    "        \"\"\"\n",
    "        async def generator():\n",
    "            while True:\n",
    "                item = await asyncio.to_thread(self.q.get)\n",
    "                if item is None: break\n",
    "                yield f\"data: {json.dumps(item)}\\n\\n\"\n",
    "            self.cleanup()\n",
    "        return StreamingResponse(generator(), media_type='text/event-stream')\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Remove cell_id from active_streams.\"\"\"\n",
    "        active_streams.pop(self.stream_key, None)\n",
    "        "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
