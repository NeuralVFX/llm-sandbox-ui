{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c675ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialog Name: unreal/unreal-llm-sandbox/nbs/main\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/cells.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/cells.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['up_arrow_ic', 'down_arrow_ic', 'close_ic', 'swap_ic', 'view_ic', 'clean_ic', 'minimize_ic', 'play_ic', 'stop_ic',\n",
      "           'edit_ic', 'tools_ic', 'label_css', 'cell_button_format', 'interrupt_button', 'BaseCell', 'PromptCell',\n",
      "           'MarkdownCell', 'CodeCell']\n",
      "\n",
      "# %% ../nbs/cells.ipynb 3\n",
      "import json\n",
      "import uuid\n",
      "import re\n",
      "import mistune\n",
      "from fasthtml.common import * \n",
      "from .app_config import PROMPT_SPLIT, AGENT_CODE_SPLIT\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 4\n",
      "up_arrow_ic = NotStr(\"&#11014\")\n",
      "down_arrow_ic = NotStr(\"&#11015\")\n",
      "close_ic = NotStr(\"&#x274C\")\n",
      "swap_ic = NotStr(\"&#128257\")\n",
      "view_ic =NotStr(\"&#x1F50D\")\n",
      "clean_ic =NotStr(\"&#x1F9F9\")\n",
      "minimize_ic = NotStr(\"&#x25BC\");\n",
      "play_ic = NotStr(\"&#9654\")\n",
      "stop_ic = NotStr(\"&#9209\")\n",
      "edit_ic = NotStr(\"&#x1F4DD\")\n",
      "tools_ic = NotStr(\"&#x1F6E0\")\n",
      "\n",
      "label_css = \"text-xs text-gray-400 px-2 py-1 bg-gray-800\"\n",
      "cell_button_format = 'btn btn-square btn-ghost btn-xs text-xl'\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 5\n",
      "def interrupt_button(cell_id):\n",
      "    \"\"\"Create an interrupt button that aborts the active stream for a cell.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique cell identifier.\n",
      "        \n",
      "    Returns:\n",
      "        Button component that POSTs to /interrupt/{cell_id}.\n",
      "    \"\"\"\n",
      "    return Button(stop_ic, \n",
      "        onClick=f\"\"\"fetch('/interrupt/{cell_id}', {{\n",
      "            method: 'POST', \n",
      "            headers: {{'Content-Type': 'application/json'}}, \n",
      "            body: JSON.stringify({{notebook: document.querySelector('.notebook-name')?.value || 'untitled'}})\n",
      "        }})\"\"\",\n",
      "        cls=cell_button_format)\n",
      "        \n",
      "\n",
      "# %% ../nbs/cells.ipynb 6\n",
      "class BaseCell:\n",
      "    \"\"\"Base class for all notebook cell types.\n",
      "    \n",
      "    Attributes:\n",
      "        cell_type (str): Type identifier ('markdown', 'code', 'llm').\n",
      "        source (str): Cell content/code.\n",
      "        outputs (list): Cell execution outputs (empty for markdown).\n",
      "        cell_id (str): Unique cell identifier.\n",
      "    \"\"\"\n",
      "    cell_type = None  \n",
      "    \n",
      "    def _make_markdown_init_script(self):\n",
      "        \"\"\" Scripts for managing Markdown display updating \"\"\"\n",
      "        return Script(f\"\"\"\n",
      "        (function() {{\n",
      "            const cell = document.querySelector('[data-cell-id=\"{self.cell_id}\"]');\n",
      "            if (!cell) return;  // Safety check\n",
      "            \n",
      "            const textarea = cell.querySelector('textarea.content-edit');\n",
      "            const renderdiv = cell.querySelector('.content-render');\n",
      "            const label = cell.querySelector('.toggle-label');\n",
      "            const checkbox = cell.querySelector('.toggle-edit');\n",
      "            \n",
      "            // Sync textarea to rendered\n",
      "            textarea.addEventListener('input', () => {{\n",
      "                renderdiv.innerHTML = marked.parse(textarea.value);\n",
      "                Prism.highlightAllUnder(renderdiv);\n",
      "            }});\n",
      "            \n",
      "            // Wire label to checkbox\n",
      "            label.addEventListener('click', () => {{ \n",
      "                checkbox.checked = !checkbox.checked; \n",
      "                checkbox.dispatchEvent(new Event('change')); \n",
      "            }});\n",
      "\n",
      "            textarea.style.height = 'auto';\n",
      "            textarea.style.height = Math.min(textarea.scrollHeight, 500) + 'px';\n",
      "            textarea.addEventListener('input', () => {{{{\n",
      "                textarea.style.height = 'auto';\n",
      "                textarea.style.height = Math.min(textarea.scrollHeight, 500) + 'px';\n",
      "            }}}});\n",
      "\n",
      "        }})();\n",
      "        \"\"\")\n",
      "\n",
      "    def __init__(self, source=\"\", outputs=\"\", cell_id=None):\n",
      "        \"\"\"Initialize a cell.\n",
      "        \n",
      "        Args:\n",
      "            source (str): Cell content. Defaults to \"\".\n",
      "            outputs (list, optional): Execution outputs. Defaults to [].\n",
      "            cell_id (str, optional): Unique ID. Generates UUID if None.\n",
      "        \"\"\"\n",
      "        self.source = source\n",
      "        self.cell_id = cell_id or uuid.uuid4().hex[:12]\n",
      "        self.outputs = outputs \n",
      "    \n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "        pass\n",
      "\n",
      "    def build_right_buttons(self):\n",
      "        \"\"\"Build common right buttons (move up/down/delete).\"\"\"\n",
      "        return Div(\n",
      "            Div(\n",
      "                Button(minimize_ic, \n",
      "                    onClick=f\"toggleMinimize('{self.cell_id}')\",\n",
      "                    cls=cell_button_format),\n",
      "                Button(up_arrow_ic,\n",
      "                    cls=cell_button_format,\n",
      "                    onClick=f\"moveUp('{self.cell_id}')\"),\n",
      "                Button(down_arrow_ic,\n",
      "                    cls=cell_button_format,\n",
      "                    onClick=f\"moveDown('{self.cell_id}')\"),\n",
      "                Button(close_ic,\n",
      "                    cls=cell_button_format,\n",
      "                    onClick=f\"deleteCell('{self.cell_id}')\"),\n",
      "                cls='btn-group'\n",
      "            ),\n",
      "            cls='flex justify-end'\n",
      "        )\n",
      "\n",
      "    def build_top_menu(self):\n",
      "        \"\"\"Build complete top menu bar with buttons and title.\"\"\"\n",
      "        display_name = self.cell_type.replace('_', ' ').title() + ' Cell'\n",
      "        return Div(\n",
      "            self.build_left_buttons(),\n",
      "            Div(display_name, style='font-size: 0.75rem; line-height: 1;'),\n",
      "            self.build_right_buttons(),\n",
      "            cls='flex justify-between items-center bg-gray-800 text-white py-0.5 px-2 rounded-t-lg border-b border-gray-700'\n",
      "        )\n",
      "\n",
      "    def build_markdown_source_area(self,source,round_b=True):\n",
      "        \"\"\"Build textarea and rendered markdown display for a cell.\n",
      "        \n",
      "        Args:\n",
      "            source: Markdown text content.\n",
      "            round_b: If True, apply rounded bottom corners.\n",
      "            \n",
      "        Returns:\n",
      "            List of [Textarea, Div] components.\n",
      "        \"\"\"\n",
      "        round_cls = 'rounded-b-lg' if round_b else ''\n",
      "\n",
      "        text_area = Textarea(source,\n",
      "                    placeholder='Enter Markdown Here...', \n",
      "                    rows=1,\n",
      "                    cls=f'w-full text-gray-100 p-4 bg-[#1e1e1e] {round_cls}'\\\n",
      "                    ' max-h-[500px] overflow-y-auto border-0 content-edit')\n",
      "\n",
      "        markdown_display = Div(NotStr(mistune.html(source)), \n",
      "                            cls='w-full markdown-body bg-gray-900 text-gray-100 p-4'\\\n",
      "                            f' {round_cls} max-h-[500px] overflow-y-auto content-render', \n",
      "                            style='list-style-position: inside; min-height: 3.5em;')\n",
      "\n",
      "\n",
      "        return [text_area, markdown_display]\n",
      "\n",
      "    def build_monaco_editor(self,cell_id,source_code='', min_height=20, max_height=500):\n",
      "        \"\"\"Build Monaco editor initialization script for a code cell.\n",
      "        \n",
      "        Args:\n",
      "            cell_id: Unique cell identifier for the editor container.\n",
      "            source_code: Initial code content.\n",
      "            min_height: Minimum editor height in pixels.\n",
      "            max_height: Maximum editor height in pixels.\n",
      "            \n",
      "        Returns:\n",
      "            Script component that initializes Monaco editor.\n",
      "        \"\"\"\n",
      "        monaco_editor_script = Script(f\"\"\"\n",
      "                                \n",
      "                require(['vs/editor/editor.main'], function() {{\n",
      "                    const sourceCode = {json.dumps(source_code)};\n",
      "                    const container = document.getElementById('monaco-{cell_id}');\n",
      "                    if (!container) return;\n",
      "                    \n",
      "                    const editor = monaco.editor.create(container, {{\n",
      "                        value: sourceCode,\n",
      "                        language: 'python',\n",
      "                        theme: 'vs-dark',\n",
      "                        automaticLayout: false,\n",
      "                        scrollBeyondLastLine: false,\n",
      "                        fontSize: 13, \n",
      "                        scrollBeyondLastColumn: 0,\n",
      "                        model: monaco.editor.createModel(sourceCode, 'python', \n",
      "                            monaco.Uri.parse(`inmemory://{cell_id}.py`))\n",
      "                    }});\n",
      "                    \n",
      "                    const lineCount = editor.getModel().getLineCount();\n",
      "                    const newHeight = Math.min(Math.max(lineCount * 19, {min_height}), {max_height});\n",
      "                    container.style.height = newHeight + 'px';\n",
      "                    editor.layout();\n",
      "\n",
      "                    editor.onDidChangeModelContent(() => {{\n",
      "                        const lineCount = editor.getModel().getLineCount();\n",
      "                        const newHeight = Math.min(Math.max(lineCount * 19,{min_height}), {max_height});\n",
      "                        container.style.height = newHeight + 'px';\n",
      "                        editor.layout(); \n",
      "                    }});\n",
      "                }});\n",
      "            \n",
      "                                \"\"\")\n",
      "        return monaco_editor_script\n",
      "\n",
      "    def build_code_output(self, tag='',min_height=100, max_height=300, outputs_json=[], round_b = False):\n",
      "        \"\"\"Build code output display area with hidden storage.\n",
      "        \n",
      "        Args:\n",
      "            tag: Suffix for CSS class names (e.g., '-code').\n",
      "            min_height: Minimum output area height in pixels.\n",
      "            max_height: Maximum output area height in pixels.\n",
      "            outputs_json: JSON string of Jupyter-style outputs.\n",
      "            round_b: If True, apply rounded bottom corners.\n",
      "            \n",
      "        Returns:\n",
      "            List of [Pre (display), Div (store)] components.\n",
      "        \"\"\"\n",
      "        if round_b:\n",
      "            round_button_cls = 'rounded-b-lg' \n",
      "        else:\n",
      "            round_button_cls = ''\n",
      "            \n",
      "        output_area_code = Pre(\n",
      "                          style='font-family: Consolas, Monaco, monospace;'\\\n",
      "                           ' font-size: 13px; background-color: #111827;',\n",
      "                          cls=f'w-full bg-gray-900 text-gray-100 p-4 {round_button_cls}' \\\n",
      "                          f' min-h-[{min_height}px] max-h-[{max_height}px] overflow-y-auto border-0 output-display{tag}')\n",
      "                          \n",
      "        output_store_code = Div(\n",
      "            outputs_json,  # â† Make sure this has content\n",
      "            cls='output-store'+tag, \n",
      "            style='display:none;'\n",
      "        )\n",
      "\n",
      "        return [output_area_code, output_store_code]\n",
      "\n",
      "    def build_llm_output(self, tag='',min_height=100, max_height=300, outputs_json=\"\"):\n",
      "        \"\"\"Build LLM markdown output display area with hidden storage.\n",
      "        \n",
      "        Args:\n",
      "            tag: Suffix for CSS class names (e.g., '-llm').\n",
      "            min_height: Minimum output area height in pixels.\n",
      "            max_height: Maximum output area height in pixels.\n",
      "            outputs_json: Raw markdown string to display.\n",
      "            \n",
      "        Returns:\n",
      "            List of [Div (store), Div (display)] components.\n",
      "        \"\"\"\n",
      "        output_store = Div(\n",
      "            outputs_json,  # â† Make sure this has content\n",
      "            cls='output-store'+tag, \n",
      "            style='display:none;'\n",
      "        )\n",
      "\n",
      "        output_area = Div(\n",
      "                        cls='w-full markdown-body bg-gray-900 text-gray-100 p-4 rounded-b-lg'\\\n",
      "                        f' min-h-[{min_height}px] max-h-[{max_height}px] overflow-y-auto border-0 output-display{tag}',\n",
      "                        style='background-color: #111827;',\n",
      "                        )\n",
      "\n",
      "        return [output_store, output_area]\n",
      "\n",
      "\n",
      "    def build_source_area(self):\n",
      "        \"\"\"Build editable source code/markdown area.\"\"\"\n",
      "        pass\n",
      "\n",
      "    def build_output_area(self):\n",
      "        \"\"\"Build output display area (if applicable).\"\"\"\n",
      "        pass\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\"Convert cell to Jupyter notebook dict format.\"\"\"\n",
      "        pass\n",
      "\n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\"Create cell from Jupyter notebook dict.\n",
      "        \n",
      "        Args:\n",
      "            cell_dict (dict): Jupyter cell structure.\n",
      "            \n",
      "        Returns:\n",
      "            BaseCell: Instantiated cell subclass.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 7\n",
      "class PromptCell(BaseCell):\n",
      "    \"\"\"Cell for LLM prompts with streaming markdown responses.\n",
      "    \n",
      "    Stores user prompt in source and LLM response in outputs.\n",
      "    Serializes to ipynb as markdown with PROMPT_SPLIT separator.\n",
      "    \"\"\"\n",
      "    cell_type = 'prompt'\n",
      "\n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\" Load From Ipynb Dict\"\"\"\n",
      "        \n",
      "        source_txt = ''.join(cell_dict['source'])\n",
      "        if PROMPT_SPLIT in source_txt:\n",
      "            source, outputs = ''.join(source_txt).split(PROMPT_SPLIT)\n",
      "\n",
      "        else:\n",
      "            source = source_txt\n",
      "            outputs = ''\n",
      "\n",
      "        return cls(source=source, \n",
      "                outputs=outputs,\n",
      "                cell_id=cell_dict['id'])\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\" Build Ipynb Dict\"\"\"\n",
      "\n",
      "        out_dict = {\n",
      "            'id':self.cell_id,\n",
      "            'cell_type': 'markdown',\n",
      "            'metadata': {'id': self.cell_id, 'prompt_cell': True}\n",
      "        }\n",
      "        \n",
      "        # Combine source + outputs with separator\n",
      "        if self.outputs:\n",
      "            source_text = self.source + PROMPT_SPLIT + self.outputs\n",
      "        else:\n",
      "            source_text = self.source\n",
      "        \n",
      "        out_dict['source'] = source_text.splitlines(keepends=True)\n",
      "        \n",
      "        return out_dict\n",
      "\n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "        \n",
      "        return Div(\n",
      "                Div(\n",
      "                    Button(play_ic,\n",
      "                            onClick=f\"executePromptCell('{self.cell_id}')\",\n",
      "                            cls=cell_button_format),\n",
      "                    interrupt_button(self.cell_id),\n",
      "                    Button(clean_ic,\n",
      "                            onClick=f\"clearOutput('{self.cell_id}')\",\n",
      "                            cls=cell_button_format),\n",
      "                    Label(edit_ic,\n",
      "                            cls=cell_button_format + ' toggle-label'),\n",
      "                    Label(\n",
      "                        Input(type='checkbox',\n",
      "                            cls=\"hidden tool-toggle\",\n",
      "                            checked=True),\n",
      "                            tools_ic,\n",
      "                            cls=cell_button_format + ' cursor-pointer'),\n",
      "                    Span(cls=\"loading loading-spinner loading-sm text-primary cell-spinner hidden\"),\n",
      "\n",
      "                ),\n",
      "                cls='flex justify-start'\n",
      "                )\n",
      "\n",
      "    def build_output_area(self):\n",
      "        \"\"\"Build output display area (if applicable).\"\"\"\n",
      "        \n",
      "        outputs_json = self.outputs if self.outputs else ''\n",
      "        output_area = self.build_llm_output( tag='',min_height=50, max_height=400, outputs_json=outputs_json)\n",
      "\n",
      "        llm_out = Div(\"LLM Output\", cls=label_css),\n",
      "\n",
      "        return [llm_out,*output_area ]\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "\n",
      "        toggle_input = Input(type='checkbox', cls=\"hidden toggle-edit\")\n",
      "\n",
      "        menu_bar = self.build_top_menu()\n",
      "        source_area = self.build_markdown_source_area(self.source,round_b=False)\n",
      "        output_area = self.build_output_area()\n",
      "        \n",
      "        watch_script = Script(f\"\"\"\n",
      "            setTimeout(() => {{\n",
      "                watchOutputStore('{self.cell_id}');\n",
      "            }}, 50);\n",
      "        \"\"\")\n",
      "\n",
      "        return Div(\n",
      "            watch_script,\n",
      "            toggle_input,\n",
      "            menu_bar,\n",
      "            *source_area,\n",
      "            *output_area,\n",
      "            self._make_markdown_init_script(),\n",
      "            cls='w-full shadow-xl p-2',\n",
      "            data_cell_type=self.cell_type,\n",
      "            data_cell_id=self.cell_id\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 8\n",
      "class MarkdownCell(BaseCell):\n",
      "    \"\"\"Static markdown documentation cell.\n",
      "    \n",
      "    Displays rendered markdown with toggle to edit source.\n",
      "    No execution or outputs - purely for notes and documentation.\n",
      "    \"\"\"\n",
      "    cell_type = 'markdown'\n",
      "\n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\" Load From Ipynb Dict\"\"\"\n",
      "                \n",
      "        source = ''.join(cell_dict['source'])\n",
      "\n",
      "        return cls(source=source,\n",
      "                cell_id=cell_dict['id'])\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\" Build Ipynb Dict\"\"\"\n",
      "        \n",
      "        out_dict = {\n",
      "            'id':self.cell_id,\n",
      "            'cell_type': 'markdown',\n",
      "            'metadata': {'id': self.cell_id},\n",
      "            'source': self.source.splitlines(keepends=True)\n",
      "        }\n",
      "        \n",
      "        return out_dict\n",
      "\n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "\n",
      "        toggle_button = Label(edit_ic, cls=cell_button_format + ' toggle-label')\n",
      "        return Div( toggle_button, cls='flex justify-start')\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "\n",
      "        toggle_input = Input(type='checkbox', cls=\"hidden toggle-edit\")\n",
      "\n",
      "        menu_bar = self.build_top_menu()\n",
      "        source_area = self.build_markdown_source_area(self.source,round_b=True)\n",
      "\n",
      "\n",
      "        return Div(\n",
      "            toggle_input,\n",
      "            menu_bar,\n",
      "            *source_area,\n",
      "            self._make_markdown_init_script(),\n",
      "            cls='w-full shadow-xl p-2',\n",
      "            data_cell_type=self.cell_type,  \n",
      "            data_cell_id=self.cell_id\n",
      "        )\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 9\n",
      "class CodeCell(BaseCell):\n",
      "    \"\"\"Executable Python code cell with Monaco editor.\n",
      "    \n",
      "    Executes code via kernel and displays Jupyter-style outputs\n",
      "    (streams, execute_result, display_data, errors).\n",
      "    \"\"\"\n",
      "    cell_type = 'code'\n",
      "    \n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\" Load From Ipynb Dict\"\"\"\n",
      "                \n",
      "        source = ''.join(cell_dict['source'])\n",
      "        outputs = cell_dict['outputs']\n",
      "\n",
      "        return cls(source=source,\n",
      "                outputs = outputs,\n",
      "                cell_id=cell_dict['id'])\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\" Build Ipynb Dict\"\"\"\n",
      "        \n",
      "        out_dict = {\n",
      "            'id':self.cell_id,\n",
      "            'cell_type': 'code',\n",
      "            'execution_count': 1,\n",
      "            'metadata': {'id': self.cell_id},\n",
      "            'source': self.source.splitlines(keepends=True),\n",
      "            'outputs': self.outputs\n",
      "        }\n",
      "        \n",
      "        return out_dict\n",
      "\n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "        \n",
      "        return Div(\n",
      "                Div(\n",
      "                    Button(play_ic,\n",
      "                            onClick=f\"executeCell('{self.cell_id}')\",\n",
      "                            cls=cell_button_format),\n",
      "                    interrupt_button(self.cell_id),\n",
      "                    Button(clean_ic,\n",
      "                            onClick=f\"clearOutput('{self.cell_id}')\",\n",
      "                            cls=cell_button_format)\n",
      "                ),\n",
      "                cls='flex justify-start'\n",
      "                )\n",
      "\n",
      "    def build_source_area(self):\n",
      "        \"\"\"Build editable source code/markdown area.\"\"\"\n",
      "        \n",
      "        monaco_editor_script = self.build_monaco_editor(self.cell_id,self.source,min_height=20, max_height=500)\n",
      "\n",
      "        editor_div = Div(id=f'monaco-{self.cell_id}', \n",
      "                        style='height: 20px; width: 100%; overflow: hidden',\n",
      "                        cls='monaco-editor')\n",
      "        \n",
      "        return [editor_div, monaco_editor_script]\n",
      "\n",
      "    def build_output_area(self):\n",
      "        \"\"\"Build output display area (if applicable).\"\"\"\n",
      "        \n",
      "        outputs_json = json.dumps(self.outputs) if self.outputs else '[]'\n",
      "        output_area = self.build_code_output(min_height=50, max_height=400, outputs_json=outputs_json , round_b=True)\n",
      "\n",
      "        code_out = Div(\"Code Output\", cls=label_css),\n",
      "\n",
      "        return [code_out,*output_area]\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "\n",
      "        menu_bar = self.build_top_menu()\n",
      "        source_area = self.build_source_area()\n",
      "        output_area = self.build_output_area()\n",
      "\n",
      "        watch_script = Script(f\"\"\"\n",
      "                setTimeout(() => {{\n",
      "                    window.cellOutputs['{self.cell_id}'] = window.cellOutputs['{self.cell_id}'] || [];\n",
      "                    watchOutputStore('{self.cell_id}');\n",
      "                }}, 50);\n",
      "                \"\"\")\n",
      "                  \n",
      "        return Div(\n",
      "            watch_script,\n",
      "            menu_bar,\n",
      "            *source_area,\n",
      "            *output_area,\n",
      "            cls='w-full shadow-xl p-2',\n",
      "            data_cell_type=self.cell_type,\n",
      "            data_cell_id=self.cell_id\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/streaming.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/streaming.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['active_streams', 'SSEStream']\n",
      "\n",
      "# %% ../nbs/streaming.ipynb 3\n",
      "import queue\n",
      "import asyncio\n",
      "import json\n",
      "from starlette.responses import StreamingResponse\n",
      "\n",
      "\n",
      "active_streams = {}\n",
      "\n",
      "\n",
      "class SSEStream:\n",
      "    \"\"\"Unified SSE streaming with queue-based message passing.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique identifier for abort handling.\n",
      "    \"\"\"\n",
      "    def __init__(self, stream_key):\n",
      "        self.stream_key = stream_key  \n",
      "        self.q = queue.Queue()\n",
      "        active_streams[stream_key] = {'abort': False}\n",
      "    \n",
      "    def text(self, content: str):\n",
      "        \"\"\"Send text chunk to stream.\n",
      "        \n",
      "        Args:\n",
      "            content: String to send.\n",
      "        \"\"\"\n",
      "        self.q.put({\"type\": \"text\", \"data\": content})\n",
      "\n",
      "    def tag(self, content: str):\n",
      "        \"\"\"Send control tag to switch stream target.\n",
      "        \n",
      "        Args:\n",
      "            content: Tag name.\n",
      "        \"\"\"\n",
      "        self.q.put({\"type\": \"tag\", \"data\": content})\n",
      "    \n",
      "    def output(self, data):\n",
      "        \"\"\"Send Jupyter-style output dict.\n",
      "        \n",
      "        Args:\n",
      "            data: Output dict/list (may contain ANSI).\n",
      "        \"\"\"\n",
      "        self.q.put({\"type\": \"output\", \"data\": data})\n",
      "        \n",
      "    def done(self):\n",
      "        \"\"\"Signal stream complete and cleanup.\"\"\"\n",
      "        self.q.put(None)\n",
      "        self.cleanup()\n",
      "\n",
      "    def aborted(self):\n",
      "        \"\"\"Check if user requested abort.\n",
      "        \n",
      "        Returns:\n",
      "            True if aborted, False otherwise.\n",
      "        \"\"\"\n",
      "        return active_streams.get(self.stream_key, {}).get('abort', True)\n",
      "\n",
      "    def response(self):\n",
      "        \"\"\"Create async SSE response.\n",
      "        \n",
      "        Returns:\n",
      "            StreamingResponse for FastHTML route.\n",
      "        \"\"\"\n",
      "        async def generator():\n",
      "            while True:\n",
      "                item = await asyncio.to_thread(self.q.get)\n",
      "                if item is None: break\n",
      "                yield f\"data: {json.dumps(item)}\\n\\n\"\n",
      "            self.cleanup()\n",
      "        return StreamingResponse(generator(), media_type='text/event-stream')\n",
      "\n",
      "    def cleanup(self):\n",
      "        \"\"\"Remove cell_id from active_streams.\"\"\"\n",
      "        active_streams.pop(self.stream_key, None)\n",
      "        \n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/llm.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/llm.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['RemoteToolLLM', 'send_llm_request']\n",
      "\n",
      "# %% ../nbs/llm.ipynb 3\n",
      "import json\n",
      "import requests\n",
      "import litellm\n",
      "\n",
      "from .app_config import MODEL, KERNEL_URL, NOTEBOOK_SYS_PROMPT, UE_TOOL_SYS_PROMPT \n",
      "from .llm_tools import TOOLS, TOOL_SCHEMAS\n",
      "\n",
      "litellm.drop_params = True\n",
      "\n",
      "\n",
      "# %% ../nbs/llm.ipynb 4\n",
      "class RemoteToolLLM:\n",
      "    \"\"\"LLM chat client that executes tools in Unreal Engine via url.\"\"\"\n",
      "    def __init__(self, model='gpt-4.1',use_ue_tools=False):\n",
      "        \"\"\"\n",
      "        LLM chat that executes tools in Unreal Engine.\n",
      "        \n",
      "        Args:\n",
      "            model: LiteLLM model string\n",
      "        \"\"\"\n",
      "        self.model = model\n",
      "        \n",
      "        # Fetch available tools from Unreal\n",
      "\n",
      "        #self.tools = self._fetch_tools()\n",
      "        #self.local_tools = self._fetch_local_tools()\n",
      "        #self.all_tools = self.tools + self.local_tools\n",
      "        if use_ue_tools:\n",
      "            self.all_tools = self._fetch_tools()\n",
      "            self.sys_prompt = UE_TOOL_SYS_PROMPT\n",
      "            print(f\"Connected to Unreal. Available tools: {[t['function']['name'] for t in self.all_tools]}\")\n",
      "\n",
      "        else:\n",
      "            self.all_tools = self._fetch_local_tools()\n",
      "            self.sys_prompt = NOTEBOOK_SYS_PROMPT\n",
      "            print(f\"Available Notebook tools: {[t['function']['name'] for t in self.all_tools]}\")\n",
      "\n",
      "\n",
      "        \n",
      "\n",
      "    \n",
      "    def _fetch_tools(self):\n",
      "        \"\"\"Fetch tool schemas from Unreal endpoint.\n",
      "        \n",
      "        Returns:\n",
      "            List of tool schema dicts.\n",
      "        \"\"\"\n",
      "        response = requests.get(f'{KERNEL_URL}/tools')\n",
      "        return response.json()\n",
      "\n",
      "    def _fetch_local_tools(self):\n",
      "        \"\"\"Get locally registered tool schemas.\n",
      "        \n",
      "        Returns:\n",
      "            List of tool schema dicts.\n",
      "        \"\"\"\n",
      "        global TOOL_SCHEMAS\n",
      "        return TOOL_SCHEMAS\n",
      "    \n",
      "    def _execute_tool(self, func_name, args):\n",
      "        \"\"\"Execute a tool locally or in Unreal.\n",
      "        \n",
      "        Args:\n",
      "            func_name: Name of tool to execute.\n",
      "            args: Dict of arguments.\n",
      "            \n",
      "        Returns:\n",
      "            Tool result as string.\n",
      "        \"\"\"\n",
      "        if func_name in TOOLS:\n",
      "            try:\n",
      "                result = TOOLS[func_name](**args)\n",
      "                return str(result)\n",
      "            except Exception as e:\n",
      "                return f\"Local tool error: {str(e)}\"\n",
      "\n",
      "        response = requests.post(\n",
      "            f'{KERNEL_URL}/execute_tool',\n",
      "            json={'function': func_name, 'arguments': args}\n",
      "        )\n",
      "        data = response.json()\n",
      "        # Check if there's an error\n",
      "        if 'error' in data:\n",
      "            return f\"Error: {data['error']}\"\n",
      "        \n",
      "        # Check if result exists\n",
      "        if 'result' not in data:\n",
      "            return f\"Unexpected response: {data}\"\n",
      "        \n",
      "        return data['result']\n",
      "    \n",
      "    def chat(self, prompt, history=None, max_steps=50, stream=True):\n",
      "        \"\"\"Send message and handle tool calls automatically.\n",
      "        \n",
      "        Args:\n",
      "            prompt: User message.\n",
      "            history: Prior conversation messages.\n",
      "            system_prompt: System instruction.\n",
      "            max_steps: Max tool call iterations.\n",
      "            stream: Enable streaming output.\n",
      "            \n",
      "        Yields:\n",
      "            Text chunks for display.\n",
      "        \"\"\"\n",
      "        messages = []\n",
      "        # Add system prompt if this is the first message\n",
      "        if self.sys_prompt:\n",
      "            messages.append({\"role\": \"system\", \"content\": self.sys_prompt})\n",
      "        if history:\n",
      "            messages += history\n",
      "        \n",
      "        # Add user message\n",
      "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
      "        \n",
      "        # Tool call loop\n",
      "        for step in range(max_steps):\n",
      "            # Call LLM\n",
      "            response = litellm.completion(\n",
      "                model=self.model,\n",
      "                messages=messages,\n",
      "                tools=self.all_tools,\n",
      "                stream=stream\n",
      "            )\n",
      "                \n",
      "            # Accumulate response\n",
      "            assistant_content = \"\"\n",
      "            tool_calls = []\n",
      "            \n",
      "            if stream:\n",
      "                for chunk in response:\n",
      "                    delta = chunk.choices[0].delta\n",
      "                    \n",
      "                    # Stream text content\n",
      "                    if hasattr(delta, 'content') and delta.content:\n",
      "                        assistant_content += delta.content\n",
      "                        yield delta.content  \n",
      "                    \n",
      "                    # Accumulate tool calls\n",
      "                    if hasattr(delta, 'tool_calls') and delta.tool_calls:\n",
      "                        tc = delta.tool_calls[0]\n",
      "                        idx = tc.index\n",
      "                        \n",
      "                        # Extend tool_calls list if needed\n",
      "                        while len(tool_calls) <= idx:\n",
      "                            tool_calls.append({\n",
      "                                'id': None,\n",
      "                                'function': {'name': '', 'arguments': ''},\n",
      "                                'type': 'function'\n",
      "                            })\n",
      "                        \n",
      "                        if tc.id:\n",
      "                            tool_calls[idx]['id'] = tc.id\n",
      "                        if hasattr(tc.function, 'name') and tc.function.name:\n",
      "                            tool_calls[idx]['function']['name'] += tc.function.name\n",
      "                        if hasattr(tc.function, 'arguments') and tc.function.arguments:\n",
      "                            tool_calls[idx]['function']['arguments'] += tc.function.arguments\n",
      "            else:\n",
      "                # Non-streaming\n",
      "                message = response.choices[0].message\n",
      "                assistant_content = message.content or \"\"\n",
      "                yield assistant_content  # \n",
      "                \n",
      "                if message.tool_calls:\n",
      "                    tool_calls = [\n",
      "                        {\n",
      "                            'id': tc.id,\n",
      "                            'function': {\n",
      "                                'name': tc.function.name,\n",
      "                                'arguments': tc.function.arguments\n",
      "                            },\n",
      "                            'type': 'function'\n",
      "                        }\n",
      "                        for tc in message.tool_calls\n",
      "                    ]\n",
      "            \n",
      "            # Add assistant message to history\n",
      "            assistant_msg = {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": assistant_content or None\n",
      "            }\n",
      "            if tool_calls:\n",
      "                assistant_msg[\"tool_calls\"] = tool_calls\n",
      "\n",
      "            messages.append(assistant_msg)\n",
      "            \n",
      "            # If no tool calls, we're done\n",
      "            if not tool_calls:\n",
      "                break\n",
      "            \n",
      "            # Execute tools in Unreal\n",
      "            for tc in tool_calls:\n",
      "                func_name = tc['function']['name']\n",
      "                try:\n",
      "                    args = json.loads(tc['function']['arguments'])\n",
      "                except:\n",
      "                    args = {}\n",
      "                \n",
      "                yield f\"\\n\\nðŸ”§ Calling {func_name}({json.dumps(args)})...\\n\\n\"  \n",
      "                \n",
      "                # Call Unreal\n",
      "                result = self._execute_tool(func_name, args)\n",
      "                #yield f\"\\n\\n Result{result}...\\n\\n\"  #\n",
      "\n",
      "                # Add tool result to messages\n",
      "                messages.append({\n",
      "                    \"role\": \"tool\",\n",
      "                    \"tool_call_id\": tc['id'],\n",
      "                    \"content\": result\n",
      "                })\n",
      "    \n",
      "\n",
      "    \n",
      "    def refresh_tools(self):\n",
      "        \"\"\"Reload tools from Unreal (call after registering new tools).\"\"\"\n",
      "        self.tools = self._fetch_tools()\n",
      "\n",
      "\n",
      "def send_llm_request(prompt, history=None, use_ue_tools=False):\n",
      "    \"\"\"Stream LLM response with tool execution.\n",
      "    \n",
      "    Args:\n",
      "        prompt: User message.\n",
      "        history: Prior conversation messages.\n",
      "        \n",
      "    Yields:\n",
      "        Text chunks from LLM response.\n",
      "    \"\"\"\n",
      "    chat = RemoteToolLLM( model=MODEL,\n",
      "                          use_ue_tools=use_ue_tools)\n",
      "    \n",
      "    for chunk in chat.chat(prompt, history=history):\n",
      "        yield chunk\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/__init__.py\n",
      "============================================================\n",
      "__version__ = \"0.0.1\"\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/_modidx.py\n",
      "============================================================\n",
      "# Autogenerated by nbdev\n",
      "\n",
      "d = { 'settings': { 'branch': 'main',\n",
      "                'doc_baseurl': '/unreal-llm-sandbox',\n",
      "                'doc_host': 'https://NeuralVFX.github.io',\n",
      "                'git_url': 'https://github.com/NeuralVFX/unreal-llm-sandbox',\n",
      "                'lib_path': 'unreal_llm_sandbox'},\n",
      "  'syms': { 'unreal_llm_sandbox.agent': { 'unreal_llm_sandbox.agent.AgentTools': ('agent.html#agenttools', 'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.__init__': ( 'agent.html#agenttools.__init__',\n",
      "                                                                                            'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.chat_history_swap': ( 'agent.html#agenttools.chat_history_swap',\n",
      "                                                                                                     'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.collect': ( 'agent.html#agenttools.collect',\n",
      "                                                                                           'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.collect_llm_stream': ( 'agent.html#agenttools.collect_llm_stream',\n",
      "                                                                                                      'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.generate_code': ( 'agent.html#agenttools.generate_code',\n",
      "                                                                                                 'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.get_tools': ( 'agent.html#agenttools.get_tools',\n",
      "                                                                                             'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.improve_code': ( 'agent.html#agenttools.improve_code',\n",
      "                                                                                                'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.print_update': ( 'agent.html#agenttools.print_update',\n",
      "                                                                                                'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.read_url': ( 'agent.html#agenttools.read_url',\n",
      "                                                                                            'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.search_web': ( 'agent.html#agenttools.search_web',\n",
      "                                                                                              'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.unit_test': ( 'agent.html#agenttools.unit_test',\n",
      "                                                                                             'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.SentimentChecker': ( 'agent.html#sentimentchecker',\n",
      "                                                                                         'unreal_llm_sandbox/agent.py')},\n",
      "            'unreal_llm_sandbox.app_config': {},\n",
      "            'unreal_llm_sandbox.cells': { 'unreal_llm_sandbox.cells.BaseCell': ('cells.html#basecell', 'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.__init__': ( 'cells.html#basecell.__init__',\n",
      "                                                                                          'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell._make_markdown_init_script': ( 'cells.html#basecell._make_markdown_init_script',\n",
      "                                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_code_output': ( 'cells.html#basecell.build_code_output',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_left_buttons': ( 'cells.html#basecell.build_left_buttons',\n",
      "                                                                                                    'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_llm_output': ( 'cells.html#basecell.build_llm_output',\n",
      "                                                                                                  'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_markdown_source_area': ( 'cells.html#basecell.build_markdown_source_area',\n",
      "                                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_monaco_editor': ( 'cells.html#basecell.build_monaco_editor',\n",
      "                                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_output_area': ( 'cells.html#basecell.build_output_area',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_right_buttons': ( 'cells.html#basecell.build_right_buttons',\n",
      "                                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_source_area': ( 'cells.html#basecell.build_source_area',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_top_menu': ( 'cells.html#basecell.build_top_menu',\n",
      "                                                                                                'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.from_ipynb': ( 'cells.html#basecell.from_ipynb',\n",
      "                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.render': ( 'cells.html#basecell.render',\n",
      "                                                                                        'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.to_ipynb': ( 'cells.html#basecell.to_ipynb',\n",
      "                                                                                          'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell': ('cells.html#codecell', 'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.build_left_buttons': ( 'cells.html#codecell.build_left_buttons',\n",
      "                                                                                                    'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.build_output_area': ( 'cells.html#codecell.build_output_area',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.build_source_area': ( 'cells.html#codecell.build_source_area',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.from_ipynb': ( 'cells.html#codecell.from_ipynb',\n",
      "                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.render': ( 'cells.html#codecell.render',\n",
      "                                                                                        'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.to_ipynb': ( 'cells.html#codecell.to_ipynb',\n",
      "                                                                                          'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell': ( 'cells.html#markdowncell',\n",
      "                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell.build_left_buttons': ( 'cells.html#markdowncell.build_left_buttons',\n",
      "                                                                                                        'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell.from_ipynb': ( 'cells.html#markdowncell.from_ipynb',\n",
      "                                                                                                'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell.render': ( 'cells.html#markdowncell.render',\n",
      "                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell.to_ipynb': ( 'cells.html#markdowncell.to_ipynb',\n",
      "                                                                                              'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell': ('cells.html#promptcell', 'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.build_left_buttons': ( 'cells.html#promptcell.build_left_buttons',\n",
      "                                                                                                      'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.build_output_area': ( 'cells.html#promptcell.build_output_area',\n",
      "                                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.from_ipynb': ( 'cells.html#promptcell.from_ipynb',\n",
      "                                                                                              'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.render': ( 'cells.html#promptcell.render',\n",
      "                                                                                          'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.to_ipynb': ( 'cells.html#promptcell.to_ipynb',\n",
      "                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.interrupt_button': ( 'cells.html#interrupt_button',\n",
      "                                                                                         'unreal_llm_sandbox/cells.py')},\n",
      "            'unreal_llm_sandbox.kernel': { 'unreal_llm_sandbox.kernel.convert_to_accumulated': ( 'kernel.html#convert_to_accumulated',\n",
      "                                                                                                 'unreal_llm_sandbox/kernel.py'),\n",
      "                                           'unreal_llm_sandbox.kernel.execute_unreal_code': ( 'kernel.html#execute_unreal_code',\n",
      "                                                                                              'unreal_llm_sandbox/kernel.py'),\n",
      "                                           'unreal_llm_sandbox.kernel.format_kernel_stream': ( 'kernel.html#format_kernel_stream',\n",
      "                                                                                               'unreal_llm_sandbox/kernel.py'),\n",
      "                                           'unreal_llm_sandbox.kernel.strip_ansi': ( 'kernel.html#strip_ansi',\n",
      "                                                                                     'unreal_llm_sandbox/kernel.py')},\n",
      "            'unreal_llm_sandbox.llm': { 'unreal_llm_sandbox.llm.RemoteToolLLM': ('llm.html#remotetoolllm', 'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.RemoteToolLLM.__init__': ( 'llm.html#remotetoolllm.__init__',\n",
      "                                                                                           'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.RemoteToolLLM._execute_tool': ( 'llm.html#remotetoolllm._execute_tool',\n",
      "                                                                                                'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.RemoteToolLLM._fetch_local_tools': ( 'llm.html#remotetoolllm._fetch_local_tools',\n",
      "                                                                                                     'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.RemoteToolLLM._fetch_tools': ( 'llm.html#remotetoolllm._fetch_tools',\n",
      "                                                                                               'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.RemoteToolLLM.chat': ( 'llm.html#remotetoolllm.chat',\n",
      "                                                                                       'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.RemoteToolLLM.refresh_tools': ( 'llm.html#remotetoolllm.refresh_tools',\n",
      "                                                                                                'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.send_llm_request': ( 'llm.html#send_llm_request',\n",
      "                                                                                     'unreal_llm_sandbox/llm.py')},\n",
      "            'unreal_llm_sandbox.llm_tools': { 'unreal_llm_sandbox.llm_tools.get_tools': ( 'llm_tools.html#get_tools',\n",
      "                                                                                          'unreal_llm_sandbox/llm_tools.py'),\n",
      "                                              'unreal_llm_sandbox.llm_tools.read_url': ( 'llm_tools.html#read_url',\n",
      "                                                                                         'unreal_llm_sandbox/llm_tools.py'),\n",
      "                                              'unreal_llm_sandbox.llm_tools.register_tool': ( 'llm_tools.html#register_tool',\n",
      "                                                                                              'unreal_llm_sandbox/llm_tools.py'),\n",
      "                                              'unreal_llm_sandbox.llm_tools.search_web': ( 'llm_tools.html#search_web',\n",
      "                                                                                           'unreal_llm_sandbox/llm_tools.py')},\n",
      "            'unreal_llm_sandbox.main': { 'unreal_llm_sandbox.main.Toolbar': ('main.html#toolbar', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.add_cell': ('main.html#add_cell', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.exe_code': ('main.html#exe_code', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.exe_prompt': ('main.html#exe_prompt', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.get_static': ('main.html#get_static', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.interrupt': ('main.html#interrupt', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.load_notebook': ('main.html#load_notebook', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.save_notebook': ('main.html#save_notebook', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.start_server': ('main.html#start_server', 'unreal_llm_sandbox/main.py')},\n",
      "            'unreal_llm_sandbox.notebook_io': { 'unreal_llm_sandbox.notebook_io.format_for_chat': ( 'notebook_io.html#format_for_chat',\n",
      "                                                                                                    'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.is_ask_cell': ( 'notebook_io.html#is_ask_cell',\n",
      "                                                                                                'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prep_code_cell': ( 'notebook_io.html#prep_code_cell',\n",
      "                                                                                                   'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prep_code_cell_output': ( 'notebook_io.html#prep_code_cell_output',\n",
      "                                                                                                          'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prep_markdown_cell': ( 'notebook_io.html#prep_markdown_cell',\n",
      "                                                                                                       'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prep_prompt_cell': ( 'notebook_io.html#prep_prompt_cell',\n",
      "                                                                                                     'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prepare_chat_history': ( 'notebook_io.html#prepare_chat_history',\n",
      "                                                                                                         'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.reconstruct_cells_from_history': ( 'notebook_io.html#reconstruct_cells_from_history',\n",
      "                                                                                                                   'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.reconstruct_ipynb_cell': ( 'notebook_io.html#reconstruct_ipynb_cell',\n",
      "                                                                                                           'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.seperate_markdown': ( 'notebook_io.html#seperate_markdown',\n",
      "                                                                                                      'unreal_llm_sandbox/notebook_io.py')},\n",
      "            'unreal_llm_sandbox.streaming': { 'unreal_llm_sandbox.streaming.SSEStream': ( 'streaming.html#ssestream',\n",
      "                                                                                          'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.__init__': ( 'streaming.html#ssestream.__init__',\n",
      "                                                                                                   'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.aborted': ( 'streaming.html#ssestream.aborted',\n",
      "                                                                                                  'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.cleanup': ( 'streaming.html#ssestream.cleanup',\n",
      "                                                                                                  'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.done': ( 'streaming.html#ssestream.done',\n",
      "                                                                                               'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.output': ( 'streaming.html#ssestream.output',\n",
      "                                                                                                 'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.response': ( 'streaming.html#ssestream.response',\n",
      "                                                                                                   'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.tag': ( 'streaming.html#ssestream.tag',\n",
      "                                                                                              'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.text': ( 'streaming.html#ssestream.text',\n",
      "                                                                                               'unreal_llm_sandbox/streaming.py')}}}\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/main.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/main.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['daisy_hdrs', 'app', 'rt', 'get_static', 'interrupt', 'exe_prompt', 'exe_code', 'Toolbar', 'add_cell', 'load_notebook',\n",
      "           'save_notebook', 'start_server']\n",
      "\n",
      "# %% ../nbs/main.ipynb 3\n",
      "import json\n",
      "import asyncio\n",
      "import requests\n",
      "import lisette\n",
      "import time\n",
      "\n",
      "from fasthtml.common import *\n",
      "from fasthtml.jupyter import JupyUvi\n",
      "from starlette.staticfiles import StaticFiles\n",
      "\n",
      "from .app_config import MODEL, KERNEL_URL, NOTEBOOK_SYS_PROMPT\n",
      "from .cells import MarkdownCell, CodeCell, PromptCell #, AgentCell\n",
      "from .streaming import SSEStream, active_streams\n",
      "from .kernel import execute_unreal_code, convert_to_accumulated\n",
      "from .notebook_io import reconstruct_cells_from_history, prepare_chat_history, reconstruct_ipynb_cell\n",
      "from .llm import RemoteToolLLM, send_llm_request\n",
      "#from unreal_llm_sandbox.agent import AgentTools, SYS_PROMPT\n",
      "\n",
      "from fasthtml.common import *\n",
      "import importlib.resources\n",
      "import unreal_llm_sandbox\n",
      "\n",
      "# 1. Helper function to read the text content of your files\n",
      "def get_static(fname, icon=False):\n",
      "    \"\"\"Read static file content from package resources.\n",
      "    \n",
      "    Args:\n",
      "        fname: Filename to read from unreal_llm_sandbox/static/.\n",
      "        \n",
      "    Returns:\n",
      "        String content of the file.\n",
      "    \"\"\"\n",
      "    ref = importlib.resources.files(unreal_llm_sandbox) / 'static' / fname\n",
      "    if icon:\n",
      "        icon_bytes = (importlib.resources.files(unreal_llm_sandbox) / 'static' / 'Icon128.png').read_bytes()\n",
      "        return base64.b64encode(icon_bytes).decode()\n",
      "    else:\n",
      "        return ref.read_text(encoding='utf-8')\n",
      "\n",
      "\n",
      "# Then in headers:\n",
      "daisy_hdrs =[\n",
      "Link(rel=\"icon\", href=f\"data:image/png;base64,{get_static('Icon32.png',icon=True)}\"),\n",
      "Link(href='https://cdn.jsdelivr.net/npm/daisyui@5', rel='stylesheet', type='text/css'),\n",
      "Script(src='https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4'),\n",
      "Link(rel=\"stylesheet\", href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css\"),\n",
      "Link(rel=\"stylesheet\", href=\"https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.5.1/github-markdown.min.css\"),\n",
      "Script (src ='https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js'),\n",
      "Script (src ='https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js'),\n",
      "Script(src='https://cdn.jsdelivr.net/npm/marked/marked.min.js'),\n",
      "Script(get_static('cells.js')),\n",
      "Script(src=\"https://cdn.jsdelivr.net/npm/ansi_up@5/ansi_up.min.js\"),\n",
      "Script(src=\"https://cdn.jsdelivr.net/npm/monaco-editor@latest/min/vs/loader.js\"),\n",
      "Script(\"\"\"\n",
      "require.config({ paths: { 'vs': 'https://cdn.jsdelivr.net/npm/monaco-editor@latest/min/vs' }});\n",
      "\"\"\"),\n",
      "Script(src=\"https://unpkg.com/htmx.org/dist/ext/sse.js\")]\n",
      "\n",
      "\n",
      "# FastHTML app setup + daisy_hdrs (the big Style/Script list)\n",
      "app = FastHTML(hdrs=daisy_hdrs)\n",
      "\n",
      "\n",
      "rt = app.route\n",
      "\n",
      "\n",
      "# %% ../nbs/main.ipynb 4\n",
      "@rt('/interrupt/{cell_id}', methods=['POST'])\n",
      "async def interrupt(cell_id: str, request):\n",
      "    \"\"\"Signal abort for an active stream.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique cell identifier.\n",
      "    \n",
      "    Returns:\n",
      "        \"OK\" acknowledgment string.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        data = await request.json()\n",
      "        notebook = data.get('notebook', 'untitled')\n",
      "    except:\n",
      "        notebook = 'untitled'\n",
      "    stream_key = f\"{notebook}:{cell_id}\"\n",
      "    if stream_key in active_streams:\n",
      "        active_streams[stream_key]['abort'] = True\n",
      "    return \"OK\"\n",
      "    \n",
      "\n",
      "# %% ../nbs/main.ipynb 5\n",
      "@rt('/execute_prompt/{cell_id}')\n",
      "async def exe_prompt(cell_id: str, request): \n",
      "    \"\"\"Execute LLM prompt with notebook context via SSE.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique cell identifier.\n",
      "        request: FastHTML request with JSON body containing:\n",
      "            - prompt: User's prompt text.\n",
      "            - context: List of cell dicts for history.\n",
      "    \n",
      "    Returns:\n",
      "        SSE StreamingResponse yielding LLM chunks.\n",
      "    \"\"\"\n",
      "\n",
      "    data = await request.json() \n",
      "\n",
      "    notebook = data.get('notebook', 'untitled')\n",
      "    \n",
      "    stream_key = f\"{notebook}:{cell_id}\" \n",
      "\n",
      "    prompt = data['prompt']\n",
      "    cell_dict_list = data.get('context', [])\n",
      "    use_tools = data.get('use_tools', True) \n",
      "\n",
      "    cells = reconstruct_cells_from_history(cell_dict_list)\n",
      "    ipynb_list = [cell.to_ipynb() for cell in cells]\n",
      "    chat_history = prepare_chat_history(ipynb_list)\n",
      "    \n",
      "    stream = SSEStream(stream_key)\n",
      "    \n",
      "    def run():\n",
      "        for msg in send_llm_request(prompt, history=chat_history, use_ue_tools=use_tools):\n",
      "            if stream.aborted(): break\n",
      "            stream.text(msg)\n",
      "        stream.done()\n",
      "    \n",
      "    asyncio.create_task(asyncio.to_thread(run))\n",
      "    return stream.response()\n",
      "\n",
      "\n",
      "# %% ../nbs/main.ipynb 6\n",
      "@rt('/execute_code/{cell_id}')\n",
      "async def exe_code(cell_id: str, request):\n",
      "    \"\"\"Execute Python code in Unreal Engine via SSE.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique cell identifier.\n",
      "        request: FastHTML request with JSON body containing:\n",
      "            - code: Python code string to execute.\n",
      "    \n",
      "    Returns:\n",
      "        SSE StreamingResponse yielding kernel output messages.\n",
      "    \"\"\"\n",
      "\n",
      "    data = await request.json()\n",
      "    notebook = data.get('notebook', 'untitled')\n",
      "    stream_key = f\"{notebook}:{cell_id}\" \n",
      "\n",
      "    stream = SSEStream(stream_key)\n",
      "    \n",
      "    def run():\n",
      "        response = requests.post(f'{KERNEL_URL}/execute', json={'code': data['code']}, stream=True, timeout=(5, 60))\n",
      "        for line in response.iter_lines():\n",
      "            if stream.aborted(): break\n",
      "            if line.startswith(b'data: '):\n",
      "                stream.output(json.loads(line[6:]))  # â† output() not raw()\n",
      "        stream.done()\n",
      "    \n",
      "    asyncio.create_task(asyncio.to_thread(run))\n",
      "    return stream.response()\n",
      "\n",
      "\n",
      "# %% ../nbs/main.ipynb 8\n",
      "def Toolbar(title):\n",
      "    \"\"\"Build the notebook toolbar with cell creation buttons.\n",
      "    \n",
      "    Args:\n",
      "        title: Notebook name to display in the editable input.\n",
      "        \n",
      "    Returns:\n",
      "        FastHTML Div containing toolbar elements.\n",
      "    \"\"\"\n",
      "    return Div(\n",
      "\n",
      "        Div(\n",
      "            Input(value=title, cls=\"text-xl font-bold text-white notebook-name bg-transparent border-none outline-none focus:outline-none flex-1\"),\n",
      "            Script(\"\"\"\n",
      "                document.querySelector('.notebook-name').addEventListener('blur', (e) => {\n",
      "                    const name = e.target.value || 'untitled';\n",
      "                    history.replaceState(null, '', `/notebook/${name}.ipynb`);\n",
      "                });\n",
      "            \"\"\"),\n",
      "            cls=\"flex flex-1 items-center\"\n",
      "        ),\n",
      "        Div(\n",
      "            Button(\"âž• Markdown\", \n",
      "                   hx_post=\"/add_cell/markdown\",\n",
      "                   hx_target=\"#notebook-container\",\n",
      "                   hx_swap=\"beforeend\",\n",
      "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"), \n",
      "            Button(\"âž• Code\", \n",
      "                   hx_post=\"/add_cell/code\",\n",
      "                   hx_target=\"#notebook-container\",\n",
      "                   hx_swap=\"beforeend\",\n",
      "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"),  \n",
      "            Button(\"âž• Prompt\", \n",
      "                   hx_post=\"/add_cell/prompt\",\n",
      "                   hx_target=\"#notebook-container\",\n",
      "                   hx_swap=\"beforeend\",\n",
      "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"),  \n",
      "            #Button(\"âž• Agent\", \n",
      "            #       hx_post=\"/add_cell/agent\",\n",
      "            #       hx_target=\"#notebook-container\",\n",
      "            #       hx_swap=\"beforeend\",\n",
      "            #       cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"), \n",
      "            cls=\"flex gap-2\"\n",
      "        ),\n",
      "        cls=\"flex justify-between p-4 bg-[#0d0d0d]\"  # â† Changed from #0d0d0d to pure black\n",
      "    )\n",
      "\n",
      "@rt('/add_cell/{cell_type}')\n",
      "def add_cell(cell_type: str):\n",
      "    \"\"\"Create and return a new cell of the specified type.\n",
      "    \n",
      "    Args:\n",
      "        cell_type: One of 'markdown', 'code', 'prompt', or 'agent'.\n",
      "        \n",
      "    Returns:\n",
      "        Rendered FastHTML cell component.\n",
      "    \"\"\"\n",
      "    if cell_type == 'markdown':\n",
      "        new_cell = MarkdownCell(\"\")\n",
      "    elif cell_type == 'code':\n",
      "        new_cell = CodeCell(\"\")\n",
      "    elif cell_type == 'prompt':\n",
      "        new_cell = PromptCell(\"\")\n",
      "    #elif cell_type == 'agent':\n",
      "    #    new_cell = AgentCell(\"\")\n",
      "    else:\n",
      "        return \"Invalid cell type\"\n",
      "    \n",
      "    return new_cell.render()\n",
      "\n",
      "\n",
      "# %% ../nbs/main.ipynb 9\n",
      "@rt('/notebook/{notebook_file}')\n",
      "def load_notebook(notebook_file:str): \n",
      "    \"\"\"Load a Jupyter Notebook file and render its cells.\n",
      "    \n",
      "    Args:\n",
      "        notebook_file: Path to .ipynb file to load.\n",
      "        \n",
      "    Returns:\n",
      "        Tuple of Title and Body elements for the page.\n",
      "    \"\"\"\n",
      "    if not os.path.exists(notebook_file):\n",
      "        rendered_cells = []\n",
      "        print ('Notebook Not Found:',notebook_file)\n",
      "\n",
      "    else:\n",
      "        cells = []\n",
      "        with open(notebook_file, 'r', encoding='utf-8') as f:\n",
      "            notebook = json.load(f)\n",
      "            cells = notebook['cells']\n",
      "        \n",
      "        cell_objects = [reconstruct_ipynb_cell(cell) for cell in cells]\n",
      "        rendered_cells = [cell.render() for cell in cell_objects]\n",
      "\n",
      "\n",
      "    return Title(\"Unreal LLM Sandbox\"),Body(\n",
      "        Toolbar(notebook_file.split('.ipynb')[0]),\n",
      "        Style(get_static('styles.css')),\n",
      "        Div(  *rendered_cells,\n",
      "            cls='px-5',  \n",
      "            id='notebook-container' \n",
      "        )\n",
      "    )\n",
      "\n",
      "@rt('/save_notebook/{notebook_file}', methods=['POST'])\n",
      "async def save_notebook(notebook_file: str, request):\n",
      "    \"\"\"Save notebook cells to a Jupyter .ipynb file.\n",
      "    \n",
      "    Args:\n",
      "        notebook_file: Filename to save to.\n",
      "        request: Request with JSON body containing 'cells' list.\n",
      "    \n",
      "    Returns:\n",
      "        JSON with status message.\n",
      "    \"\"\"\n",
      "    data = await request.json()\n",
      "    cell_dict_list = data.get('cells', [])\n",
      "    \n",
      "    # Reconstruct cell objects and convert to ipynb format\n",
      "    cells = reconstruct_cells_from_history(cell_dict_list)\n",
      "    ipynb_cells = [cell.to_ipynb() for cell in cells]\n",
      "    \n",
      "    # Build notebook structure\n",
      "    notebook = {\n",
      "        \"nbformat\": 4,\n",
      "        \"nbformat_minor\": 5,\n",
      "        \"metadata\": {\n",
      "            \"kernelspec\": {\n",
      "                \"display_name\": \"Python 3\",\n",
      "                \"language\": \"python\",\n",
      "                \"name\": \"python3\"\n",
      "            }\n",
      "        },\n",
      "        \"cells\": ipynb_cells\n",
      "    }\n",
      "    \n",
      "    with open(notebook_file, 'w', encoding='utf-8') as f:\n",
      "        json.dump(notebook, f, indent=2, ensure_ascii=False)\n",
      "    \n",
      "    return {\"status\": \"saved\", \"file\": notebook_file}\n",
      "    \n",
      "\n",
      "# %% ../nbs/main.ipynb 10\n",
      "import uvicorn\n",
      "\n",
      "def start_server():\n",
      "    uvicorn.run(app,\n",
      "                 host='0.0.0.0',\n",
      "                 port=5001, \n",
      "                 timeout_graceful_shutdown=1)\n",
      "\n",
      "# %% ../nbs/main.ipynb 12\n",
      "#| eval: false\n",
      "if __name__ == \"__main__\":\n",
      "    start_server()\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/kernel.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/kernel.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['strip_ansi', 'format_kernel_stream', 'execute_unreal_code', 'convert_to_accumulated']\n",
      "\n",
      "# %% ../nbs/kernel.ipynb 3\n",
      "import re\n",
      "import copy\n",
      "import requests\n",
      "\n",
      "from .app_config import KERNEL_URL\n",
      "\n",
      "\n",
      "# %% ../nbs/kernel.ipynb 4\n",
      "def strip_ansi(text):\n",
      "    \"\"\"Remove ANSI escape codes from text.\n",
      "    \n",
      "    Args:\n",
      "        text: String potentially containing ANSI color/formatting codes.\n",
      "        \n",
      "    Returns:\n",
      "        String with all ANSI escape sequences removed.\n",
      "    \"\"\"\n",
      "    return re.sub(r'\\x1b\\[[0-9;]*m', '', text)\n",
      "    \n",
      "\n",
      "def format_kernel_stream(json_response, clean_ansi=True ):\n",
      "    \"\"\"Format raw kernel response into clean, consolidated messages.\n",
      "    \n",
      "    Merges consecutive stream messages of the same type and optionally\n",
      "    strips ANSI codes from error tracebacks.\n",
      "    \n",
      "    Args:\n",
      "        json_response: Dict with 'messages' key containing kernel output.\n",
      "        clean_ansi: If True, remove ANSI codes from tracebacks.\n",
      "        \n",
      "    Returns:\n",
      "        List of formatted message dicts with consolidated streams.\n",
      "    \"\"\"    \n",
      "    formatted_response = []\n",
      "    prev_name = None\n",
      "    prev_type = None\n",
      "    \n",
      "    for msg in json_response.get('messages', []):\n",
      "        msg_copy = copy.deepcopy(msg)\n",
      "        \n",
      "        if msg['msg_type'] == 'error':\n",
      "            if clean_ansi:\n",
      "                tb = msg_copy['content']['traceback']\n",
      "                msg_copy['content']['traceback'] = ['\\n'.join([strip_ansi(line) for line in tb])]\n",
      "\n",
      "        appended = False\n",
      "        if msg['msg_type'] == 'stream':\n",
      "            if prev_type == msg['msg_type'] and prev_name == msg['content']['name']:\n",
      "                formatted_response[-1]['content']['text'] += msg['content']['text']\n",
      "                appended = True\n",
      "\n",
      "        if not appended:\n",
      "            formatted_response.append(msg_copy)\n",
      "\n",
      "        prev_type = msg['msg_type']\n",
      "        if msg['msg_type'] == 'stream':\n",
      "            prev_name = msg['content']['name']\n",
      "\n",
      "    return formatted_response\n",
      "\n",
      "\n",
      "def execute_unreal_code(code):\n",
      "    \"\"\" \n",
      "    Execute Python code in the Unreal Engine kernel via ngrok.\n",
      "    \n",
      "    Args:\n",
      "        code (str): Python code to execute in Unreal\n",
      "        \n",
      "    Returns:\n",
      "        list: Formatted kernel messages containing:\n",
      "            - 'stream' messages with stdout/stderr output\n",
      "            - 'error' messages with exception name, value, and cleaned traceback\n",
      "    \"\"\"\n",
      "    \n",
      "    try:\n",
      "        response = requests.post(\n",
      "            f'{KERNEL_URL}/execute_sync',\n",
      "            json={'code': code},\n",
      "            timeout=30\n",
      "        )\n",
      "        json_response = response.json()\n",
      "\n",
      "    except (requests.RequestException, requests.Timeout) as e:\n",
      "        # Return error in same format as kernel errors\n",
      "        error_msg = [{\"msg_type\": \"error\", \"content\": {\"ename\": \"KernelError\", \"evalue\": str(e), \"traceback\": []}}]\n",
      "        return error_msg, error_msg\n",
      "\n",
      "    print (json_response)\n",
      "    return format_kernel_stream(json_response), format_kernel_stream(json_response,clean_ansi=False)\n",
      "\n",
      "def convert_to_accumulated(json_response):\n",
      "    \"\"\"\n",
      "    Convert Python kernel response messages to JavaScript accumulated output format.\n",
      "    \n",
      "    Transforms a list of Jupyter kernel messages into the format expected by the\n",
      "    frontend's output rendering system. Merges consecutive stream outputs of the\n",
      "    same type (stdout/stderr).\n",
      "    \n",
      "    Args:\n",
      "        json_response: List of dicts with 'msg_type' and 'content' keys from unreal_llm_sandbox.kernel.\n",
      "    \n",
      "    Returns:\n",
      "        List of accumulated output dicts with 'output_type' and type-specific fields.\n",
      "    \"\"\"\n",
      "    accumulated = []\n",
      "    for msg in json_response:\n",
      "        t = msg['msg_type']\n",
      "        c = msg['content']\n",
      "        if t == 'stream':\n",
      "            # Check if we can merge with previous\n",
      "            if accumulated and accumulated[-1].get('output_type') == 'stream' and accumulated[-1].get('name') == c['name']:\n",
      "                accumulated[-1]['text'].append(c['text'])\n",
      "            else:\n",
      "                accumulated.append({'output_type': 'stream',\n",
      "                                    'name': c['name'],\n",
      "                                    'text': [c['text']]})\n",
      "        elif t == 'execute_result':\n",
      "            accumulated.append({'output_type': 'execute_result',\n",
      "                                 'data': c['data'],\n",
      "                                 'execution_count': c.get('execution_count')})\n",
      "        elif t == 'error':\n",
      "            accumulated.append({'output_type': 'error', \n",
      "                                'ename': c['ename'],\n",
      "                                'evalue': c['evalue'],\n",
      "                                'traceback': c['traceback']})\n",
      "    return accumulated\n",
      "    \n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/llm_tools.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/llm_tools.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['TOOLS', 'TOOL_SCHEMAS', 'get_tools', 'register_tool', 'search_web', 'read_url']\n",
      "\n",
      "# %% ../nbs/llm_tools.ipynb 3\n",
      "import requests\n",
      "import litellm\n",
      "import json\n",
      "from lisette import lite_mk_func\n",
      "\n",
      "TOOLS = {}\n",
      "TOOL_SCHEMAS = []\n",
      "\n",
      "\n",
      "def get_tools():\n",
      "    \"\"\"Return available tool schemas.\"\"\"\n",
      "    return TOOL_SCHEMAS\n",
      "\n",
      "\n",
      "def register_tool(func):\n",
      "    \"\"\"Register a function as a tool.\"\"\"\n",
      "    TOOLS[func.__name__] = func\n",
      "    schema = lite_mk_func(func)\n",
      "    # Remove old schema if exists\n",
      "    TOOL_SCHEMAS[:] = [s for s in TOOL_SCHEMAS if s['function']['name'] != func.__name__]\n",
      "    TOOL_SCHEMAS.append(schema)\n",
      "    return func\n",
      "\n",
      "\n",
      "@register_tool\n",
      "def search_web(query: str, max_results: int = 10):\n",
      "    \"\"\"Search DuckDuckGo and return top results.\n",
      "    \n",
      "    Args:\n",
      "        query: Search string.\n",
      "        max_results: Maximum number of results to return.\n",
      "        \n",
      "    Returns:\n",
      "        JSON string of results with title, url, snippet.\n",
      "    \"\"\"    \n",
      "    from ddgs import DDGS\n",
      "    \n",
      "    results = DDGS().text(query, max_results=max_results)\n",
      "    return str([{\"title\": r[\"title\"], \"url\": r[\"href\"], \"snippet\": r[\"body\"]} \n",
      "            for r in results])\n",
      "\n",
      "\n",
      "@register_tool\n",
      "def read_url(url:str):\n",
      "    \"\"\"Retrieve webpage HTML content.\n",
      "    \n",
      "    Args:\n",
      "        url: URL to fetch.\n",
      "        \n",
      "    Returns:\n",
      "        Raw HTML string.\n",
      "    \"\"\"    \n",
      "    import requests\n",
      "    response = requests.get(url)\n",
      "    html = response.text\n",
      "    return html\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/app_config.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/app_config.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['KERNEL_URL', 'MODEL', 'PROMPT_SPLIT', 'NOTEBOOK_SYS_PROMPT', 'UE_TOOL_SYS_PROMPT']\n",
      "\n",
      "# %% ../nbs/app_config.ipynb 3\n",
      "KERNEL_URL = 'http://localhost:8765'\n",
      "MODEL = 'gpt-5.2'\n",
      "\n",
      "PROMPT_SPLIT = '\\n\\n##### LLM Response: <!-- LLM -->\\n\\n'\n",
      "\n",
      "NOTEBOOK_SYS_PROMPT = \"\"\"You are an AI assistant, your goal is to help the user build tools.\\n\n",
      "You're in a Jupyter Notebook, which is connected to Unreal Engine 5.6.\\n\n",
      "The users programming language of choice is python.\\n\n",
      "You can search the internet if unsure about an Unreal function\\n\"\"\"\n",
      "\n",
      "UE_TOOL_SYS_PROMPT = \"\"\"You are an AI assistant in a Jupyter Notebook.\\n\n",
      "The TOOLS you have run in Unreal Engine.\\n\n",
      "Your goal is to use TOOLS to:\n",
      "A) Modify the Unreal Scene.\\n\n",
      "or..\n",
      "B) Answer questions ab out the Unreal Scene.\\n\n",
      "**Use the TOOLS** provided to you to accomplish the task.\\n\n",
      "Dont respond by generating blocks of code.\\n\"\"\"\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/agent.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/agent.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['SentimentChecker', 'AgentTools']\n",
      "\n",
      "# %% ../nbs/agent.ipynb 3\n",
      "from dataclasses import dataclass\n",
      "import requests\n",
      "from ddgs import DDGS\n",
      "import lisette\n",
      "\n",
      "from unreal_llm_sandbox.app_config import (\n",
      "    KERNEL_URL, MODEL, NOTEBOOK_SYS_PROMPT, SYS_PROMPT,\n",
      "    CODE_GENERATOR, CODE_IMPROVER, UNIT_TEST_STR, SYS_CODER, SYS_REVIEW\n",
      ")\n",
      "from .kernel import *\n",
      "\n",
      "\n",
      "# %% ../nbs/agent.ipynb 4\n",
      "@dataclass\n",
      "class SentimentChecker:\n",
      "    \"\"\" Use this tool register whether you think the code review your looking at approved\\n\n",
      "    \"\"\"\n",
      "    approved: bool\n",
      "    \n",
      "\n",
      "# %% ../nbs/agent.ipynb 5\n",
      "class AgentTools():\n",
      "    def __init__(self, stream, chat, prompt, cell_id, code = '', print_updates = False):\n",
      "        \"\"\"Initialize agent tools.\n",
      "        \n",
      "        Args:\n",
      "            stream: SSEStream for output to GUI.\n",
      "            chat: LLM chat instance.\n",
      "            prompt: User's code generation request.\n",
      "            cell_id: Unique cell identifier.\n",
      "            code: Existing code to improve.\n",
      "            print_updates: Enable debug printing.\n",
      "        \"\"\"\n",
      "        self.chat = chat\n",
      "        self.code = code\n",
      "        self.prompt = prompt\n",
      "        self.cell_id = cell_id\n",
      "        self.print_updates = print_updates\n",
      "        self.stream = stream\n",
      "\n",
      "    def print_update(self, text):\n",
      "        \"\"\"Print debug message if updates enabled.\"\"\"\n",
      "        if self.print_updates:\n",
      "            print(text)\n",
      "\n",
      "    def collect(self, piece, dtype='text'):\n",
      "        \"\"\"Send output to GUI stream.\n",
      "        \n",
      "        Args:\n",
      "            piece: Content to send.\n",
      "            dtype: One of 'text', 'tag', or 'output'.\n",
      "        \"\"\"\n",
      "        if dtype == 'text':\n",
      "            self.stream.text(piece)\n",
      "        elif dtype == 'tag':\n",
      "            self.stream.tag(piece)\n",
      "        elif dtype == 'output':\n",
      "            self.stream.output(piece)\n",
      "\n",
      "    def chat_history_swap(self,new_sys,step_prompt):\n",
      "        \"\"\"Get LLM response with temporary system prompt.\n",
      "        \n",
      "        Args:\n",
      "            new_sys: Temporary system prompt.\n",
      "            step_prompt: Prompt for this step.\n",
      "        \n",
      "        Returns:\n",
      "            Collected response text.\n",
      "        \"\"\"\n",
      "        old_sys = self.chat.sp\n",
      "        self.chat.sp = new_sys\n",
      "        old_hist = self.chat.hist[:]\n",
      "        \n",
      "        response = self.chat(step_prompt,stream=True)\n",
      "        collected_stream = self.collect_llm_stream(response)\n",
      "        \n",
      "        self.chat.sp = old_sys\n",
      "        self.chat.hist = old_hist\n",
      "        return collected_stream\n",
      "\n",
      "    def collect_llm_stream(self,response):\n",
      "        \"\"\"Stream LLM chunks to GUI.\n",
      "        \n",
      "        Args:\n",
      "            response: LLM streaming response.\n",
      "        \n",
      "        Returns:\n",
      "            Full accumulated text.\n",
      "        \"\"\"\n",
      "        raw = ''\n",
      "        for piece in response:\n",
      "            if self.stream.aborted():  \n",
      "                break\n",
      "            if hasattr(piece, 'choices'):\n",
      "                if hasattr(piece.choices[0], 'delta'):\n",
      "                    if hasattr(piece.choices[0].delta, 'content'):\n",
      "                        crumb = piece.choices[0].delta.content\n",
      "                        if crumb:\n",
      "                            raw += crumb\n",
      "                            self.collect(crumb)\n",
      "        return raw\n",
      "\n",
      "    def search_web(self, query: str, max_results: int = 5):\n",
      "        \"\"\"Search DuckDuckGo for query.\n",
      "        \n",
      "        Args:\n",
      "            query: Search string.\n",
      "            max_results: Max results to return.\n",
      "        \"\"\"\n",
      "        from ddgs import DDGS\n",
      "        self.print_update('Searching Web\\n')\n",
      "        self.collect('tool-websearch',dtype='tag')\n",
      "\n",
      "        results = DDGS().text(query, max_results=max_results)\n",
      "    \n",
      "        snippet = str([{\"title\": r[\"title\"], \"url\": r[\"href\"], \"snippet\": r[\"body\"]} \n",
      "                for r in results])\n",
      "        result = str({'step':'SearchWeb','code':snippet})\n",
      "        self.chat.hist.append({\"role\":\"assistant\",\"content\":result})\n",
      "        return \n",
      "\n",
      "\n",
      "    def read_url(self, url:str):\n",
      "        \"\"\"Fetch webpage content.\n",
      "        \n",
      "        Args:\n",
      "            url: URL to retrieve.\n",
      "        \n",
      "        Returns:\n",
      "            HTML content.\n",
      "        \"\"\"\n",
      "        import requests\n",
      "        self.print_update('Loading URL\\n')\n",
      "        self.collect('tool-readurl',dtype='tag')\n",
      "\n",
      "        response = requests.get(url)\n",
      "        html = response.text\n",
      "\n",
      "        result = str({'step':'ReadUrl','code':html})\n",
      "        self.chat.hist.append({\"role\":\"assistant\",\"content\":result})\n",
      "        return html\n",
      "\n",
      "\n",
      "    def improve_code(self):\n",
      "        \"\"\"Improve existing code based on unit test feedback. Returns improved code.\"\"\"\n",
      "        self.print_update('Improving Code\\n')\n",
      "        self.collect('code-box',dtype='tag')\n",
      "\n",
      "        raw_code = self.chat_history_swap(SYS_CODER,CODE_IMPROVER)\n",
      "        self.code = raw_code\n",
      "\n",
      "        result = str({'step':'CodeImprovment','code':self.code})\n",
      "        self.chat.hist.append({\"role\":\"user\",\"content\":result})\n",
      "\n",
      "        return result\n",
      "\n",
      "\n",
      "    def generate_code(self):\n",
      "        \"\"\"Generate initial code and unit test for the given prompt. Returns generated code.\"\"\"\n",
      "        self.print_update('Generating Code\\n')\n",
      "        self.collect('code-box>',dtype='tag')\n",
      "\n",
      "        raw_code = self.chat_history_swap(SYS_CODER,CODE_GENERATOR)\n",
      "        self.code = raw_code\n",
      "\n",
      "        result = str({'step':'CodeFirstPass','code':self.code})\n",
      "        self.chat.hist.append({\"role\":\"user\",\"content\":result})\n",
      "        return result\n",
      "\n",
      "\n",
      "    def unit_test(self):\n",
      "        \"\"\"Execute code in Unreal Engine and review results. Returns test outcome with pass/fail status.\"\"\"\n",
      "        self.print_update('Testing Code\\n')\n",
      "        self.collect('unit-box',dtype='tag')\n",
      "\n",
      "        unit_test_result, unit_test_result_ansi = execute_unreal_code(self.code)\n",
      "        \n",
      "        # Send to GUi\n",
      "        accumulated = convert_to_accumulated(unit_test_result_ansi)\n",
      "        self.collect(accumulated, dtype='output')\n",
      "\n",
      "        unit_test_dict = {'unit_test_result':unit_test_result,\n",
      "                          'step':'CodeUnitTest'}\n",
      "                          \n",
      "        self.chat.hist.append({\"role\":\"assistant\",\n",
      "                               \"content\":str(unit_test_dict)})\n",
      "\n",
      "        self.collect('review-box',dtype='tag')\n",
      "        raw_review = self.chat_history_swap(SYS_REVIEW,UNIT_TEST_STR)\n",
      "\n",
      "        boolean_query =[{\"role\":\"user\", \n",
      "                        \"content\":f'Is this response saying this code is good enough to approve?: {raw_review}'}]\n",
      "        sent_result = lisette.structured(MODEL,\n",
      "                                boolean_query,\n",
      "                                tool=SentimentChecker)\n",
      "\n",
      "        self.print_update(str(sent_result.approved)+'\\n')\n",
      "        if sent_result.approved:\n",
      "            self.collect(\"DONE\",dtype='tag')\n",
      "\n",
      "        result = str({'pass':sent_result.approved,\n",
      "                    'explanation':raw_review,\n",
      "                    'step':'CodeUnitTestReview'}) \n",
      "\n",
      "        self.chat.hist.append({\"role\":\"assistant\",\"content\":result})\n",
      "        return result\n",
      "\n",
      "    def get_tools(self):\n",
      "        return [self.improve_code,self.generate_code,self.unit_test,self.read_url,self.search_web]\n",
      "        \n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/notebook_io.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/notebook_io.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['reconstruct_cells_from_history', 'reconstruct_ipynb_cell', 'prepare_chat_history', 'is_ask_cell', 'prep_prompt_cell',\n",
      "           'seperate_markdown', 'prep_markdown_cell', 'format_for_chat', 'prep_code_cell', 'prep_code_cell_output']\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 3\n",
      "import io\n",
      "import base64\n",
      "import json\n",
      "from PIL import Image\n",
      "from .cells import MarkdownCell, CodeCell, PromptCell#, AgentCell\n",
      "from .app_config import PROMPT_SPLIT\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 4\n",
      "def reconstruct_cells_from_history(notebook_history):\n",
      "    \"\"\"Convert raw JavaScript cell data into rendered cell objects.\n",
      "    \n",
      "    Args:\n",
      "        notebook_history: List of cell dicts from JavaScript with keys:\n",
      "            cell_type, cell_id, source, outputs.\n",
      "    \n",
      "    Returns:\n",
      "        List of cell objects (MarkdownCell, CodeCell, or PromptCell).\n",
      "    \n",
      "    Raises:\n",
      "        ValueError: If cell_type is unknown.\n",
      "    \"\"\"    \n",
      "    cells = []\n",
      "    \n",
      "    for cell_data in notebook_history:\n",
      "        cell_type = cell_data['cell_type']\n",
      "        cell_id = cell_data['cell_id']\n",
      "        source = cell_data['source']\n",
      "        outputs = cell_data.get('outputs')\n",
      "        \n",
      "        if cell_type == 'markdown':\n",
      "            cell = MarkdownCell(source=source, cell_id=cell_id)\n",
      "        \n",
      "        elif cell_type == 'code':\n",
      "            cell = CodeCell(source=source, outputs=outputs or [], cell_id=cell_id)\n",
      "        \n",
      "        elif cell_type == 'prompt':\n",
      "            cell = PromptCell(source=source, outputs=outputs or '', cell_id=cell_id)\n",
      "\n",
      "        #elif cell_type == 'agent':\n",
      "        #    cell = AgentCell(source_prompt=source, source_code=outputs, cell_id=cell_id)\n",
      "        else:\n",
      "            raise ValueError(f\"Unknown cell type: {cell_type}\")\n",
      "        \n",
      "        cells.append(cell)\n",
      "    \n",
      "    return cells\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 5\n",
      "def reconstruct_ipynb_cell(cell):\n",
      "    \"\"\"Convert a Jupyter notebook cell dict to the appropriate cell class.\n",
      "    \n",
      "    Args:\n",
      "        cell: Dict with 'cell_type', 'metadata', and type-specific keys.\n",
      "            Markdown cells may have 'agent_cell' or 'prompt_cell' in metadata.\n",
      "    \n",
      "    Returns:\n",
      "        MarkdownCell, CodeCell, PromptCell, AgentCell, or None if unknown type.\n",
      "    \"\"\"\n",
      "    jup_cell_type = cell['cell_type']\n",
      "\n",
      "    if jup_cell_type == 'markdown':\n",
      "        #if 'agent_cell' in cell['metadata']:\n",
      "        #    cell_type = 'agent'\n",
      "        if 'prompt_cell' in cell['metadata']:\n",
      "            cell_type = 'prompt'\n",
      "        else:\n",
      "            cell_type = 'markdown'\n",
      "    else:\n",
      "        cell_type = jup_cell_type\n",
      "    \n",
      "    \n",
      "    if cell_type == 'markdown':\n",
      "        return MarkdownCell.from_ipynb(cell)\n",
      "    if cell_type == 'code':\n",
      "        return CodeCell.from_ipynb(cell)\n",
      "    elif cell_type == 'prompt':\n",
      "        return PromptCell.from_ipynb(cell)\n",
      "    #elif cell_type == 'agent':\n",
      "    #    return AgentCell.from_ipynb(cell)\n",
      "    \n",
      "    else:\n",
      "        return None\n",
      "\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 6\n",
      "def prepare_chat_history(cell_list):\n",
      "    \"\"\"\n",
      "    Converts a list of notebook cells into a conversation history for the LLM.\n",
      "\n",
      "    Args:\n",
      "        cell_list (list): List of notebook cells.\n",
      "\n",
      "    Returns:\n",
      "        list: A list of message dictionaries (role/content) for the Chat API.\n",
      "    \"\"\"\n",
      "    cell_context = []\n",
      "    for cell in cell_list:\n",
      "        cell_type = cell['cell_type']\n",
      "\n",
      "        if cell_type == 'markdown':\n",
      "\n",
      "            if is_ask_cell(cell):\n",
      "                    question, answer = prep_prompt_cell(cell)\n",
      "                    formatted_q = format_for_chat(question)\n",
      "                    cell_context.append( {\"role\": \"user\", \"content\": formatted_q} )\n",
      "                    formatted_a = format_for_chat(answer)\n",
      "                    cell_context.append( {\"role\": \"assistant\", \"content\": formatted_a} )\n",
      "            else:\n",
      "                formatted = format_for_chat(prep_markdown_cell(cell))\n",
      "                if formatted:\n",
      "\n",
      "                    cell_context.append( {\"role\": \"user\", \"content\": formatted} )\n",
      "\n",
      "        elif cell_type == 'code':\n",
      "\n",
      "            sub_type = 'Code'\n",
      "            response_role = 'user'\n",
      "\n",
      "            formatted = format_for_chat(prep_code_cell(cell,cell_type=sub_type))\n",
      "            if formatted:\n",
      "                cell_context.append( {\"role\": \"user\", \"content\": formatted} )\n",
      "\n",
      "            formatted = format_for_chat(prep_code_cell_output(cell,cell_type=sub_type))\n",
      "            if formatted:\n",
      "                cell_context.append( {\"role\": response_role, \"content\":formatted} )\n",
      "    return cell_context\n",
      "\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 7\n",
      "def is_ask_cell(cell):\n",
      "    \"\"\"Check if a cell is a prompt cell with a response.\n",
      "    \n",
      "    Args:\n",
      "        cell (dict): The JSON dictionary representing a cell.\n",
      "        \n",
      "    Returns:\n",
      "        bool: True if cell contains the prompt/response separator, False otherwise.\n",
      "    \"\"\"\n",
      "    source = cell['source']\n",
      "    try:\n",
      "        split_index =  source.index(PROMPT_SPLIT[2:-1])\n",
      "        return True\n",
      "    except:\n",
      "        return False\n",
      "         \n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 8\n",
      "def prep_prompt_cell(cell):\n",
      "    \"\"\"\n",
      "    Extracts text and embedded images from a markdown cell.\n",
      "\n",
      "    Args:\n",
      "        cell (dict): The JSON dictionary representing a markdown cell.\n",
      "\n",
      "    Returns:\n",
      "        tuple (list): Two lists containing strings (text content) and bytes (decoded image data).\n",
      "    \"\"\"\n",
      "    source = cell['source']\n",
      "    try:\n",
      "        split_index =  source.index(PROMPT_SPLIT[2:-1])\n",
      "        question = seperate_markdown(source[:split_index-1])\n",
      "        answer = seperate_markdown(source[split_index+2:])\n",
      "    except:\n",
      "        question = seperate_markdown(source)\n",
      "        answer = []\n",
      "\n",
      "    formatted_question = ['## User Question Cell\\n']+question\n",
      "    return formatted_question, answer\n",
      "\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 9\n",
      "def seperate_markdown(markdown):\n",
      "    \"\"\"Separate markdown text blocks from embedded base64 images.\n",
      "    \n",
      "    Args:\n",
      "        markdown: List of markdown content strings, potentially containing\n",
      "            embedded base64 images in the format `(data:image/...;base64,...)`.\n",
      "    \n",
      "    Returns:\n",
      "        List containing strings for text blocks and bytes for decoded images.\n",
      "    \"\"\"\n",
      "    out_list = []\n",
      "    for block in markdown:\n",
      "\n",
      "        if \"(data:image/\" in block:\n",
      "            base_64_text = block.split('base64,')[1]\n",
      "            base_64_text = base_64_text.split(')')[0]\n",
      "            output_image_bytes =  base64.b64decode(base_64_text)\n",
      "            out_list.append(output_image_bytes )\n",
      " \n",
      "        else:\n",
      "            out_list.append(block)\n",
      "    return out_list\n",
      "\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 10\n",
      "def prep_markdown_cell(markdown_cell):\n",
      "    \"\"\"\n",
      "    Extracts text and embedded images from a markdown cell.\n",
      "\n",
      "    Args:\n",
      "        markdown_cell (dict): The JSON dictionary representing a markdown cell.\n",
      "\n",
      "    Returns:\n",
      "        list: A list containing strings (text content) and bytes (decoded image data).\n",
      "    \"\"\"\n",
      "    output_list = ['## Markdown Cell\\n']\n",
      "\n",
      "    for block in markdown_cell['source']:\n",
      "        if \"(data:image/\" in block:\n",
      "            base_64_text = block.split('base64,')[1]\n",
      "            base_64_text = base_64_text.split(')')[0]\n",
      "            output_image_bytes =  base64.b64decode(base_64_text)\n",
      "            output_list.append(output_image_bytes )\n",
      " \n",
      "        else:\n",
      "            output_list.append(block)\n",
      "    return output_list\n",
      "    \n",
      "\n",
      "def format_for_chat(items):\n",
      "    \"\"\"\n",
      "    Formats a list of mixed text and image bytes into the OpenAI/LiteLLM message structure.\n",
      "\n",
      "    Args:\n",
      "        items (list): A list containing strings or byte objects.\n",
      "\n",
      "    Returns:\n",
      "        list: A list of dictionaries with 'type' (text/image_url) keys.\n",
      "    \"\"\"\n",
      "    formatted = []\n",
      "    \n",
      "    for item in items:\n",
      "        if isinstance(item,str):\n",
      "            if item != '':\n",
      "                formatted.append( {\"type\": \"text\", \"text\": item})\n",
      "        elif isinstance(item,bytes):\n",
      "            img = Image.open(io.BytesIO(item))\n",
      "            img_format = img.format.lower()\n",
      "            base64_string = base64.b64encode(item).decode('utf-8')\n",
      "            formatted.append( {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/{img_format};base64,{base64_string}\"}})\n",
      "    \n",
      "    return formatted\n",
      "\n",
      "\n",
      "def prep_code_cell(code_cell,cell_type='Code'):\n",
      "    \"\"\"\n",
      "    Extracts and labels source code from a code cell.\n",
      "\n",
      "    Args:\n",
      "        code_cell (dict): The JSON dictionary representing a code cell.\n",
      "        cell_type (str, optional): Label for the cell. Defaults to 'Code'.\n",
      "\n",
      "    Returns:\n",
      "        list: A list containing the labeled header and the source code string.\n",
      "    \"\"\"\n",
      "    output_list = [f'{cell_type} Cell\\n']\n",
      "\n",
      "    code_input = ''.join(code_cell['source'])\n",
      "    output_list.append(code_input)\n",
      "\n",
      "    return output_list\n",
      "\n",
      "\n",
      "def prep_code_cell_output(code_cell,cell_type='Code'):\n",
      "    \"\"\"\n",
      "    Extracts outputs (logs, streams, errors, images) from a code cell.\n",
      "\n",
      "    Args:\n",
      "        code_cell (dict): The JSON dictionary representing a code cell.\n",
      "        cell_type (str, optional): Label for the cell. Defaults to 'Code'.\n",
      "\n",
      "    Returns:\n",
      "        list: A list containing text output, error traces, or image bytes.\n",
      "    \"\"\"\n",
      "    if cell_type == 'Code':\n",
      "        output_list = ['### Code Cell Output\\n']\n",
      "    else:\n",
      "        output_list = []\n",
      "        \n",
      "    for block in code_cell['outputs']:\n",
      "        if block['output_type'] in ['display_data', 'execute_result']:\n",
      "            for key in  block['data'].keys():\n",
      "\n",
      "                out_data = None\n",
      "                block_data = block['data'][key]\n",
      "\n",
      "                if key.endswith('json'):\n",
      "                    try:\n",
      "                        out_data = json.dumps(block_data,indent=4)\n",
      "\n",
      "                    except Exception as e:\n",
      "                        out_data = f'[Un-Serializable JSON Output: {key}]'\n",
      "\n",
      "                elif key.startswith('image'):\n",
      "                    try:\n",
      "                        out_data = base64.b64decode(block_data)\n",
      "\n",
      "                    except Exception as e:\n",
      "                        out_data = f'[Un-Encodable Image Output: {key}]'\n",
      "\n",
      "                elif key.startswith('text'):\n",
      "                    if isinstance(block_data, list):\n",
      "                        out_data = \"\".join(block_data)\n",
      "                    else:\n",
      "                        out_data = block_data\n",
      "                else:\n",
      "                    out_data = f'[Un-Renderable Output Type: {key}]'\n",
      "                \n",
      "                output_list.append(out_data)\n",
      "\n",
      "\n",
      "        elif block['output_type'] == 'stream':\n",
      "            output_list.append(''.join(block['text']))\n",
      "\n",
      "        elif block['output_type'] == 'error' :\n",
      "            output_list.append('#### Error\\n')  \n",
      "            output_list.append(f'evalue:{block[\"evalue\"]}\\n\\n traceback:{block[\"traceback\"]}')  \n",
      "\n",
      "\n",
      "    return output_list\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| notest\n",
    "#| eval: false\n",
    "#| hide\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../unreal_llm_sandbox/')\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "import big_project_helper as bph\n",
    "\n",
    "bph.display_project_contents('unreal_llm_sandbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp main\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfca5b7",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "import asyncio\n",
    "import requests\n",
    "import lisette\n",
    "import time\n",
    "\n",
    "from fasthtml.common import *\n",
    "from fasthtml.jupyter import JupyUvi\n",
    "from starlette.staticfiles import StaticFiles\n",
    "\n",
    "from unreal_llm_sandbox.app_config import MODEL, KERNEL_URL, NOTEBOOK_SYS_PROMPT\n",
    "from unreal_llm_sandbox.cells import MarkdownCell, CodeCell, PromptCell #, AgentCell\n",
    "from unreal_llm_sandbox.streaming import SSEStream, active_streams\n",
    "#from unreal_llm_sandbox.kernel import execute_unreal_code, convert_to_accumulated\n",
    "from unreal_llm_sandbox.notebook_io import reconstruct_cells_from_history, prepare_chat_history, reconstruct_ipynb_cell\n",
    "from unreal_llm_sandbox.llm import RemoteToolLLM, send_llm_request\n",
    "#from unreal_llm_sandbox.agent import AgentTools, SYS_PROMPT\n",
    "\n",
    "from fasthtml.common import *\n",
    "import importlib.resources\n",
    "import unreal_llm_sandbox\n",
    "\n",
    "# 1. Helper function to read the text content of your files\n",
    "def get_static(fname, icon=False):\n",
    "    \"\"\"Read static file content from package resources.\n",
    "    \n",
    "    Args:\n",
    "        fname: Filename to read from unreal_llm_sandbox/static/.\n",
    "        \n",
    "    Returns:\n",
    "        String content of the file.\n",
    "    \"\"\"\n",
    "    ref = importlib.resources.files(unreal_llm_sandbox) / 'static' / fname\n",
    "    if icon:\n",
    "        icon_bytes = (importlib.resources.files(unreal_llm_sandbox) / 'static' / 'Icon128.png').read_bytes()\n",
    "        return base64.b64encode(icon_bytes).decode()\n",
    "    else:\n",
    "        return ref.read_text(encoding='utf-8')\n",
    "\n",
    "\n",
    "# Then in headers:\n",
    "daisy_hdrs =[\n",
    "Link(rel=\"icon\", href=f\"data:image/png;base64,{get_static('Icon32.png',icon=True)}\"),\n",
    "Link(href='https://cdn.jsdelivr.net/npm/daisyui@5', rel='stylesheet', type='text/css'),\n",
    "Script(src='https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4'),\n",
    "Link(rel=\"stylesheet\", href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css\"),\n",
    "Link(rel=\"stylesheet\", href=\"https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.5.1/github-markdown.min.css\"),\n",
    "Script (src ='https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js'),\n",
    "Script (src ='https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js'),\n",
    "Script(src='https://cdn.jsdelivr.net/npm/marked/marked.min.js'),\n",
    "Script(get_static('cells.js')),\n",
    "Script(src=\"https://cdn.jsdelivr.net/npm/ansi_up@5/ansi_up.min.js\"),\n",
    "Script(src=\"https://cdn.jsdelivr.net/npm/monaco-editor@latest/min/vs/loader.js\"),\n",
    "Script(\"\"\"\n",
    "require.config({ paths: { 'vs': 'https://cdn.jsdelivr.net/npm/monaco-editor@latest/min/vs' }});\n",
    "\"\"\"),\n",
    "Script(src=\"https://unpkg.com/htmx.org/dist/ext/sse.js\")]\n",
    "\n",
    "\n",
    "# FastHTML app setup + daisy_hdrs (the big Style/Script list)\n",
    "app = FastHTML(hdrs=daisy_hdrs)\n",
    "\n",
    "\n",
    "rt = app.route\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c021a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@rt('/interrupt/{cell_id}', methods=['POST'])\n",
    "async def interrupt(cell_id: str, request):\n",
    "    \"\"\"Signal abort for an active stream.\n",
    "    \n",
    "    Args:\n",
    "        cell_id: Unique cell identifier.\n",
    "    \n",
    "    Returns:\n",
    "        \"OK\" acknowledgment string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = await request.json()\n",
    "        notebook = data.get('notebook', 'untitled')\n",
    "    except:\n",
    "        notebook = 'untitled'\n",
    "    stream_key = f\"{notebook}:{cell_id}\"\n",
    "    if stream_key in active_streams:\n",
    "        active_streams[stream_key]['abort'] = True\n",
    "    return \"OK\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61155ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@rt('/execute_prompt/{cell_id}')\n",
    "async def exe_prompt(cell_id: str, request): \n",
    "    \"\"\"Execute LLM prompt with notebook context via SSE.\n",
    "    \n",
    "    Args:\n",
    "        cell_id: Unique cell identifier.\n",
    "        request: FastHTML request with JSON body containing:\n",
    "            - prompt: User's prompt text.\n",
    "            - context: List of cell dicts for history.\n",
    "    \n",
    "    Returns:\n",
    "        SSE StreamingResponse yielding LLM chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    data = await request.json() \n",
    "\n",
    "    notebook = data.get('notebook', 'untitled')\n",
    "    \n",
    "    stream_key = f\"{notebook}:{cell_id}\" \n",
    "\n",
    "    prompt = data['prompt']\n",
    "    cell_dict_list = data.get('context', [])\n",
    "    use_tools = data.get('use_tools', True) \n",
    "\n",
    "    cells = reconstruct_cells_from_history(cell_dict_list)\n",
    "    ipynb_list = [cell.to_ipynb() for cell in cells]\n",
    "    chat_history = prepare_chat_history(ipynb_list)\n",
    "    \n",
    "    stream = SSEStream(stream_key)\n",
    "    \n",
    "    def run():\n",
    "        for msg in send_llm_request(prompt, history=chat_history, use_ue_tools=use_tools):\n",
    "            if stream.aborted(): break\n",
    "            stream.text(msg)\n",
    "        stream.done()\n",
    "    \n",
    "    asyncio.create_task(asyncio.to_thread(run))\n",
    "    return stream.response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f016726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@rt('/execute_code/{cell_id}')\n",
    "async def exe_code(cell_id: str, request):\n",
    "    \"\"\"Execute Python code in Unreal Engine via SSE.\n",
    "    \n",
    "    Args:\n",
    "        cell_id: Unique cell identifier.\n",
    "        request: FastHTML request with JSON body containing:\n",
    "            - code: Python code string to execute.\n",
    "    \n",
    "    Returns:\n",
    "        SSE StreamingResponse yielding kernel output messages.\n",
    "    \"\"\"\n",
    "\n",
    "    data = await request.json()\n",
    "    notebook = data.get('notebook', 'untitled')\n",
    "    stream_key = f\"{notebook}:{cell_id}\" \n",
    "\n",
    "    stream = SSEStream(stream_key)\n",
    "    \n",
    "    def run():\n",
    "        response = requests.post(f'{KERNEL_URL}/execute', json={'code': data['code']}, stream=True, timeout=(5, 60))\n",
    "        for line in response.iter_lines():\n",
    "            if stream.aborted(): break\n",
    "            if line.startswith(b'data: '):\n",
    "                stream.output(json.loads(line[6:]))  # â† output() not raw()\n",
    "        stream.done()\n",
    "    \n",
    "    asyncio.create_task(asyncio.to_thread(run))\n",
    "    return stream.response()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35b31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@rt(\\'/agent_tool_build/{cell_id}\\', methods=[\\'POST\\'])\\nasync def agent_stream(cell_id: str, request):\\n    \"\"Run agent code generation loop with tool calling via SSE.\\n\\n    Args:\\n        cell_id: Unique cell identifier.\\n        request: FastHTML request with JSON body containing:\\n            - prompt: Code generation request.\\n            - existing_code: Optional code to modify.\\n            - context: List of cell dicts for history.\\n\\n    Returns:\\n        SSE StreamingResponse yielding agent progress (tags, text, outputs).\\n    \"\"\\n    data = await request.json()\\n    notebook = data.get(\\'notebook\\', \\'untitled\\')\\n    stream_key = f\"{notebook}:{cell_id}\" \\n\\n    stream = SSEStream(stream_key)\\n    def run_chat():\\n        PROMPT = data[\\'prompt\\']\\n\\n        existing_code = data.get(\\'existing_code\\')\\n        cell_dict_list = data.get(\\'context\\', [])  # â† Add this\\n\\n        # Convert to chat history like prompt cells do\\n        cells = reconstruct_cells_from_history(cell_dict_list)\\n        ipynb_list = [cell.to_ipynb() for cell in cells]\\n        chat_history = prepare_chat_history(ipynb_list)\\n\\n        if existing_code:\\n            CODE = existing_code  # Initialize CODE with existing\\n            PROMPT = f\"Modify this code: {existing_code}\\n\\nRequest: {data[\\'prompt\\']}\"\\n        else:\\n            CODE = \"\"\\n            PROMPT = data[\\'prompt\\']\\n\\n\\n        CHAT = lisette.Chat(MODEL, SYS_PROMPT)\\n        CHAT.hist += chat_history\\n        CHAT.hist.append( {\"role\":\"assistant\", \"content\":PROMPT})\\n\\n        a_tools = AgentTools(stream, CHAT, PROMPT,cell_id, code=CODE, print_updates=False)\\n        tools = a_tools.get_tools()\\n\\n        chat = lisette.Chat(MODEL, SYS_PROMPT, tools=tools)\\n        chat.hist += chat_history\\n\\n\\n        gen = chat(PROMPT, max_steps=15)\\n        for _ in gen:\\n            if stream.aborted():\\n                break\\n        print(\"Chat loop finished!\") \\n        time.sleep(0.1) \\n        stream.done()\\n\\n    asyncio.create_task(asyncio.to_thread(run_chat))\\n    return stream.response()\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@rt('/agent_tool_build/{cell_id}', methods=['POST'])\n",
    "async def agent_stream(cell_id: str, request):\n",
    "    \"\"Run agent code generation loop with tool calling via SSE.\n",
    "    \n",
    "    Args:\n",
    "        cell_id: Unique cell identifier.\n",
    "        request: FastHTML request with JSON body containing:\n",
    "            - prompt: Code generation request.\n",
    "            - existing_code: Optional code to modify.\n",
    "            - context: List of cell dicts for history.\n",
    "    \n",
    "    Returns:\n",
    "        SSE StreamingResponse yielding agent progress (tags, text, outputs).\n",
    "    \"\"\n",
    "    data = await request.json()\n",
    "    notebook = data.get('notebook', 'untitled')\n",
    "    stream_key = f\"{notebook}:{cell_id}\" \n",
    "\n",
    "    stream = SSEStream(stream_key)\n",
    "    def run_chat():\n",
    "        PROMPT = data['prompt']\n",
    "\n",
    "        existing_code = data.get('existing_code')\n",
    "        cell_dict_list = data.get('context', [])  # â† Add this\n",
    "\n",
    "        # Convert to chat history like prompt cells do\n",
    "        cells = reconstruct_cells_from_history(cell_dict_list)\n",
    "        ipynb_list = [cell.to_ipynb() for cell in cells]\n",
    "        chat_history = prepare_chat_history(ipynb_list)\n",
    "\n",
    "        if existing_code:\n",
    "            CODE = existing_code  # Initialize CODE with existing\n",
    "            PROMPT = f\"Modify this code: {existing_code}\\n\\nRequest: {data['prompt']}\"\n",
    "        else:\n",
    "            CODE = \"\"\n",
    "            PROMPT = data['prompt']\n",
    "        \n",
    "\n",
    "        CHAT = lisette.Chat(MODEL, SYS_PROMPT)\n",
    "        CHAT.hist += chat_history\n",
    "        CHAT.hist.append( {\"role\":\"assistant\", \"content\":PROMPT})\n",
    "\n",
    "        a_tools = AgentTools(stream, CHAT, PROMPT,cell_id, code=CODE, print_updates=False)\n",
    "        tools = a_tools.get_tools()\n",
    "        \n",
    "        chat = lisette.Chat(MODEL, SYS_PROMPT, tools=tools)\n",
    "        chat.hist += chat_history\n",
    "\n",
    "\n",
    "        gen = chat(PROMPT, max_steps=15)\n",
    "        for _ in gen:\n",
    "            if stream.aborted():\n",
    "                break\n",
    "        print(\"Chat loop finished!\") \n",
    "        time.sleep(0.1) \n",
    "        stream.done()\n",
    "    \n",
    "    asyncio.create_task(asyncio.to_thread(run_chat))\n",
    "    return stream.response()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d496e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def Toolbar(title):\n",
    "    \"\"\"Build the notebook toolbar with cell creation buttons.\n",
    "    \n",
    "    Args:\n",
    "        title: Notebook name to display in the editable input.\n",
    "        \n",
    "    Returns:\n",
    "        FastHTML Div containing toolbar elements.\n",
    "    \"\"\"\n",
    "    return Div(\n",
    "\n",
    "        Div(\n",
    "            Input(value=title, cls=\"text-xl font-bold text-white notebook-name bg-transparent border-none outline-none focus:outline-none flex-1\"),\n",
    "            Script(\"\"\"\n",
    "                document.querySelector('.notebook-name').addEventListener('blur', (e) => {\n",
    "                    const name = e.target.value || 'untitled';\n",
    "                    history.replaceState(null, '', `/notebook/${name}.ipynb`);\n",
    "                });\n",
    "            \"\"\"),\n",
    "            cls=\"flex flex-1 items-center\"\n",
    "        ),\n",
    "        Div(\n",
    "            Button(\"âž• Markdown\", \n",
    "                   hx_post=\"/add_cell/markdown\",\n",
    "                   hx_target=\"#notebook-container\",\n",
    "                   hx_swap=\"beforeend\",\n",
    "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"), \n",
    "            Button(\"âž• Code\", \n",
    "                   hx_post=\"/add_cell/code\",\n",
    "                   hx_target=\"#notebook-container\",\n",
    "                   hx_swap=\"beforeend\",\n",
    "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"),  \n",
    "            Button(\"âž• Prompt\", \n",
    "                   hx_post=\"/add_cell/prompt\",\n",
    "                   hx_target=\"#notebook-container\",\n",
    "                   hx_swap=\"beforeend\",\n",
    "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"),  \n",
    "            #Button(\"âž• Agent\", \n",
    "            #       hx_post=\"/add_cell/agent\",\n",
    "            #       hx_target=\"#notebook-container\",\n",
    "            #       hx_swap=\"beforeend\",\n",
    "            #       cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"), \n",
    "            cls=\"flex gap-2\"\n",
    "        ),\n",
    "        cls=\"flex justify-between p-4 bg-[#0d0d0d]\"  # â† Changed from #0d0d0d to pure black\n",
    "    )\n",
    "\n",
    "@rt('/add_cell/{cell_type}')\n",
    "def add_cell(cell_type: str):\n",
    "    \"\"\"Create and return a new cell of the specified type.\n",
    "    \n",
    "    Args:\n",
    "        cell_type: One of 'markdown', 'code', 'prompt', or 'agent'.\n",
    "        \n",
    "    Returns:\n",
    "        Rendered FastHTML cell component.\n",
    "    \"\"\"\n",
    "    if cell_type == 'markdown':\n",
    "        new_cell = MarkdownCell(\"\")\n",
    "    elif cell_type == 'code':\n",
    "        new_cell = CodeCell(\"\")\n",
    "    elif cell_type == 'prompt':\n",
    "        new_cell = PromptCell(\"\")\n",
    "    #elif cell_type == 'agent':\n",
    "    #    new_cell = AgentCell(\"\")\n",
    "    else:\n",
    "        return \"Invalid cell type\"\n",
    "    \n",
    "    return new_cell.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@rt('/notebook/{notebook_file}')\n",
    "def load_notebook(notebook_file:str): \n",
    "    \"\"\"Load a Jupyter Notebook file and render its cells.\n",
    "    \n",
    "    Args:\n",
    "        notebook_file: Path to .ipynb file to load.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of Title and Body elements for the page.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(notebook_file):\n",
    "        rendered_cells = []\n",
    "        print ('Notebook Not Found:',notebook_file)\n",
    "\n",
    "    else:\n",
    "        cells = []\n",
    "        with open(notebook_file, 'r', encoding='utf-8') as f:\n",
    "            notebook = json.load(f)\n",
    "            cells = notebook['cells']\n",
    "        \n",
    "        cell_objects = [reconstruct_ipynb_cell(cell) for cell in cells]\n",
    "        rendered_cells = [cell.render() for cell in cell_objects]\n",
    "\n",
    "\n",
    "    return Title(\"Unreal LLM Sandbox\"),Body(\n",
    "        Toolbar(notebook_file.split('.ipynb')[0]),\n",
    "        Style(get_static('styles.css')),\n",
    "        Div(  *rendered_cells,\n",
    "            cls='px-5',  \n",
    "            id='notebook-container' \n",
    "        )\n",
    "    )\n",
    "\n",
    "@rt('/save_notebook/{notebook_file}', methods=['POST'])\n",
    "async def save_notebook(notebook_file: str, request):\n",
    "    \"\"\"Save notebook cells to a Jupyter .ipynb file.\n",
    "    \n",
    "    Args:\n",
    "        notebook_file: Filename to save to.\n",
    "        request: Request with JSON body containing 'cells' list.\n",
    "    \n",
    "    Returns:\n",
    "        JSON with status message.\n",
    "    \"\"\"\n",
    "    data = await request.json()\n",
    "    cell_dict_list = data.get('cells', [])\n",
    "    \n",
    "    # Reconstruct cell objects and convert to ipynb format\n",
    "    cells = reconstruct_cells_from_history(cell_dict_list)\n",
    "    ipynb_cells = [cell.to_ipynb() for cell in cells]\n",
    "    \n",
    "    # Build notebook structure\n",
    "    notebook = {\n",
    "        \"nbformat\": 4,\n",
    "        \"nbformat_minor\": 5,\n",
    "        \"metadata\": {\n",
    "            \"kernelspec\": {\n",
    "                \"display_name\": \"Python 3\",\n",
    "                \"language\": \"python\",\n",
    "                \"name\": \"python3\"\n",
    "            }\n",
    "        },\n",
    "        \"cells\": ipynb_cells\n",
    "    }\n",
    "    \n",
    "    with open(notebook_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(notebook, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    return {\"status\": \"saved\", \"file\": notebook_file}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184db627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import uvicorn\n",
    "\n",
    "def start_server():\n",
    "    uvicorn.run(app,\n",
    "                 host='0.0.0.0',\n",
    "                 port=5001, \n",
    "                 timeout_graceful_shutdown=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "##| eval: false\n",
    "#from fasthtml.jupyter import JupyUvi\n",
    "#server = JupyUvi(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b008b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m",
      "\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#| eval: false\u001b[39;00m",
      "\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mstart_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m",
      "",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mstart_server\u001b[39m\u001b[34m()\u001b[39m",
      "\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart_server\u001b[39m():",
      "\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43muvicorn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m",
      "\u001b[32m      5\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m0.0.0.0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m",
      "\u001b[32m      6\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m",
      "\u001b[32m      7\u001b[39m \u001b[43m                 \u001b[49m\u001b[43mtimeout_graceful_shutdown\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/uvicorn/main.py:594\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, timeout_worker_healthcheck, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[39m",
      "\u001b[32m    592\u001b[39m         Multiprocess(config, target=server.run, sockets=[sock]).run()",
      "\u001b[32m    593\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:",
      "\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m         \u001b[43mserver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[32m    595\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:",
      "\u001b[32m    596\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# pragma: full coverage\u001b[39;00m",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/uvicorn/server.py:67\u001b[39m, in \u001b[36mServer.run\u001b[39m\u001b[34m(self, sockets)\u001b[39m",
      "\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket.socket] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:",
      "\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[43m=\u001b[49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loop_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/asyncio/runners.py:191\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m",
      "\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m",
      "\u001b[32m    162\u001b[39m ",
      "\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m",
      "\u001b[32m    188\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m",
      "\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:",
      "\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m",
      "\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(",
      "\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)",
      "\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:",
      "\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)",
      "",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#| eval: false\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    start_server()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
