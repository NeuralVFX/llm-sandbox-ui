{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c675ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialog Name: unreal/unreal-llm-sandbox/nbs/main\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/llm_tools.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/llm_tools.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['TOOLS', 'TOOL_SCHEMAS', 'get_tools', 'register_tool', 'search_web', 'read_url']\n",
      "\n",
      "# %% ../nbs/llm_tools.ipynb 2\n",
      "import requests\n",
      "import litellm\n",
      "import json\n",
      "from lisette import lite_mk_func\n",
      "\n",
      "TOOLS = {}\n",
      "TOOL_SCHEMAS = []\n",
      "\n",
      "\n",
      "def get_tools():\n",
      "    \"\"\"Return available tool schemas.\"\"\"\n",
      "    return TOOL_SCHEMAS\n",
      "\n",
      "\n",
      "def register_tool(func):\n",
      "    \"\"\"Register a function as a tool.\"\"\"\n",
      "    TOOLS[func.__name__] = func\n",
      "    schema = lite_mk_func(func)\n",
      "    # Remove old schema if exists\n",
      "    TOOL_SCHEMAS[:] = [s for s in TOOL_SCHEMAS if s['function']['name'] != func.__name__]\n",
      "    TOOL_SCHEMAS.append(schema)\n",
      "    return func\n",
      "\n",
      "\n",
      "@register_tool\n",
      "def search_web(query: str, max_results: int = 10):\n",
      "    \"\"\"Search DuckDuckGo and return top results.\n",
      "    \n",
      "    Args:\n",
      "        query: Search string.\n",
      "        max_results: Maximum number of results to return.\n",
      "        \n",
      "    Returns:\n",
      "        JSON string of results with title, url, snippet.\n",
      "    \"\"\"    \n",
      "    from ddgs import DDGS\n",
      "    \n",
      "    results = DDGS().text(query, max_results=max_results)\n",
      "    return str([{\"title\": r[\"title\"], \"url\": r[\"href\"], \"snippet\": r[\"body\"]} \n",
      "            for r in results])\n",
      "\n",
      "\n",
      "@register_tool\n",
      "def read_url(url:str):\n",
      "    \"\"\"Retrieve webpage HTML content.\n",
      "    \n",
      "    Args:\n",
      "        url: URL to fetch.\n",
      "        \n",
      "    Returns:\n",
      "        Raw HTML string.\n",
      "    \"\"\"    \n",
      "    import requests\n",
      "    response = requests.get(url)\n",
      "    html = response.text\n",
      "    return html\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/app_config.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/app_config.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['KERNEL_URL', 'MODEL', 'PROMPT_SPLIT', 'AGENT_CODE_SPLIT', 'AGENT_CODE_OUTPUT_SPLIT', 'AGENT_LLM_OUTPUT_SPLIT',\n",
      "           'UNIT_TEST_STR', 'CODE_GENERATOR', 'CODE_IMPROVER', 'SYS_CODER', 'SYS_REVIEW', 'SYS_PROMPT',\n",
      "           'NOTEBOOK_SYS_PROMPT']\n",
      "\n",
      "# %% ../nbs/app_config.ipynb 2\n",
      "KERNEL_URL = 'http://localhost:8765'\n",
      "MODEL = 'gpt-5.2'\n",
      "\n",
      "PROMPT_SPLIT = '\\n\\n##### LLM Response: <!-- LLM -->\\n\\n'\n",
      "AGENT_CODE_SPLIT = '\\n\\n##### Agent Code: <!-- AGENTCODE -->\\n\\n'\n",
      "AGENT_CODE_OUTPUT_SPLIT = '\\n\\n##### Code Unit Test Output: <!-- UNITTEST -->\\n\\n'\n",
      "AGENT_LLM_OUTPUT_SPLIT = '\\n\\n##### Agent Review: <!-- AGENTREVIEW -->\\n\\n'\n",
      "\n",
      "UNIT_TEST_STR = \"\"\"Review the results of the UNIT TEST.\\n\n",
      "Take into consideration: IS THE TOOL COMPLETING THE ORIGINAL GOAL?\\n\n",
      "Consider if anything about the UNIT TEST results shows a possible problem.\\n\n",
      "Note if the test doesn't have print statements, or isn't called ei: unit_test().\\n\n",
      "Make sure your explanation of any problems is clear.\\n\n",
      "This doesnt have to be scientifically perfect!( If it doesnt follow perfect code convention its ok ). \\n\n",
      "It just has to work, and match the users requirements.\\n\n",
      "Ultimately you must decide PASS or FAIL.\\n\n",
      "Explain thoroughly, but concisely!\\n\n",
      "\"\"\"\n",
      "\n",
      "CODE_GENERATOR = \"\"\"Generate code and a unit test.\\n\n",
      "Put the main function and unit test in code.\\n\n",
      "The UNIT TEST, must test the operation of the tool, by running it, and then querying the unreal scene to verify the results.\\n\n",
      "The UNIT TEST must use print(), NEVER USE console.log().\\n\n",
      "THE UNIT TEST FUNCTION MUST BE EXECTUTED ei: unit_test().\\n \n",
      "DONT respond with words, only output raw executable CODE.\\n\n",
      "DONT use excessive try; excepts or asserts\\n\n",
      "Dont make Makrdown, Do NOT start with ```python !!\\n\n",
      "\"\"\"\n",
      "\n",
      "CODE_IMPROVER = \"\"\"Improve the code based on feedback.\\n\n",
      "Include the complete corrected code.\\n\n",
      "The UNIT TEST must use print(), NEVER USE console.log().\\n\n",
      "THE UNIT TEST FUNCTION MUST BE EXECTUTED ei: unit_test()\\n\n",
      "DONT respond with words, only output raw executable CODE.\\n\n",
      "DONT use excessive try; excepts or asserts\\n\n",
      "Dont make Makrdown, Do NOT start with ```python !! \\n\n",
      "\"\"\"\n",
      "\n",
      "SYS_CODER = \"\"\"You are a python coder, you are writing code for unreal engine 5.6.\\n\n",
      "You review the log of the goal, the previos code and the results of the unit test.\\n\n",
      "You take this into account as yout write new code\\n\n",
      "\"\"\"\n",
      "\n",
      "SYS_REVIEW = \"\"\"You are a code reviewer. Your job is to study the code and answer questions about it.\n",
      "We are working in an unreal engine 5.6 environment\\n\"\"\"\n",
      "\n",
      "SYS_PROMPT = \"\"\"You are an experiences python developer, with unreal engine 5.6.\\n\n",
      "Your job is to either review existing code, or write new code, or improve existing code\\n\n",
      "\n",
      "--- Use your privded tool ---\n",
      "Do any preliminary websearch you need, check help urls\\n\n",
      "Our General Code Cycle is: \\n\n",
      "- generateCode\\n\n",
      "- unitTest   - This executes the code in unreal engine\\n\n",
      "while unitTest not passed:\n",
      "    - improveCode\\n\n",
      "    - unitTest\\n\n",
      "        - If AN AttributeError: is found in unitTest, do a websearch, check urls\\n\n",
      "    - REPEAT!\n",
      "\"\"\"\n",
      "\n",
      "NOTEBOOK_SYS_PROMPT = \"\"\"You are an AI assistant, your goal is to help the user build tools.\\n\n",
      "You're in a Jupyter Notebook, which is connected to Unreal Engine 5.6.\\n\n",
      "The users programming language of choice is python.\\n\n",
      "!!IMPORTANT!!: Always end your response with an explantion\\n\"\"\"\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/agent.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/agent.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['SentimentChecker', 'AgentTools']\n",
      "\n",
      "# %% ../nbs/agent.ipynb 2\n",
      "from dataclasses import dataclass\n",
      "import requests\n",
      "from ddgs import DDGS\n",
      "import lisette\n",
      "\n",
      "from unreal_llm_sandbox.app_config import (\n",
      "    KERNEL_URL, MODEL, NOTEBOOK_SYS_PROMPT, SYS_PROMPT,\n",
      "    CODE_GENERATOR, CODE_IMPROVER, UNIT_TEST_STR, SYS_CODER, SYS_REVIEW\n",
      ")\n",
      "from .kernel import *\n",
      "\n",
      "\n",
      "# %% ../nbs/agent.ipynb 3\n",
      "@dataclass\n",
      "class SentimentChecker:\n",
      "    \"\"\" Use this tool register whether you think the code review your looking at approved\\n\n",
      "    \"\"\"\n",
      "    approved: bool\n",
      "    \n",
      "\n",
      "# %% ../nbs/agent.ipynb 4\n",
      "class AgentTools():\n",
      "    def __init__(self, stream, chat, prompt, cell_id, code = '', print_updates = False):\n",
      "        \"\"\"Initialize agent tools.\n",
      "        \n",
      "        Args:\n",
      "            stream: SSEStream for output to GUI.\n",
      "            chat: LLM chat instance.\n",
      "            prompt: User's code generation request.\n",
      "            cell_id: Unique cell identifier.\n",
      "            code: Existing code to improve.\n",
      "            print_updates: Enable debug printing.\n",
      "        \"\"\"\n",
      "        self.chat = chat\n",
      "        self.code = code\n",
      "        self.prompt = prompt\n",
      "        self.cell_id = cell_id\n",
      "        self.print_updates = print_updates\n",
      "        self.stream = stream\n",
      "\n",
      "    def print_update(self, text):\n",
      "        \"\"\"Print debug message if updates enabled.\"\"\"\n",
      "        if self.print_updates:\n",
      "            print(text)\n",
      "\n",
      "    def collect(self, piece, dtype='text'):\n",
      "        \"\"\"Send output to GUI stream.\n",
      "        \n",
      "        Args:\n",
      "            piece: Content to send.\n",
      "            dtype: One of 'text', 'tag', or 'output'.\n",
      "        \"\"\"\n",
      "        if dtype == 'text':\n",
      "            self.stream.text(piece)\n",
      "        elif dtype == 'tag':\n",
      "            self.stream.tag(piece)\n",
      "        elif dtype == 'output':\n",
      "            self.stream.output(piece)\n",
      "\n",
      "    def chat_history_swap(self,new_sys,step_prompt):\n",
      "        \"\"\"Get LLM response with temporary system prompt.\n",
      "        \n",
      "        Args:\n",
      "            new_sys: Temporary system prompt.\n",
      "            step_prompt: Prompt for this step.\n",
      "        \n",
      "        Returns:\n",
      "            Collected response text.\n",
      "        \"\"\"\n",
      "        old_sys = self.chat.sp\n",
      "        self.chat.sp = new_sys\n",
      "        old_hist = self.chat.hist[:]\n",
      "        \n",
      "        response = self.chat(step_prompt,stream=True)\n",
      "        collected_stream = self.collect_llm_stream(response)\n",
      "        \n",
      "        self.chat.sp = old_sys\n",
      "        self.chat.hist = old_hist\n",
      "        return collected_stream\n",
      "\n",
      "    def collect_llm_stream(self,response):\n",
      "        \"\"\"Stream LLM chunks to GUI.\n",
      "        \n",
      "        Args:\n",
      "            response: LLM streaming response.\n",
      "        \n",
      "        Returns:\n",
      "            Full accumulated text.\n",
      "        \"\"\"\n",
      "        raw = ''\n",
      "        for piece in response:\n",
      "            if self.stream.aborted():  \n",
      "                break\n",
      "            if hasattr(piece, 'choices'):\n",
      "                if hasattr(piece.choices[0], 'delta'):\n",
      "                    if hasattr(piece.choices[0].delta, 'content'):\n",
      "                        crumb = piece.choices[0].delta.content\n",
      "                        if crumb:\n",
      "                            raw += crumb\n",
      "                            self.collect(crumb)\n",
      "        return raw\n",
      "\n",
      "    def search_web(self, query: str, max_results: int = 5):\n",
      "        \"\"\"Search DuckDuckGo for query.\n",
      "        \n",
      "        Args:\n",
      "            query: Search string.\n",
      "            max_results: Max results to return.\n",
      "        \"\"\"\n",
      "        from ddgs import DDGS\n",
      "        self.print_update('Searching Web\\n')\n",
      "        self.collect('tool-websearch',dtype='tag')\n",
      "\n",
      "        results = DDGS().text(query, max_results=max_results)\n",
      "    \n",
      "        snippet = str([{\"title\": r[\"title\"], \"url\": r[\"href\"], \"snippet\": r[\"body\"]} \n",
      "                for r in results])\n",
      "        result = str({'step':'SearchWeb','code':snippet})\n",
      "        self.chat.hist.append({\"role\":\"assistant\",\"content\":result})\n",
      "        return \n",
      "\n",
      "\n",
      "    def read_url(self, url:str):\n",
      "        \"\"\"Fetch webpage content.\n",
      "        \n",
      "        Args:\n",
      "            url: URL to retrieve.\n",
      "        \n",
      "        Returns:\n",
      "            HTML content.\n",
      "        \"\"\"\n",
      "        import requests\n",
      "        self.print_update('Loading URL\\n')\n",
      "        self.collect('tool-readurl',dtype='tag')\n",
      "\n",
      "        response = requests.get(url)\n",
      "        html = response.text\n",
      "\n",
      "        result = str({'step':'ReadUrl','code':html})\n",
      "        self.chat.hist.append({\"role\":\"assistant\",\"content\":result})\n",
      "        return html\n",
      "\n",
      "\n",
      "    def improve_code(self):\n",
      "        \"\"\"Improve existing code based on unit test feedback. Returns improved code.\"\"\"\n",
      "        self.print_update('Improving Code\\n')\n",
      "        self.collect('code-box',dtype='tag')\n",
      "\n",
      "        raw_code = self.chat_history_swap(SYS_CODER,CODE_IMPROVER)\n",
      "        self.code = raw_code\n",
      "\n",
      "        result = str({'step':'CodeImprovment','code':self.code})\n",
      "        self.chat.hist.append({\"role\":\"user\",\"content\":result})\n",
      "\n",
      "        return result\n",
      "\n",
      "\n",
      "    def generate_code(self):\n",
      "        \"\"\"Generate initial code and unit test for the given prompt. Returns generated code.\"\"\"\n",
      "        self.print_update('Generating Code\\n')\n",
      "        self.collect('code-box>',dtype='tag')\n",
      "\n",
      "        raw_code = self.chat_history_swap(SYS_CODER,CODE_GENERATOR)\n",
      "        self.code = raw_code\n",
      "\n",
      "        result = str({'step':'CodeFirstPass','code':self.code})\n",
      "        self.chat.hist.append({\"role\":\"user\",\"content\":result})\n",
      "        return result\n",
      "\n",
      "\n",
      "    def unit_test(self):\n",
      "        \"\"\"Execute code in Unreal Engine and review results. Returns test outcome with pass/fail status.\"\"\"\n",
      "        self.print_update('Testing Code\\n')\n",
      "        self.collect('unit-box',dtype='tag')\n",
      "\n",
      "        unit_test_result, unit_test_result_ansi = execute_unreal_code(self.code)\n",
      "        \n",
      "        # Send to GUi\n",
      "        accumulated = convert_to_accumulated(unit_test_result_ansi)\n",
      "        self.collect(accumulated, dtype='output')\n",
      "\n",
      "        unit_test_dict = {'unit_test_result':unit_test_result,\n",
      "                          'step':'CodeUnitTest'}\n",
      "                          \n",
      "        self.chat.hist.append({\"role\":\"assistant\",\n",
      "                               \"content\":str(unit_test_dict)})\n",
      "\n",
      "        self.collect('review-box',dtype='tag')\n",
      "        raw_review = self.chat_history_swap(SYS_REVIEW,UNIT_TEST_STR)\n",
      "\n",
      "        boolean_query =[{\"role\":\"user\", \n",
      "                        \"content\":f'Is this response saying this code is good enough to approve?: {raw_review}'}]\n",
      "        sent_result = lisette.structured(MODEL,\n",
      "                                boolean_query,\n",
      "                                tool=SentimentChecker)\n",
      "\n",
      "        self.print_update(str(sent_result.approved)+'\\n')\n",
      "        if sent_result.approved:\n",
      "            self.collect(\"DONE\",dtype='tag')\n",
      "\n",
      "        result = str({'pass':sent_result.approved,\n",
      "                    'explanation':raw_review,\n",
      "                    'step':'CodeUnitTestReview'}) \n",
      "\n",
      "        self.chat.hist.append({\"role\":\"assistant\",\"content\":result})\n",
      "        return result\n",
      "\n",
      "    def get_tools(self):\n",
      "        return [self.improve_code,self.generate_code,self.unit_test,self.read_url,self.search_web]\n",
      "        \n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/config.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/app_config.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['KERNEL_URL', 'MODEL', 'PROMPT_SPLIT', 'AGENT_CODE_SPLIT', 'AGENT_CODE_OUTPUT_SPLIT', 'AGENT_LLM_OUTPUT_SPLIT',\n",
      "           'UNIT_TEST_STR', 'CODE_GENERATOR', 'CODE_IMPROVER', 'SYS_CODER', 'SYS_REVIEW', 'SYS_PROMPT',\n",
      "           'NOTEBOOK_SYS_PROMPT']\n",
      "\n",
      "# %% ../nbs/app_config.ipynb 2\n",
      "KERNEL_URL = 'http://localhost:8765'\n",
      "MODEL = 'gpt-5.2'\n",
      "\n",
      "PROMPT_SPLIT = '\\n\\n##### LLM Response: <!-- LLM -->\\n\\n'\n",
      "AGENT_CODE_SPLIT = '\\n\\n##### Agent Code: <!-- AGENTCODE -->\\n\\n'\n",
      "AGENT_CODE_OUTPUT_SPLIT = '\\n\\n##### Code Unit Test Output: <!-- UNITTEST -->\\n\\n'\n",
      "AGENT_LLM_OUTPUT_SPLIT = '\\n\\n##### Agent Review: <!-- AGENTREVIEW -->\\n\\n'\n",
      "\n",
      "UNIT_TEST_STR = \"\"\"Review the results of the UNIT TEST.\\n\n",
      "Take into consideration: IS THE TOOL COMPLETING THE ORIGINAL GOAL?\\n\n",
      "Consider if anything about the UNIT TEST results shows a possible problem.\\n\n",
      "Note if the test doesn't have print statements, or isn't called ei: unit_test().\\n\n",
      "Make sure your explanation of any problems is clear.\\n\n",
      "This doesnt have to be scientifically perfect!( If it doesnt follow perfect code convention its ok ). \\n\n",
      "It just has to work, and match the users requirements.\\n\n",
      "Ultimately you must decide PASS or FAIL.\\n\n",
      "Explain thoroughly, but concisely!\\n\n",
      "\"\"\"\n",
      "\n",
      "CODE_GENERATOR = \"\"\"Generate code and a unit test.\\n\n",
      "Put the main function and unit test in code.\\n\n",
      "The UNIT TEST, must test the operation of the tool, by running it, and then querying the unreal scene to verify the results.\\n\n",
      "The UNIT TEST must use print(), NEVER USE console.log().\\n\n",
      "THE UNIT TEST FUNCTION MUST BE EXECTUTED ei: unit_test().\\n \n",
      "DONT respond with words, only output raw executable CODE.\\n\n",
      "DONT use excessive try; excepts or asserts\\n\n",
      "Dont make Makrdown, Do NOT start with ```python !!\\n\n",
      "\"\"\"\n",
      "\n",
      "CODE_IMPROVER = \"\"\"Improve the code based on feedback.\\n\n",
      "Include the complete corrected code.\\n\n",
      "The UNIT TEST must use print(), NEVER USE console.log().\\n\n",
      "THE UNIT TEST FUNCTION MUST BE EXECTUTED ei: unit_test()\\n\n",
      "DONT respond with words, only output raw executable CODE.\\n\n",
      "DONT use excessive try; excepts or asserts\\n\n",
      "Dont make Makrdown, Do NOT start with ```python !! \\n\n",
      "\"\"\"\n",
      "\n",
      "SYS_CODER = \"\"\"You are a python coder, you are writing code for unreal engine 5.6.\\n\n",
      "You review the log of the goal, the previos code and the results of the unit test.\\n\n",
      "You take this into account as yout write new code\\n\n",
      "\"\"\"\n",
      "\n",
      "SYS_REVIEW = \"\"\"You are a code reviewer. Your job is to study the code and answer questions about it.\n",
      "We are working in an unreal engine 5.6 environment\\n\"\"\"\n",
      "\n",
      "SYS_PROMPT = \"\"\"You are an experiences python developer, with unreal engine 5.6.\\n\n",
      "Your job is to either review existing code, or write new code, or improve existing code\\n\n",
      "\n",
      "--- Use your privded tool ---\n",
      "Do any preliminary websearch you need, check help urls\\n\n",
      "Our General Code Cycle is: \\n\n",
      "- generateCode\\n\n",
      "- unitTest   - This executes the code in unreal engine\\n\n",
      "while unitTest not passed:\n",
      "    - improveCode\\n\n",
      "    - unitTest\\n\n",
      "        - If AN AttributeError: is found in unitTest, do a websearch, check urls\\n\n",
      "    - REPEAT!\n",
      "\"\"\"\n",
      "\n",
      "NOTEBOOK_SYS_PROMPT = \"\"\"You are an AI assistant, your goal is to help the user build tools.\\n\n",
      "You're in a Jupyter Notebook, which is connected to Unreal Engine 5.6.\\n\n",
      "The users programming language of choice is python.\\n\n",
      "!!IMPORTANT!!: Always end your response with an explantion\\n\"\"\"\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/cells.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/cells.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['up_arrow_ic', 'down_arrow_ic', 'close_ic', 'swap_ic', 'view_ic', 'clean_ic', 'minimize_ic', 'play_ic', 'stop_ic',\n",
      "           'edit_ic', 'label_css', 'cell_button_format', 'interrupt_button', 'BaseCell', 'PromptCell', 'MarkdownCell',\n",
      "           'CodeCell', 'AgentCell']\n",
      "\n",
      "# %% ../nbs/cells.ipynb 3\n",
      "import json\n",
      "import uuid\n",
      "import re\n",
      "import mistune\n",
      "from fasthtml.common import * \n",
      "from .app_config import PROMPT_SPLIT, AGENT_CODE_SPLIT\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 5\n",
      "up_arrow_ic = NotStr(\"&#11014\")\n",
      "down_arrow_ic = NotStr(\"&#11015\")\n",
      "close_ic = NotStr(\"&#x274C\")\n",
      "swap_ic = NotStr(\"&#128257\")\n",
      "view_ic =NotStr(\"&#x1F50D\")\n",
      "clean_ic =NotStr(\"&#x1F9F9\")\n",
      "minimize_ic = NotStr(\"&#x25BC\");\n",
      "play_ic = NotStr(\"&#9654\")\n",
      "stop_ic = NotStr(\"&#9209\")\n",
      "edit_ic = NotStr(\"&#x1F4DD\")\n",
      "\n",
      "\n",
      "label_css = \"text-xs text-gray-400 px-2 py-1 bg-gray-800\"\n",
      "cell_button_format = 'btn btn-square btn-ghost btn-xs text-xl'\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 7\n",
      "def interrupt_button(cell_id):\n",
      "    return Button(stop_ic, \n",
      "        onClick=f\"\"\"fetch('/interrupt/{cell_id}', {{\n",
      "            method: 'POST', \n",
      "            headers: {{'Content-Type': 'application/json'}}, \n",
      "            body: JSON.stringify({{notebook: document.querySelector('.notebook-name')?.value || 'untitled'}})\n",
      "        }})\"\"\",\n",
      "        cls=cell_button_format)\n",
      "        \n",
      "\n",
      "# %% ../nbs/cells.ipynb 9\n",
      "class BaseCell:\n",
      "    \"\"\"Base class for all notebook cell types.\n",
      "    \n",
      "    Attributes:\n",
      "        cell_type (str): Type identifier ('markdown', 'code', 'llm').\n",
      "        source (str): Cell content/code.\n",
      "        outputs (list): Cell execution outputs (empty for markdown).\n",
      "        cell_id (str): Unique cell identifier.\n",
      "    \"\"\"\n",
      "    cell_type = None  \n",
      "    \n",
      "    def _make_markdown_init_script(self):\n",
      "        \"\"\" Scripts for managing Markdown display updating \"\"\"\n",
      "        return Script(f\"\"\"\n",
      "        (function() {{\n",
      "            const cell = document.querySelector('[data-cell-id=\"{self.cell_id}\"]');\n",
      "            if (!cell) return;  // Safety check\n",
      "            \n",
      "            const textarea = cell.querySelector('textarea.content-edit');\n",
      "            const renderdiv = cell.querySelector('.content-render');\n",
      "            const label = cell.querySelector('.toggle-label');\n",
      "            const checkbox = cell.querySelector('.toggle-edit');\n",
      "            \n",
      "            // Sync textarea to rendered\n",
      "            textarea.addEventListener('input', () => {{\n",
      "                renderdiv.innerHTML = marked.parse(textarea.value);\n",
      "                Prism.highlightAllUnder(renderdiv);\n",
      "            }});\n",
      "            \n",
      "            // Wire label to checkbox\n",
      "            label.addEventListener('click', () => {{ \n",
      "                checkbox.checked = !checkbox.checked; \n",
      "                checkbox.dispatchEvent(new Event('change')); \n",
      "            }});\n",
      "\n",
      "            textarea.style.height = 'auto';\n",
      "            textarea.style.height = Math.min(textarea.scrollHeight, 500) + 'px';\n",
      "            textarea.addEventListener('input', () => {{{{\n",
      "                textarea.style.height = 'auto';\n",
      "                textarea.style.height = Math.min(textarea.scrollHeight, 500) + 'px';\n",
      "            }}}});\n",
      "\n",
      "        }})();\n",
      "        \"\"\")\n",
      "\n",
      "    def __init__(self, source=\"\", outputs=\"\", cell_id=None):\n",
      "        \"\"\"Initialize a cell.\n",
      "        \n",
      "        Args:\n",
      "            source (str): Cell content. Defaults to \"\".\n",
      "            outputs (list, optional): Execution outputs. Defaults to [].\n",
      "            cell_id (str, optional): Unique ID. Generates UUID if None.\n",
      "        \"\"\"\n",
      "        self.source = source\n",
      "        self.cell_id = cell_id or uuid.uuid4().hex[:12]\n",
      "        self.outputs = outputs \n",
      "    \n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "        pass\n",
      "\n",
      "    def build_right_buttons(self):\n",
      "        \"\"\"Build common right buttons (move up/down/delete).\"\"\"\n",
      "        return Div(\n",
      "            Div(\n",
      "                Button(minimize_ic, \n",
      "                    onClick=f\"toggleMinimize('{self.cell_id}')\",\n",
      "                    cls=cell_button_format),\n",
      "                Button(up_arrow_ic,\n",
      "                    cls=cell_button_format,\n",
      "                    onClick=f\"moveUp('{self.cell_id}')\"),\n",
      "                Button(down_arrow_ic,\n",
      "                    cls=cell_button_format,\n",
      "                    onClick=f\"moveDown('{self.cell_id}')\"),\n",
      "                Button(close_ic,\n",
      "                    cls=cell_button_format,\n",
      "                    onClick=f\"deleteCell('{self.cell_id}')\"),\n",
      "                cls='btn-group'\n",
      "            ),\n",
      "            cls='flex justify-end'\n",
      "        )\n",
      "\n",
      "    def build_top_menu(self):\n",
      "        \"\"\"Build complete top menu bar with buttons and title.\"\"\"\n",
      "        display_name = self.cell_type.replace('_', ' ').title() + ' Cell'\n",
      "        return Div(\n",
      "            self.build_left_buttons(),\n",
      "            Div(display_name, style='font-size: 0.75rem; line-height: 1;'),\n",
      "            self.build_right_buttons(),\n",
      "            cls='flex justify-between items-center bg-gray-800 text-white py-0.5 px-2 rounded-t-lg border-b border-gray-700'\n",
      "        )\n",
      "\n",
      "    def build_markdown_source_area(self,source,round_b=True):\n",
      "        round_cls = 'rounded-b-lg' if round_b else ''\n",
      "\n",
      "        text_area = Textarea(source,\n",
      "                    placeholder='Enter Markdown Here...', \n",
      "                    rows=1,\n",
      "                    cls=f'w-full text-gray-100 p-4 bg-[#1e1e1e] {round_cls}'\\\n",
      "                    ' max-h-[500px] overflow-y-auto border-0 content-edit')\n",
      "\n",
      "        markdown_display = Div(NotStr(mistune.html(source)), \n",
      "                            cls='w-full markdown-body bg-gray-900 text-gray-100 p-4'\\\n",
      "                            f' {round_cls} max-h-[500px] overflow-y-auto content-render', \n",
      "                            style='list-style-position: inside; min-height: 3.5em;')\n",
      "\n",
      "\n",
      "        return [text_area, markdown_display]\n",
      "\n",
      "    def build_monaco_editor(self,cell_id,source_code='', min_height=20, max_height=500):\n",
      "    \n",
      "        monaco_editor_script = Script(f\"\"\"\n",
      "                                \n",
      "                require(['vs/editor/editor.main'], function() {{\n",
      "                    const sourceCode = {json.dumps(source_code)};\n",
      "                    const container = document.getElementById('monaco-{cell_id}');\n",
      "                    if (!container) return;\n",
      "                    \n",
      "                    const editor = monaco.editor.create(container, {{\n",
      "                        value: sourceCode,\n",
      "                        language: 'python',\n",
      "                        theme: 'vs-dark',\n",
      "                        automaticLayout: false,\n",
      "                        scrollBeyondLastLine: false,\n",
      "                        fontSize: 13, \n",
      "                        scrollBeyondLastColumn: 0,\n",
      "                        model: monaco.editor.createModel(sourceCode, 'python', \n",
      "                            monaco.Uri.parse(`inmemory://{cell_id}.py`))\n",
      "                    }});\n",
      "                    \n",
      "                    const lineCount = editor.getModel().getLineCount();\n",
      "                    const newHeight = Math.min(Math.max(lineCount * 19, {min_height}), {max_height});\n",
      "                    container.style.height = newHeight + 'px';\n",
      "                    editor.layout();\n",
      "\n",
      "                    editor.onDidChangeModelContent(() => {{\n",
      "                        const lineCount = editor.getModel().getLineCount();\n",
      "                        const newHeight = Math.min(Math.max(lineCount * 19,{min_height}), {max_height});\n",
      "                        container.style.height = newHeight + 'px';\n",
      "                        editor.layout(); \n",
      "                    }});\n",
      "                }});\n",
      "            \n",
      "                                \"\"\")\n",
      "        return monaco_editor_script\n",
      "\n",
      "    def build_code_output(self, tag='',min_height=100, max_height=300, outputs_json=[], round_b = False):\n",
      "\n",
      "        if round_b:\n",
      "            round_button_cls = 'rounded-b-lg' \n",
      "        else:\n",
      "            round_button_cls = ''\n",
      "            \n",
      "        output_area_code = Pre(\n",
      "                          style='font-family: Consolas, Monaco, monospace;'\\\n",
      "                           ' font-size: 13px; background-color: #111827;',\n",
      "                          cls=f'w-full bg-gray-900 text-gray-100 p-4 {round_button_cls}' \\\n",
      "                          f' min-h-[{min_height}px] max-h-[{max_height}px] overflow-y-auto border-0 output-display{tag}')\n",
      "                          \n",
      "        output_store_code = Div(\n",
      "            outputs_json,  # ← Make sure this has content\n",
      "            cls='output-store'+tag, \n",
      "            style='display:none;'\n",
      "        )\n",
      "\n",
      "        return [output_area_code, output_store_code]\n",
      "\n",
      "    def build_llm_output(self, tag='',min_height=100, max_height=300, outputs_json=\"\"):\n",
      "\n",
      "        output_store = Div(\n",
      "            outputs_json,  # ← Make sure this has content\n",
      "            cls='output-store'+tag, \n",
      "            style='display:none;'\n",
      "        )\n",
      "\n",
      "        output_area = Div(\n",
      "                        cls='w-full markdown-body bg-gray-900 text-gray-100 p-4 rounded-b-lg'\\\n",
      "                        f' min-h-[{min_height}px] max-h-[{max_height}px] overflow-y-auto border-0 output-display{tag}',\n",
      "                        style='background-color: #111827;',\n",
      "                        )\n",
      "\n",
      "        return [output_store, output_area]\n",
      "\n",
      "\n",
      "    def build_source_area(self):\n",
      "        \"\"\"Build editable source code/markdown area.\"\"\"\n",
      "        pass\n",
      "\n",
      "    def build_output_area(self):\n",
      "        \"\"\"Build output display area (if applicable).\"\"\"\n",
      "        pass\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\"Convert cell to Jupyter notebook dict format.\"\"\"\n",
      "        pass\n",
      "\n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\"Create cell from Jupyter notebook dict.\n",
      "        \n",
      "        Args:\n",
      "            cell_dict (dict): Jupyter cell structure.\n",
      "            \n",
      "        Returns:\n",
      "            BaseCell: Instantiated cell subclass.\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "        pass\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 11\n",
      "class PromptCell(BaseCell):\n",
      "\n",
      "    cell_type = 'prompt'\n",
      "\n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\" Load From Ipynb Dict\"\"\"\n",
      "        \n",
      "        source_txt = ''.join(cell_dict['source'])\n",
      "        if PROMPT_SPLIT in source_txt:\n",
      "            source, outputs = ''.join(source_txt).split(PROMPT_SPLIT)\n",
      "\n",
      "        else:\n",
      "            source = source_txt\n",
      "            outputs = ''\n",
      "\n",
      "        return cls(source=source, \n",
      "                outputs=outputs,\n",
      "                cell_id=cell_dict['id'])\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\" Build Ipynb Dict\"\"\"\n",
      "\n",
      "        out_dict = {\n",
      "            'id':self.cell_id,\n",
      "            'cell_type': 'markdown',\n",
      "            'metadata': {'id': self.cell_id, 'prompt_cell': True}\n",
      "        }\n",
      "        \n",
      "        # Combine source + outputs with separator\n",
      "        if self.outputs:\n",
      "            source_text = self.source + PROMPT_SPLIT + self.outputs\n",
      "        else:\n",
      "            source_text = self.source\n",
      "        \n",
      "        out_dict['source'] = source_text.splitlines(keepends=True)\n",
      "        \n",
      "        return out_dict\n",
      "\n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "        \n",
      "        return Div(\n",
      "                Div(\n",
      "                    Button(play_ic,\n",
      "                            onClick=f\"executePromptCell('{self.cell_id}')\",\n",
      "                            cls=cell_button_format),\n",
      "                    interrupt_button(self.cell_id),\n",
      "                    Button(clean_ic,\n",
      "                            onClick=f\"clearOutput('{self.cell_id}')\",\n",
      "                            cls=cell_button_format),\n",
      "                    Label(edit_ic,\n",
      "                            cls=cell_button_format + ' toggle-label'),\n",
      "                ),\n",
      "                cls='flex justify-start'\n",
      "                )\n",
      "\n",
      "    def build_output_area(self):\n",
      "        \"\"\"Build output display area (if applicable).\"\"\"\n",
      "        \n",
      "        outputs_json = self.outputs if self.outputs else ''\n",
      "        output_area = self.build_llm_output( tag='',min_height=50, max_height=400, outputs_json=outputs_json)\n",
      "\n",
      "        llm_out = Div(\"LLM Output\", cls=label_css),\n",
      "\n",
      "        return [llm_out,*output_area ]\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "\n",
      "        toggle_input = Input(type='checkbox', cls=\"hidden toggle-edit\")\n",
      "\n",
      "        menu_bar = self.build_top_menu()\n",
      "        source_area = self.build_markdown_source_area(self.source,round_b=False)\n",
      "        output_area = self.build_output_area()\n",
      "        \n",
      "        watch_script = Script(f\"\"\"\n",
      "            setTimeout(() => {{\n",
      "                watchOutputStore('{self.cell_id}');\n",
      "            }}, 50);\n",
      "        \"\"\")\n",
      "\n",
      "        return Div(\n",
      "            watch_script,\n",
      "            toggle_input,\n",
      "            menu_bar,\n",
      "            *source_area,\n",
      "            *output_area,\n",
      "            self._make_markdown_init_script(),\n",
      "            cls='w-full shadow-xl p-2',\n",
      "            data_cell_type=self.cell_type,\n",
      "            data_cell_id=self.cell_id\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 13\n",
      "class MarkdownCell(BaseCell):\n",
      "\n",
      "    cell_type = 'markdown'\n",
      "\n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\" Load From Ipynb Dict\"\"\"\n",
      "                \n",
      "        source = ''.join(cell_dict['source'])\n",
      "\n",
      "        return cls(source=source,\n",
      "                cell_id=cell_dict['id'])\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\" Build Ipynb Dict\"\"\"\n",
      "        \n",
      "        out_dict = {\n",
      "            'id':self.cell_id,\n",
      "            'cell_type': 'markdown',\n",
      "            'metadata': {'id': self.cell_id},\n",
      "            'source': self.source.splitlines(keepends=True)\n",
      "        }\n",
      "        \n",
      "        return out_dict\n",
      "\n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "\n",
      "        toggle_button = Label(edit_ic, cls=cell_button_format + ' toggle-label')\n",
      "        return Div( toggle_button, cls='flex justify-start')\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "\n",
      "        toggle_input = Input(type='checkbox', cls=\"hidden toggle-edit\")\n",
      "\n",
      "        menu_bar = self.build_top_menu()\n",
      "        source_area = self.build_markdown_source_area(self.source,round_b=True)\n",
      "\n",
      "\n",
      "        return Div(\n",
      "            toggle_input,\n",
      "            menu_bar,\n",
      "            *source_area,\n",
      "            self._make_markdown_init_script(),\n",
      "            cls='w-full shadow-xl p-2',\n",
      "            data_cell_type=self.cell_type,  \n",
      "            data_cell_id=self.cell_id\n",
      "        )\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 15\n",
      "class CodeCell(BaseCell):\n",
      "\n",
      "    cell_type = 'code'\n",
      "    \n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\" Load From Ipynb Dict\"\"\"\n",
      "                \n",
      "        source = ''.join(cell_dict['source'])\n",
      "        outputs = cell_dict['outputs']\n",
      "\n",
      "        return cls(source=source,\n",
      "                outputs = outputs,\n",
      "                cell_id=cell_dict['id'])\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\" Build Ipynb Dict\"\"\"\n",
      "        \n",
      "        out_dict = {\n",
      "            'id':self.cell_id,\n",
      "            'cell_type': 'code',\n",
      "            'execution_count': 1,\n",
      "            'metadata': {'id': self.cell_id},\n",
      "            'source': self.source.splitlines(keepends=True),\n",
      "            'outputs': self.outputs\n",
      "        }\n",
      "        \n",
      "        return out_dict\n",
      "\n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "        \n",
      "        return Div(\n",
      "                Div(\n",
      "                    Button(play_ic,\n",
      "                            onClick=f\"executeCell('{self.cell_id}')\",\n",
      "                            cls=cell_button_format),\n",
      "                    interrupt_button(self.cell_id),\n",
      "                    Button(clean_ic,\n",
      "                            onClick=f\"clearOutput('{self.cell_id}')\",\n",
      "                            cls=cell_button_format)\n",
      "                ),\n",
      "                cls='flex justify-start'\n",
      "                )\n",
      "\n",
      "    def build_source_area(self):\n",
      "        \"\"\"Build editable source code/markdown area.\"\"\"\n",
      "        \n",
      "        monaco_editor_script = self.build_monaco_editor(self.cell_id,self.source,min_height=20, max_height=500)\n",
      "\n",
      "        editor_div = Div(id=f'monaco-{self.cell_id}', \n",
      "                        style='height: 20px; width: 100%; overflow: hidden',\n",
      "                        cls='monaco-editor')\n",
      "        \n",
      "        return [editor_div, monaco_editor_script]\n",
      "\n",
      "    def build_output_area(self):\n",
      "        \"\"\"Build output display area (if applicable).\"\"\"\n",
      "        \n",
      "        outputs_json = json.dumps(self.outputs) if self.outputs else '[]'\n",
      "        output_area = self.build_code_output(min_height=50, max_height=400, outputs_json=outputs_json , round_b=True)\n",
      "\n",
      "        code_out = Div(\"Code Output\", cls=label_css),\n",
      "\n",
      "        return [code_out,*output_area]\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "\n",
      "        menu_bar = self.build_top_menu()\n",
      "        source_area = self.build_source_area()\n",
      "        output_area = self.build_output_area()\n",
      "\n",
      "        watch_script = Script(f\"\"\"\n",
      "                setTimeout(() => {{\n",
      "                    window.cellOutputs['{self.cell_id}'] = window.cellOutputs['{self.cell_id}'] || [];\n",
      "                    watchOutputStore('{self.cell_id}');\n",
      "                }}, 50);\n",
      "                \"\"\")\n",
      "                  \n",
      "        return Div(\n",
      "            watch_script,\n",
      "            menu_bar,\n",
      "            *source_area,\n",
      "            *output_area,\n",
      "            cls='w-full shadow-xl p-2',\n",
      "            data_cell_type=self.cell_type,\n",
      "            data_cell_id=self.cell_id\n",
      "        )\n",
      "\n",
      "\n",
      "# %% ../nbs/cells.ipynb 17\n",
      "class AgentCell(BaseCell):\n",
      "\n",
      "    cell_type = 'agent'\n",
      "\n",
      "\n",
      "    def __init__(self, source_prompt=\"\", source_code=\"\", outputs=\"\", outputs_llm=\"\",outputs_code=\"\", cell_id=None):\n",
      "        super().__init__(source=\"\", outputs=outputs, cell_id=cell_id)\n",
      "        self.source_prompt = source_prompt\n",
      "        self.source_code = source_code\n",
      "        self.outputs_llm = outputs_llm\n",
      "        self.outputs_code = outputs_code\n",
      "\n",
      "    @classmethod\n",
      "    def from_ipynb(cls, cell_dict):\n",
      "        \"\"\" Load From Ipynb Dict\"\"\"\n",
      "\n",
      "        source_txt = ''.join(cell_dict['source'])\n",
      "        code = \"\"  # ← Add default\n",
      "        if AGENT_CODE_SPLIT in source_txt:\n",
      "            prompt, code = source_txt.split(AGENT_CODE_SPLIT)\n",
      "            re_outputs = re.search(r'```python\\n(.*?)\\n```', code, re.DOTALL)\n",
      "            if re_outputs:\n",
      "                code = re_outputs.group(1)\n",
      "        else:\n",
      "            prompt = source_txt\n",
      "\n",
      "        return cls(source_prompt=prompt, \n",
      "                source_code=code,\n",
      "                cell_id=cell_dict['id'])\n",
      "\n",
      "    def to_ipynb(self):\n",
      "        \"\"\" Build Ipynb Dict\"\"\"\n",
      "\n",
      "        out_dict = {\n",
      "            'id':self.cell_id,\n",
      "            'cell_type': 'markdown',\n",
      "            'metadata': {'id': self.cell_id, 'agent_cell': True}\n",
      "        }\n",
      "        \n",
      "        # Combine prompt + code with separator\n",
      "        if self.source_code:\n",
      "            source_text = self.source_prompt + AGENT_CODE_SPLIT + '```python\\n' + self.source_code + '\\n```'\n",
      "        else:\n",
      "            source_text = self.source_prompt\n",
      "        \n",
      "        out_dict['source'] = source_text.splitlines(keepends=True)\n",
      "        \n",
      "        return out_dict\n",
      "\n",
      "    def build_left_buttons(self):\n",
      "        \"\"\"Build cell-specific left button group (play, stop, etc).\"\"\"\n",
      "        \n",
      "        return Div(\n",
      "                Div(\n",
      "                    Button(play_ic,\n",
      "                            onClick=f\"executeAgentCell('{self.cell_id}')\",\n",
      "                            cls=cell_button_format),\n",
      "                    interrupt_button(self.cell_id),\n",
      "                    Button(clean_ic,\n",
      "                            onClick=f\"clearOutput('{self.cell_id}')\",\n",
      "                            cls=cell_button_format),\n",
      "                    Label(edit_ic,\n",
      "                            cls=cell_button_format + ' toggle-label'),\n",
      "                ),\n",
      "                cls='flex justify-start'\n",
      "                )\n",
      "\n",
      "    def build_source_area(self):\n",
      "        \"\"\"Build editable source code/markdown area.\"\"\"\n",
      "\n",
      "        markdown_source = self.build_markdown_source_area(self.source_prompt,round_b=False)\n",
      "\n",
      "        monaco_editor_script = self.build_monaco_editor(self.cell_id,self.source_code,100,300)\n",
      "       \n",
      "\n",
      "        editor_div = Div(id=f'monaco-{self.cell_id}', \n",
      "                        style='height: 20px; width: 100%; overflow: hidden',\n",
      "                        cls='monaco-editor')\n",
      "\n",
      "        agent_in = Div(\"Prompt\", cls=label_css),\n",
      "\n",
      "        code_in = Div(\n",
      "            Div(\"Agent Code\", cls=\"flex-shrink-0\"),\n",
      "            Div(\"Idle\", id=f\"status\", \n",
      "                cls=\"flex-grow px-3 py-0.5 bg-gray-900 rounded text-center text-xs\"),\n",
      "            Div(\"Iteration: NA\", id=f\"iteration\",\n",
      "                cls=\"flex-shrink-0 px-2 py-0.5 bg-gray-900 rounded text-xs\"),\n",
      "            cls=\"flex items-center gap-2 text-xs text-gray-400 px-2 py-1 bg-gray-800\"\n",
      "        )\n",
      "\n",
      "\n",
      "        return [agent_in, *markdown_source,code_in,editor_div, monaco_editor_script]\n",
      "\n",
      "    def build_output_area(self):\n",
      "        \"\"\"Build output display area (if applicable).\"\"\"\n",
      "\n",
      "        ### Code Out\n",
      "        outputs_json = json.dumps(self.outputs_code) if self.outputs_code else '[]'\n",
      "        output_area_code = self.build_code_output(tag='-code',min_height=100, max_height=300, outputs_json=outputs_json, round_b=False)\n",
      "\n",
      "        ### LLM Out\n",
      "        outputs_json = self.outputs_llm if self.outputs_llm else ''\n",
      "        output_area_llm = self.build_llm_output( tag='-llm',min_height=100, max_height=300, outputs_json=outputs_json)\n",
      "\n",
      "\n",
      "        agent_out = Div(\"Agent Output\", cls=label_css),\n",
      "        code_out = Div(\"Unit Test Output\", cls=label_css),\n",
      "\n",
      "        return [code_out,*output_area_code,agent_out,*output_area_llm]\n",
      "\n",
      "    def render(self):\n",
      "        \"\"\"Render cell as FastHTML component tree.\"\"\"\n",
      "\n",
      "        toggle_input = Input(type='checkbox', cls=\"hidden toggle-edit\")\n",
      "\n",
      "        menu_bar = self.build_top_menu()\n",
      "        source_area = self.build_source_area()\n",
      "        output_area = self.build_output_area()\n",
      "        \n",
      "        watch_script = Script(f\"\"\"\n",
      "            setTimeout(() => {{\n",
      "                watchOutputStore('{self.cell_id}');\n",
      "            }}, 50);\n",
      "        \"\"\")\n",
      "\n",
      "        return Div(\n",
      "            watch_script,\n",
      "            toggle_input,\n",
      "            menu_bar,\n",
      "            *source_area,\n",
      "            *output_area,\n",
      "            self._make_markdown_init_script(),\n",
      "            cls='w-full shadow-xl p-2',\n",
      "            data_cell_type=self.cell_type,\n",
      "            data_cell_id=self.cell_id\n",
      "        )\n",
      "\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/llm.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/llm.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['RemoteToolLLM', 'send_llm_request']\n",
      "\n",
      "# %% ../nbs/llm.ipynb 2\n",
      "import json\n",
      "import requests\n",
      "import litellm\n",
      "\n",
      "from .app_config import MODEL, KERNEL_URL, NOTEBOOK_SYS_PROMPT\n",
      "from .llm_tools import TOOLS, TOOL_SCHEMAS\n",
      "\n",
      "litellm.drop_params = True\n",
      "\n",
      "\n",
      "# %% ../nbs/llm.ipynb 3\n",
      "class RemoteToolLLM:\n",
      "    \"\"\"LLM chat client that executes tools in Unreal Engine via url.\"\"\"\n",
      "    def __init__(self, model='gpt-4.1'):\n",
      "        \"\"\"\n",
      "        LLM chat that executes tools in Unreal Engine.\n",
      "        \n",
      "        Args:\n",
      "            model: LiteLLM model string\n",
      "        \"\"\"\n",
      "        self.model = model\n",
      "        \n",
      "        # Fetch available tools from Unreal\n",
      "        self.tools = self._fetch_tools()\n",
      "        self.local_tools = self._fetch_local_tools()\n",
      "        self.all_tools = self.tools + self.local_tools\n",
      "        print(f\"Connected to Unreal. Available tools: {[t['function']['name'] for t in self.all_tools]}\")\n",
      "    \n",
      "    def _fetch_tools(self):\n",
      "        \"\"\"Fetch tool schemas from Unreal endpoint.\n",
      "        \n",
      "        Returns:\n",
      "            List of tool schema dicts.\n",
      "        \"\"\"\n",
      "        response = requests.get(f'{KERNEL_URL}/tools')\n",
      "        return response.json()\n",
      "\n",
      "    def _fetch_local_tools(self):\n",
      "        \"\"\"Get locally registered tool schemas.\n",
      "        \n",
      "        Returns:\n",
      "            List of tool schema dicts.\n",
      "        \"\"\"\n",
      "        global TOOL_SCHEMAS\n",
      "        return TOOL_SCHEMAS\n",
      "    \n",
      "    def _execute_tool(self, func_name, args):\n",
      "        \"\"\"Execute a tool locally or in Unreal.\n",
      "        \n",
      "        Args:\n",
      "            func_name: Name of tool to execute.\n",
      "            args: Dict of arguments.\n",
      "            \n",
      "        Returns:\n",
      "            Tool result as string.\n",
      "        \"\"\"\n",
      "        if func_name in TOOLS:\n",
      "            try:\n",
      "                result = TOOLS[func_name](**args)\n",
      "                return str(result)\n",
      "            except Exception as e:\n",
      "                return f\"Local tool error: {str(e)}\"\n",
      "\n",
      "        response = requests.post(\n",
      "            f'{KERNEL_URL}/execute_tool',\n",
      "            json={'function': func_name, 'arguments': args}\n",
      "        )\n",
      "        data = response.json()\n",
      "        # Check if there's an error\n",
      "        if 'error' in data:\n",
      "            return f\"Error: {data['error']}\"\n",
      "        \n",
      "        # Check if result exists\n",
      "        if 'result' not in data:\n",
      "            return f\"Unexpected response: {data}\"\n",
      "        \n",
      "        return data['result']\n",
      "    \n",
      "    def chat(self, prompt, history=None, system_prompt=None, max_steps=50, stream=True):\n",
      "        \"\"\"Send message and handle tool calls automatically.\n",
      "        \n",
      "        Args:\n",
      "            prompt: User message.\n",
      "            history: Prior conversation messages.\n",
      "            system_prompt: System instruction.\n",
      "            max_steps: Max tool call iterations.\n",
      "            stream: Enable streaming output.\n",
      "            \n",
      "        Yields:\n",
      "            Text chunks for display.\n",
      "        \"\"\"\n",
      "        messages = []\n",
      "        # Add system prompt if this is the first message\n",
      "        if system_prompt:\n",
      "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
      "        if history:\n",
      "            messages += history\n",
      "        \n",
      "        # Add user message\n",
      "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
      "        \n",
      "        # Tool call loop\n",
      "        for step in range(max_steps):\n",
      "            # Call LLM\n",
      "            response = litellm.completion(\n",
      "                model=self.model,\n",
      "                messages=messages,\n",
      "                tools=self.all_tools,\n",
      "                stream=stream\n",
      "            )\n",
      "                \n",
      "            # Accumulate response\n",
      "            assistant_content = \"\"\n",
      "            tool_calls = []\n",
      "            \n",
      "            if stream:\n",
      "                for chunk in response:\n",
      "                    delta = chunk.choices[0].delta\n",
      "                    \n",
      "                    # Stream text content\n",
      "                    if hasattr(delta, 'content') and delta.content:\n",
      "                        assistant_content += delta.content\n",
      "                        yield delta.content  \n",
      "                    \n",
      "                    # Accumulate tool calls\n",
      "                    if hasattr(delta, 'tool_calls') and delta.tool_calls:\n",
      "                        tc = delta.tool_calls[0]\n",
      "                        idx = tc.index\n",
      "                        \n",
      "                        # Extend tool_calls list if needed\n",
      "                        while len(tool_calls) <= idx:\n",
      "                            tool_calls.append({\n",
      "                                'id': None,\n",
      "                                'function': {'name': '', 'arguments': ''},\n",
      "                                'type': 'function'\n",
      "                            })\n",
      "                        \n",
      "                        if tc.id:\n",
      "                            tool_calls[idx]['id'] = tc.id\n",
      "                        if hasattr(tc.function, 'name') and tc.function.name:\n",
      "                            tool_calls[idx]['function']['name'] += tc.function.name\n",
      "                        if hasattr(tc.function, 'arguments') and tc.function.arguments:\n",
      "                            tool_calls[idx]['function']['arguments'] += tc.function.arguments\n",
      "            else:\n",
      "                # Non-streaming\n",
      "                message = response.choices[0].message\n",
      "                assistant_content = message.content or \"\"\n",
      "                yield assistant_content  # \n",
      "                \n",
      "                if message.tool_calls:\n",
      "                    tool_calls = [\n",
      "                        {\n",
      "                            'id': tc.id,\n",
      "                            'function': {\n",
      "                                'name': tc.function.name,\n",
      "                                'arguments': tc.function.arguments\n",
      "                            },\n",
      "                            'type': 'function'\n",
      "                        }\n",
      "                        for tc in message.tool_calls\n",
      "                    ]\n",
      "            \n",
      "            # Add assistant message to history\n",
      "            assistant_msg = {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": assistant_content or None\n",
      "            }\n",
      "            if tool_calls:\n",
      "                assistant_msg[\"tool_calls\"] = tool_calls\n",
      "\n",
      "            messages.append(assistant_msg)\n",
      "            \n",
      "            # If no tool calls, we're done\n",
      "            if not tool_calls:\n",
      "                break\n",
      "            \n",
      "            # Execute tools in Unreal\n",
      "            for tc in tool_calls:\n",
      "                func_name = tc['function']['name']\n",
      "                try:\n",
      "                    args = json.loads(tc['function']['arguments'])\n",
      "                except:\n",
      "                    args = {}\n",
      "                \n",
      "                yield f\"\\n\\n🔧 Calling {func_name}({json.dumps(args)})...\\n\\n\"  \n",
      "                \n",
      "                # Call Unreal\n",
      "                result = self._execute_tool(func_name, args)\n",
      "                #yield f\"\\n\\n Result{result}...\\n\\n\"  #\n",
      "\n",
      "                # Add tool result to messages\n",
      "                messages.append({\n",
      "                    \"role\": \"tool\",\n",
      "                    \"tool_call_id\": tc['id'],\n",
      "                    \"content\": result\n",
      "                })\n",
      "    \n",
      "\n",
      "    \n",
      "    def refresh_tools(self):\n",
      "        \"\"\"Reload tools from Unreal (call after registering new tools).\"\"\"\n",
      "        self.tools = self._fetch_tools()\n",
      "\n",
      "\n",
      "def send_llm_request(prompt, history=None):\n",
      "    \"\"\"Stream LLM response with tool execution.\n",
      "    \n",
      "    Args:\n",
      "        prompt: User message.\n",
      "        history: Prior conversation messages.\n",
      "        \n",
      "    Yields:\n",
      "        Text chunks from LLM response.\n",
      "    \"\"\"\n",
      "    chat = RemoteToolLLM( model=MODEL)\n",
      "    \n",
      "    for chunk in chat.chat(prompt,\n",
      "                            history=history,\n",
      "                            system_prompt=NOTEBOOK_SYS_PROMPT):\n",
      "        yield chunk\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/streaming.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/streaming.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['active_streams', 'SSEStream']\n",
      "\n",
      "# %% ../nbs/streaming.ipynb 2\n",
      "import queue\n",
      "import asyncio\n",
      "import json\n",
      "from starlette.responses import StreamingResponse\n",
      "\n",
      "\n",
      "active_streams = {}\n",
      "\n",
      "\n",
      "class SSEStream:\n",
      "    \"\"\"Unified SSE streaming with queue-based message passing.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique identifier for abort handling.\n",
      "    \"\"\"\n",
      "    def __init__(self, stream_key):\n",
      "        self.stream_key = stream_key  \n",
      "        self.q = queue.Queue()\n",
      "        active_streams[stream_key] = {'abort': False}\n",
      "    \n",
      "    def text(self, content: str):\n",
      "        \"\"\"Send text chunk to stream.\n",
      "        \n",
      "        Args:\n",
      "            content: String to send.\n",
      "        \"\"\"\n",
      "        self.q.put({\"type\": \"text\", \"data\": content})\n",
      "\n",
      "    def tag(self, content: str):\n",
      "        \"\"\"Send control tag to switch stream target.\n",
      "        \n",
      "        Args:\n",
      "            content: Tag name.\n",
      "        \"\"\"\n",
      "        self.q.put({\"type\": \"tag\", \"data\": content})\n",
      "    \n",
      "    def output(self, data):\n",
      "        \"\"\"Send Jupyter-style output dict.\n",
      "        \n",
      "        Args:\n",
      "            data: Output dict/list (may contain ANSI).\n",
      "        \"\"\"\n",
      "        self.q.put({\"type\": \"output\", \"data\": data})\n",
      "        \n",
      "    def done(self):\n",
      "        \"\"\"Signal stream complete and cleanup.\"\"\"\n",
      "        self.q.put(None)\n",
      "        self.cleanup()\n",
      "\n",
      "    def aborted(self):\n",
      "        \"\"\"Check if user requested abort.\n",
      "        \n",
      "        Returns:\n",
      "            True if aborted, False otherwise.\n",
      "        \"\"\"\n",
      "        return active_streams.get(self.stream_key, {}).get('abort', True)\n",
      "\n",
      "    def response(self):\n",
      "        \"\"\"Create async SSE response.\n",
      "        \n",
      "        Returns:\n",
      "            StreamingResponse for FastHTML route.\n",
      "        \"\"\"\n",
      "        async def generator():\n",
      "            while True:\n",
      "                item = await asyncio.to_thread(self.q.get)\n",
      "                if item is None: break\n",
      "                yield f\"data: {json.dumps(item)}\\n\\n\"\n",
      "            self.cleanup()\n",
      "        return StreamingResponse(generator(), media_type='text/event-stream')\n",
      "\n",
      "    def cleanup(self):\n",
      "        \"\"\"Remove cell_id from active_streams.\"\"\"\n",
      "        active_streams.pop(self.stream_key, None)\n",
      "        \n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/notebook_io.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/notebook_io.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['reconstruct_cells_from_history', 'reconstruct_ipynb_cell', 'prepare_chat_history', 'is_ask_cell', 'prep_prompt_cell',\n",
      "           'seperate_markdown', 'prep_markdown_cell', 'format_for_chat', 'prep_code_cell', 'prep_code_cell_output']\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 2\n",
      "import io\n",
      "import base64\n",
      "import json\n",
      "from PIL import Image\n",
      "from .cells import MarkdownCell, CodeCell, PromptCell, AgentCell\n",
      "from .app_config import PROMPT_SPLIT\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 3\n",
      "def reconstruct_cells_from_history(notebook_history):\n",
      "    \"\"\"Convert raw JavaScript cell data into rendered cell objects.\n",
      "    \n",
      "    Args:\n",
      "        notebook_history: List of cell dicts from JavaScript with keys:\n",
      "            cell_type, cell_id, source, outputs.\n",
      "    \n",
      "    Returns:\n",
      "        List of cell objects (MarkdownCell, CodeCell, or PromptCell).\n",
      "    \n",
      "    Raises:\n",
      "        ValueError: If cell_type is unknown.\n",
      "    \"\"\"    \n",
      "    cells = []\n",
      "    \n",
      "    for cell_data in notebook_history:\n",
      "        cell_type = cell_data['cell_type']\n",
      "        cell_id = cell_data['cell_id']\n",
      "        source = cell_data['source']\n",
      "        outputs = cell_data.get('outputs')\n",
      "        \n",
      "        if cell_type == 'markdown':\n",
      "            cell = MarkdownCell(source=source, cell_id=cell_id)\n",
      "        \n",
      "        elif cell_type == 'code':\n",
      "            cell = CodeCell(source=source, outputs=outputs or [], cell_id=cell_id)\n",
      "        \n",
      "        elif cell_type == 'prompt':\n",
      "            cell = PromptCell(source=source, outputs=outputs or '', cell_id=cell_id)\n",
      "\n",
      "        elif cell_type == 'agent':\n",
      "            cell = AgentCell(source_prompt=source, source_code=outputs, cell_id=cell_id)\n",
      "        else:\n",
      "            raise ValueError(f\"Unknown cell type: {cell_type}\")\n",
      "        \n",
      "        cells.append(cell)\n",
      "    \n",
      "    return cells\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 4\n",
      "def reconstruct_ipynb_cell(cell):\n",
      "    \"\"\"Convert a Jupyter notebook cell dict to the appropriate cell class.\n",
      "    \n",
      "    Args:\n",
      "        cell: Dict with 'cell_type', 'metadata', and type-specific keys.\n",
      "            Markdown cells may have 'agent_cell' or 'prompt_cell' in metadata.\n",
      "    \n",
      "    Returns:\n",
      "        MarkdownCell, CodeCell, PromptCell, AgentCell, or None if unknown type.\n",
      "    \"\"\"\n",
      "    jup_cell_type = cell['cell_type']\n",
      "\n",
      "    if jup_cell_type == 'markdown':\n",
      "        if 'agent_cell' in cell['metadata']:\n",
      "            cell_type = 'agent'\n",
      "        elif 'prompt_cell' in cell['metadata']:\n",
      "            cell_type = 'prompt'\n",
      "        else:\n",
      "            cell_type = 'markdown'\n",
      "    else:\n",
      "        cell_type = jup_cell_type\n",
      "    \n",
      "    \n",
      "    if cell_type == 'markdown':\n",
      "        return MarkdownCell.from_ipynb(cell)\n",
      "    if cell_type == 'code':\n",
      "        return CodeCell.from_ipynb(cell)\n",
      "    elif cell_type == 'prompt':\n",
      "        return PromptCell.from_ipynb(cell)\n",
      "    elif cell_type == 'agent':\n",
      "        return AgentCell.from_ipynb(cell)\n",
      "    \n",
      "    else:\n",
      "        return None\n",
      "\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 5\n",
      "def prepare_chat_history(cell_list):\n",
      "    \"\"\"\n",
      "    Converts a list of notebook cells into a conversation history for the LLM.\n",
      "\n",
      "    Args:\n",
      "        cell_list (list): List of notebook cells.\n",
      "\n",
      "    Returns:\n",
      "        list: A list of message dictionaries (role/content) for the Chat API.\n",
      "    \"\"\"\n",
      "    cell_context = []\n",
      "    for cell in cell_list:\n",
      "        cell_type = cell['cell_type']\n",
      "\n",
      "        if cell_type == 'markdown':\n",
      "\n",
      "            if is_ask_cell(cell):\n",
      "                    question, answer = prep_prompt_cell(cell)\n",
      "                    formatted_q = format_for_chat(question)\n",
      "                    cell_context.append( {\"role\": \"user\", \"content\": formatted_q} )\n",
      "                    formatted_a = format_for_chat(answer)\n",
      "                    cell_context.append( {\"role\": \"assistant\", \"content\": formatted_a} )\n",
      "            else:\n",
      "                formatted = format_for_chat(prep_markdown_cell(cell))\n",
      "                if formatted:\n",
      "\n",
      "                    cell_context.append( {\"role\": \"user\", \"content\": formatted} )\n",
      "\n",
      "        elif cell_type == 'code':\n",
      "\n",
      "            sub_type = 'Code'\n",
      "            response_role = 'user'\n",
      "\n",
      "            formatted = format_for_chat(prep_code_cell(cell,cell_type=sub_type))\n",
      "            if formatted:\n",
      "                cell_context.append( {\"role\": \"user\", \"content\": formatted} )\n",
      "\n",
      "            formatted = format_for_chat(prep_code_cell_output(cell,cell_type=sub_type))\n",
      "            if formatted:\n",
      "                cell_context.append( {\"role\": response_role, \"content\":formatted} )\n",
      "    return cell_context\n",
      "\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 6\n",
      "def is_ask_cell(cell):\n",
      "    \"\"\"Check if a cell is a prompt cell with a response.\n",
      "    \n",
      "    Args:\n",
      "        cell (dict): The JSON dictionary representing a cell.\n",
      "        \n",
      "    Returns:\n",
      "        bool: True if cell contains the prompt/response separator, False otherwise.\n",
      "    \"\"\"\n",
      "    source = cell['source']\n",
      "    try:\n",
      "        split_index =  source.index(PROMPT_SPLIT[2:-1])\n",
      "        return True\n",
      "    except:\n",
      "        return False\n",
      "         \n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 7\n",
      "def prep_prompt_cell(cell):\n",
      "    \"\"\"\n",
      "    Extracts text and embedded images from a markdown cell.\n",
      "\n",
      "    Args:\n",
      "        cell (dict): The JSON dictionary representing a markdown cell.\n",
      "\n",
      "    Returns:\n",
      "        tuple (list): Two lists containing strings (text content) and bytes (decoded image data).\n",
      "    \"\"\"\n",
      "    source = cell['source']\n",
      "    try:\n",
      "        split_index =  source.index(PROMPT_SPLIT[2:-1])\n",
      "        question = seperate_markdown(source[:split_index-1])\n",
      "        answer = seperate_markdown(source[split_index+2:])\n",
      "    except:\n",
      "        question = seperate_markdown(source)\n",
      "        answer = []\n",
      "\n",
      "    formatted_question = ['## User Question Cell\\n']+question\n",
      "    return formatted_question, answer\n",
      "\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 8\n",
      "def seperate_markdown(markdown):\n",
      "    \"\"\"Separate markdown text blocks from embedded base64 images.\n",
      "    \n",
      "    Args:\n",
      "        markdown: List of markdown content strings, potentially containing\n",
      "            embedded base64 images in the format `(data:image/...;base64,...)`.\n",
      "    \n",
      "    Returns:\n",
      "        List containing strings for text blocks and bytes for decoded images.\n",
      "    \"\"\"\n",
      "    out_list = []\n",
      "    for block in markdown:\n",
      "\n",
      "        if \"(data:image/\" in block:\n",
      "            base_64_text = block.split('base64,')[1]\n",
      "            base_64_text = base_64_text.split(')')[0]\n",
      "            output_image_bytes =  base64.b64decode(base_64_text)\n",
      "            out_list.append(output_image_bytes )\n",
      " \n",
      "        else:\n",
      "            out_list.append(block)\n",
      "    return out_list\n",
      "\n",
      "\n",
      "# %% ../nbs/notebook_io.ipynb 9\n",
      "def prep_markdown_cell(markdown_cell):\n",
      "    \"\"\"\n",
      "    Extracts text and embedded images from a markdown cell.\n",
      "\n",
      "    Args:\n",
      "        markdown_cell (dict): The JSON dictionary representing a markdown cell.\n",
      "\n",
      "    Returns:\n",
      "        list: A list containing strings (text content) and bytes (decoded image data).\n",
      "    \"\"\"\n",
      "    output_list = ['## Markdown Cell\\n']\n",
      "\n",
      "    for block in markdown_cell['source']:\n",
      "        if \"(data:image/\" in block:\n",
      "            base_64_text = block.split('base64,')[1]\n",
      "            base_64_text = base_64_text.split(')')[0]\n",
      "            output_image_bytes =  base64.b64decode(base_64_text)\n",
      "            output_list.append(output_image_bytes )\n",
      " \n",
      "        else:\n",
      "            output_list.append(block)\n",
      "    return output_list\n",
      "    \n",
      "\n",
      "def format_for_chat(items):\n",
      "    \"\"\"\n",
      "    Formats a list of mixed text and image bytes into the OpenAI/LiteLLM message structure.\n",
      "\n",
      "    Args:\n",
      "        items (list): A list containing strings or byte objects.\n",
      "\n",
      "    Returns:\n",
      "        list: A list of dictionaries with 'type' (text/image_url) keys.\n",
      "    \"\"\"\n",
      "    formatted = []\n",
      "    \n",
      "    for item in items:\n",
      "        if isinstance(item,str):\n",
      "            if item != '':\n",
      "                formatted.append( {\"type\": \"text\", \"text\": item})\n",
      "        elif isinstance(item,bytes):\n",
      "            img = Image.open(io.BytesIO(item))\n",
      "            img_format = img.format.lower()\n",
      "            base64_string = base64.b64encode(item).decode('utf-8')\n",
      "            formatted.append( {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/{img_format};base64,{base64_string}\"}})\n",
      "    \n",
      "    return formatted\n",
      "\n",
      "\n",
      "def prep_code_cell(code_cell,cell_type='Code'):\n",
      "    \"\"\"\n",
      "    Extracts and labels source code from a code cell.\n",
      "\n",
      "    Args:\n",
      "        code_cell (dict): The JSON dictionary representing a code cell.\n",
      "        cell_type (str, optional): Label for the cell. Defaults to 'Code'.\n",
      "\n",
      "    Returns:\n",
      "        list: A list containing the labeled header and the source code string.\n",
      "    \"\"\"\n",
      "    output_list = [f'{cell_type} Cell\\n']\n",
      "\n",
      "    code_input = ''.join(code_cell['source'])\n",
      "    output_list.append(code_input)\n",
      "\n",
      "    return output_list\n",
      "\n",
      "\n",
      "def prep_code_cell_output(code_cell,cell_type='Code'):\n",
      "    \"\"\"\n",
      "    Extracts outputs (logs, streams, errors, images) from a code cell.\n",
      "\n",
      "    Args:\n",
      "        code_cell (dict): The JSON dictionary representing a code cell.\n",
      "        cell_type (str, optional): Label for the cell. Defaults to 'Code'.\n",
      "\n",
      "    Returns:\n",
      "        list: A list containing text output, error traces, or image bytes.\n",
      "    \"\"\"\n",
      "    if cell_type == 'Code':\n",
      "        output_list = ['### Code Cell Output\\n']\n",
      "    else:\n",
      "        output_list = []\n",
      "        \n",
      "    for block in code_cell['outputs']:\n",
      "        if block['output_type'] in ['display_data', 'execute_result']:\n",
      "            for key in  block['data'].keys():\n",
      "\n",
      "                out_data = None\n",
      "                block_data = block['data'][key]\n",
      "\n",
      "                if key.endswith('json'):\n",
      "                    try:\n",
      "                        out_data = json.dumps(block_data,indent=4)\n",
      "\n",
      "                    except Exception as e:\n",
      "                        out_data = f'[Un-Serializable JSON Output: {key}]'\n",
      "\n",
      "                elif key.startswith('image'):\n",
      "                    try:\n",
      "                        out_data = base64.b64decode(block_data)\n",
      "\n",
      "                    except Exception as e:\n",
      "                        out_data = f'[Un-Encodable Image Output: {key}]'\n",
      "\n",
      "                elif key.startswith('text'):\n",
      "                    if isinstance(block_data, list):\n",
      "                        out_data = \"\".join(block_data)\n",
      "                    else:\n",
      "                        out_data = block_data\n",
      "                else:\n",
      "                    out_data = f'[Un-Renderable Output Type: {key}]'\n",
      "                \n",
      "                output_list.append(out_data)\n",
      "\n",
      "\n",
      "        elif block['output_type'] == 'stream':\n",
      "            output_list.append(''.join(block['text']))\n",
      "\n",
      "        elif block['output_type'] == 'error' :\n",
      "            output_list.append('#### Error\\n')  \n",
      "            output_list.append(f'evalue:{block[\"evalue\"]}\\n\\n traceback:{block[\"traceback\"]}')  \n",
      "\n",
      "\n",
      "    return output_list\n",
      "    \n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/__init__.py\n",
      "============================================================\n",
      "__version__ = \"0.0.1\"\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/_modidx.py\n",
      "============================================================\n",
      "# Autogenerated by nbdev\n",
      "\n",
      "d = { 'settings': { 'branch': 'main',\n",
      "                'doc_baseurl': '/unreal-llm-sandbox',\n",
      "                'doc_host': 'https://NeuralVFX.github.io',\n",
      "                'git_url': 'https://github.com/NeuralVFX/unreal-llm-sandbox',\n",
      "                'lib_path': 'unreal_llm_sandbox'},\n",
      "  'syms': { 'unreal_llm_sandbox.agent': { 'unreal_llm_sandbox.agent.AgentTools': ('agent.html#agenttools', 'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.__init__': ( 'agent.html#agenttools.__init__',\n",
      "                                                                                            'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.chat_history_swap': ( 'agent.html#agenttools.chat_history_swap',\n",
      "                                                                                                     'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.collect': ( 'agent.html#agenttools.collect',\n",
      "                                                                                           'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.collect_llm_stream': ( 'agent.html#agenttools.collect_llm_stream',\n",
      "                                                                                                      'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.generate_code': ( 'agent.html#agenttools.generate_code',\n",
      "                                                                                                 'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.get_tools': ( 'agent.html#agenttools.get_tools',\n",
      "                                                                                             'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.improve_code': ( 'agent.html#agenttools.improve_code',\n",
      "                                                                                                'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.print_update': ( 'agent.html#agenttools.print_update',\n",
      "                                                                                                'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.read_url': ( 'agent.html#agenttools.read_url',\n",
      "                                                                                            'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.search_web': ( 'agent.html#agenttools.search_web',\n",
      "                                                                                              'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.AgentTools.unit_test': ( 'agent.html#agenttools.unit_test',\n",
      "                                                                                             'unreal_llm_sandbox/agent.py'),\n",
      "                                          'unreal_llm_sandbox.agent.SentimentChecker': ( 'agent.html#sentimentchecker',\n",
      "                                                                                         'unreal_llm_sandbox/agent.py')},\n",
      "            'unreal_llm_sandbox.app_config': {},\n",
      "            'unreal_llm_sandbox.cells': { 'unreal_llm_sandbox.cells.AgentCell': ('cells.html#agentcell', 'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.AgentCell.__init__': ( 'cells.html#agentcell.__init__',\n",
      "                                                                                           'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.AgentCell.build_left_buttons': ( 'cells.html#agentcell.build_left_buttons',\n",
      "                                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.AgentCell.build_output_area': ( 'cells.html#agentcell.build_output_area',\n",
      "                                                                                                    'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.AgentCell.build_source_area': ( 'cells.html#agentcell.build_source_area',\n",
      "                                                                                                    'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.AgentCell.from_ipynb': ( 'cells.html#agentcell.from_ipynb',\n",
      "                                                                                             'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.AgentCell.render': ( 'cells.html#agentcell.render',\n",
      "                                                                                         'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.AgentCell.to_ipynb': ( 'cells.html#agentcell.to_ipynb',\n",
      "                                                                                           'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell': ('cells.html#basecell', 'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.__init__': ( 'cells.html#basecell.__init__',\n",
      "                                                                                          'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell._make_markdown_init_script': ( 'cells.html#basecell._make_markdown_init_script',\n",
      "                                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_code_output': ( 'cells.html#basecell.build_code_output',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_left_buttons': ( 'cells.html#basecell.build_left_buttons',\n",
      "                                                                                                    'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_llm_output': ( 'cells.html#basecell.build_llm_output',\n",
      "                                                                                                  'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_markdown_source_area': ( 'cells.html#basecell.build_markdown_source_area',\n",
      "                                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_monaco_editor': ( 'cells.html#basecell.build_monaco_editor',\n",
      "                                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_output_area': ( 'cells.html#basecell.build_output_area',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_right_buttons': ( 'cells.html#basecell.build_right_buttons',\n",
      "                                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_source_area': ( 'cells.html#basecell.build_source_area',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.build_top_menu': ( 'cells.html#basecell.build_top_menu',\n",
      "                                                                                                'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.from_ipynb': ( 'cells.html#basecell.from_ipynb',\n",
      "                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.render': ( 'cells.html#basecell.render',\n",
      "                                                                                        'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.BaseCell.to_ipynb': ( 'cells.html#basecell.to_ipynb',\n",
      "                                                                                          'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell': ('cells.html#codecell', 'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.build_left_buttons': ( 'cells.html#codecell.build_left_buttons',\n",
      "                                                                                                    'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.build_output_area': ( 'cells.html#codecell.build_output_area',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.build_source_area': ( 'cells.html#codecell.build_source_area',\n",
      "                                                                                                   'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.from_ipynb': ( 'cells.html#codecell.from_ipynb',\n",
      "                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.render': ( 'cells.html#codecell.render',\n",
      "                                                                                        'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.CodeCell.to_ipynb': ( 'cells.html#codecell.to_ipynb',\n",
      "                                                                                          'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell': ( 'cells.html#markdowncell',\n",
      "                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell.build_left_buttons': ( 'cells.html#markdowncell.build_left_buttons',\n",
      "                                                                                                        'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell.from_ipynb': ( 'cells.html#markdowncell.from_ipynb',\n",
      "                                                                                                'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell.render': ( 'cells.html#markdowncell.render',\n",
      "                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.MarkdownCell.to_ipynb': ( 'cells.html#markdowncell.to_ipynb',\n",
      "                                                                                              'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell': ('cells.html#promptcell', 'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.build_left_buttons': ( 'cells.html#promptcell.build_left_buttons',\n",
      "                                                                                                      'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.build_output_area': ( 'cells.html#promptcell.build_output_area',\n",
      "                                                                                                     'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.from_ipynb': ( 'cells.html#promptcell.from_ipynb',\n",
      "                                                                                              'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.render': ( 'cells.html#promptcell.render',\n",
      "                                                                                          'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.PromptCell.to_ipynb': ( 'cells.html#promptcell.to_ipynb',\n",
      "                                                                                            'unreal_llm_sandbox/cells.py'),\n",
      "                                          'unreal_llm_sandbox.cells.interrupt_button': ( 'cells.html#interrupt_button',\n",
      "                                                                                         'unreal_llm_sandbox/cells.py')},\n",
      "            'unreal_llm_sandbox.config': {},\n",
      "            'unreal_llm_sandbox.kernel': { 'unreal_llm_sandbox.kernel.convert_to_accumulated': ( 'kernel.html#convert_to_accumulated',\n",
      "                                                                                                 'unreal_llm_sandbox/kernel.py'),\n",
      "                                           'unreal_llm_sandbox.kernel.execute_unreal_code': ( 'kernel.html#execute_unreal_code',\n",
      "                                                                                              'unreal_llm_sandbox/kernel.py'),\n",
      "                                           'unreal_llm_sandbox.kernel.format_kernel_stream': ( 'kernel.html#format_kernel_stream',\n",
      "                                                                                               'unreal_llm_sandbox/kernel.py'),\n",
      "                                           'unreal_llm_sandbox.kernel.strip_ansi': ( 'kernel.html#strip_ansi',\n",
      "                                                                                     'unreal_llm_sandbox/kernel.py')},\n",
      "            'unreal_llm_sandbox.llm': { 'unreal_llm_sandbox.llm.RemoteToolLLM': ('llm.html#remotetoolllm', 'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.RemoteToolLLM.__init__': ( 'llm.html#remotetoolllm.__init__',\n",
      "                                                                                           'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.RemoteToolLLM._execute_tool': ( 'llm.html#remotetoolllm._execute_tool',\n",
      "                                                                                                'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.RemoteToolLLM._fetch_local_tools': ( 'llm.html#remotetoolllm._fetch_local_tools',\n",
      "                                                                                                     'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.RemoteToolLLM._fetch_tools': ( 'llm.html#remotetoolllm._fetch_tools',\n",
      "                                                                                               'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.RemoteToolLLM.chat': ( 'llm.html#remotetoolllm.chat',\n",
      "                                                                                       'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.RemoteToolLLM.refresh_tools': ( 'llm.html#remotetoolllm.refresh_tools',\n",
      "                                                                                                'unreal_llm_sandbox/llm.py'),\n",
      "                                        'unreal_llm_sandbox.llm.send_llm_request': ( 'llm.html#send_llm_request',\n",
      "                                                                                     'unreal_llm_sandbox/llm.py')},\n",
      "            'unreal_llm_sandbox.llm_tools': { 'unreal_llm_sandbox.llm_tools.get_tools': ( 'llm_tools.html#get_tools',\n",
      "                                                                                          'unreal_llm_sandbox/llm_tools.py'),\n",
      "                                              'unreal_llm_sandbox.llm_tools.read_url': ( 'llm_tools.html#read_url',\n",
      "                                                                                         'unreal_llm_sandbox/llm_tools.py'),\n",
      "                                              'unreal_llm_sandbox.llm_tools.register_tool': ( 'llm_tools.html#register_tool',\n",
      "                                                                                              'unreal_llm_sandbox/llm_tools.py'),\n",
      "                                              'unreal_llm_sandbox.llm_tools.search_web': ( 'llm_tools.html#search_web',\n",
      "                                                                                           'unreal_llm_sandbox/llm_tools.py')},\n",
      "            'unreal_llm_sandbox.main': { 'unreal_llm_sandbox.main.Toolbar': ('main.html#toolbar', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.add_cell': ('main.html#add_cell', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.agent_stream': ('main.html#agent_stream', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.exe_code': ('main.html#exe_code', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.exe_prompt': ('main.html#exe_prompt', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.interrupt': ('main.html#interrupt', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.load_notebook': ('main.html#load_notebook', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.save_notebook': ('main.html#save_notebook', 'unreal_llm_sandbox/main.py'),\n",
      "                                         'unreal_llm_sandbox.main.start_server': ('main.html#start_server', 'unreal_llm_sandbox/main.py')},\n",
      "            'unreal_llm_sandbox.notebook_io': { 'unreal_llm_sandbox.notebook_io.format_for_chat': ( 'notebook_io.html#format_for_chat',\n",
      "                                                                                                    'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.is_ask_cell': ( 'notebook_io.html#is_ask_cell',\n",
      "                                                                                                'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prep_code_cell': ( 'notebook_io.html#prep_code_cell',\n",
      "                                                                                                   'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prep_code_cell_output': ( 'notebook_io.html#prep_code_cell_output',\n",
      "                                                                                                          'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prep_markdown_cell': ( 'notebook_io.html#prep_markdown_cell',\n",
      "                                                                                                       'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prep_prompt_cell': ( 'notebook_io.html#prep_prompt_cell',\n",
      "                                                                                                     'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.prepare_chat_history': ( 'notebook_io.html#prepare_chat_history',\n",
      "                                                                                                         'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.reconstruct_cells_from_history': ( 'notebook_io.html#reconstruct_cells_from_history',\n",
      "                                                                                                                   'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.reconstruct_ipynb_cell': ( 'notebook_io.html#reconstruct_ipynb_cell',\n",
      "                                                                                                           'unreal_llm_sandbox/notebook_io.py'),\n",
      "                                                'unreal_llm_sandbox.notebook_io.seperate_markdown': ( 'notebook_io.html#seperate_markdown',\n",
      "                                                                                                      'unreal_llm_sandbox/notebook_io.py')},\n",
      "            'unreal_llm_sandbox.scripts': {},\n",
      "            'unreal_llm_sandbox.streaming': { 'unreal_llm_sandbox.streaming.SSEStream': ( 'streaming.html#ssestream',\n",
      "                                                                                          'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.__init__': ( 'streaming.html#ssestream.__init__',\n",
      "                                                                                                   'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.aborted': ( 'streaming.html#ssestream.aborted',\n",
      "                                                                                                  'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.cleanup': ( 'streaming.html#ssestream.cleanup',\n",
      "                                                                                                  'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.done': ( 'streaming.html#ssestream.done',\n",
      "                                                                                               'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.output': ( 'streaming.html#ssestream.output',\n",
      "                                                                                                 'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.response': ( 'streaming.html#ssestream.response',\n",
      "                                                                                                   'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.tag': ( 'streaming.html#ssestream.tag',\n",
      "                                                                                              'unreal_llm_sandbox/streaming.py'),\n",
      "                                              'unreal_llm_sandbox.streaming.SSEStream.text': ( 'streaming.html#ssestream.text',\n",
      "                                                                                               'unreal_llm_sandbox/streaming.py')}}}\n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/main.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/main.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['CSS', 'daisy_hdrs', 'app', 'rt', 'interrupt', 'exe_prompt', 'exe_code', 'agent_stream', 'Toolbar', 'add_cell',\n",
      "           'load_notebook', 'save_notebook', 'start_server']\n",
      "\n",
      "# %% ../nbs/main.ipynb 3\n",
      "CSS = \"\"\"\n",
      ".markdown-body { \n",
      "    background-color: bg-gray-900 !important; \n",
      "}\n",
      ".markdown-body ul { \n",
      "    list-style-type: disc !important; \n",
      "    padding-left: 2em !important; \n",
      "}\n",
      ".markdown-body ol { \n",
      "    list-style-type: decimal !important; \n",
      "    padding-left: 2em !important; \n",
      "}\n",
      "[data-cell-id].minimized .output-display-llm,\n",
      "[data-cell-id].minimized .output-display-code {\n",
      "    display: none !important;\n",
      "}\n",
      "[data-cell-id].minimized .content-edit,\n",
      "[data-cell-id].minimized .content-render,\n",
      "[data-cell-id].minimized .output-display,\n",
      "[data-cell-id].minimized .text-gray-400 {\n",
      "    display: none;\n",
      "}\n",
      "[data-cell-id].minimized .content-edit,\n",
      "[data-cell-id].minimized .content-render {\n",
      "    display: none !important;\n",
      "}\n",
      "[data-cell-id].minimized .monaco-editor,\n",
      "[data-cell-id].minimized .content-edit,\n",
      "[data-cell-id].minimized .content-render,\n",
      "[data-cell-id].minimized .output-display {\n",
      "    max-height: 0 !important;\n",
      "    overflow: hidden;\n",
      "}\n",
      "[data-cell-id].minimized .bg-gray-800 {\n",
      "    opacity: 0.5 !important;\n",
      "}\n",
      "body {\n",
      "    background-color: #070707 !important;  /* 95% black = 5% brightness */\n",
      "}\n",
      ".markdown-body { \n",
      "    background-color: bg-gray-900 !important;\n",
      "    font-size: 0.825rem !important;  /* ← Smaller base size */\n",
      "}\n",
      ".markdown-body h1 { font-size: 1.25rem !important; }\n",
      ".markdown-body h2 { font-size: 1.1rem !important; }\n",
      ".markdown-body h3 { font-size: 1.0rem !important; }\n",
      ".markdown-body ul, .markdown-body ol { \n",
      "    list-style-type: disc !important; \n",
      "    padding-left: 2em !important;\n",
      "    font-size: 0.825rem !important;  /* ← Match body */\n",
      "}\n",
      ".content-edit {\n",
      "    font-size: 0.825rem !important;  /* ← Textarea size */\n",
      "}\n",
      "\n",
      ".content-render {\n",
      "    background-color: #1a1a1a  !important;  /* ← Medium grey for rendered input */\n",
      "}\n",
      ".running { color: #ef4444 !important; }\n",
      ".complete { color: #22c55e !important; }\n",
      "#notebook-container {\n",
      "    height: calc(100vh - 64px); \n",
      "    overflow-y: auto;\n",
      ".toggle-edit:checked ~ .content-edit { display: block; }\n",
      ".toggle-edit:checked ~ .content-render { display: none; }\n",
      ".toggle-edit:not(:checked) ~ .content-edit { display: none; }\n",
      ".toggle-edit:not(:checked) ~ .content-render { display: block; }\n",
      "\"\"\"\n",
      "\n",
      "# %% ../nbs/main.ipynb 4\n",
      "import json\n",
      "import asyncio\n",
      "import requests\n",
      "import lisette\n",
      "import time\n",
      "\n",
      "from fasthtml.common import *\n",
      "from fasthtml.jupyter import JupyUvi\n",
      "from starlette.staticfiles import StaticFiles\n",
      "\n",
      "from .app_config import MODEL, KERNEL_URL, NOTEBOOK_SYS_PROMPT\n",
      "from .cells import MarkdownCell, CodeCell, PromptCell, AgentCell\n",
      "from .streaming import SSEStream, active_streams\n",
      "from .kernel import execute_unreal_code, convert_to_accumulated\n",
      "from .notebook_io import reconstruct_cells_from_history, prepare_chat_history, reconstruct_ipynb_cell\n",
      "from .llm import RemoteToolLLM, send_llm_request\n",
      "from .agent import AgentTools, SYS_PROMPT\n",
      "from .scripts import CODE_CELL_SCRIPT, HEIGHT_ADJ_SCRIPT, CELL_FOCUS_SCRIPT\n",
      "\n",
      "from fasthtml.common import *\n",
      "\n",
      "\n",
      "daisy_hdrs =[\n",
      "Link(href='https://cdn.jsdelivr.net/npm/daisyui@5', rel='stylesheet', type='text/css'),\n",
      "Script(src='https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4'),\n",
      "Link(rel=\"stylesheet\", href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css\"),\n",
      "Link(rel=\"stylesheet\", href=\"https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.5.1/github-markdown.min.css\"),\n",
      "Script (src ='https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js'),\n",
      "Script (src ='https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js'),\n",
      "Script(src='https://cdn.jsdelivr.net/npm/marked/marked.min.js'),\n",
      "Script(CODE_CELL_SCRIPT+ HEIGHT_ADJ_SCRIPT+CELL_FOCUS_SCRIPT),\n",
      "Script(src=\"https://cdn.jsdelivr.net/npm/ansi_up@5/ansi_up.min.js\"),\n",
      "Script(src=\"https://cdn.jsdelivr.net/npm/monaco-editor@latest/min/vs/loader.js\"),\n",
      "Script(\"\"\"\n",
      "require.config({ paths: { 'vs': 'https://cdn.jsdelivr.net/npm/monaco-editor@latest/min/vs' }});\n",
      "\"\"\"),\n",
      "Script(src=\"https://unpkg.com/htmx.org/dist/ext/sse.js\")]\n",
      "\n",
      "\n",
      "# FastHTML app setup + daisy_hdrs (the big Style/Script list)\n",
      "app = FastHTML(hdrs=daisy_hdrs)\n",
      "#app.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\n",
      "\n",
      "rt = app.route\n",
      "\n",
      "\n",
      "# %% ../nbs/main.ipynb 6\n",
      "@rt('/interrupt/{cell_id}', methods=['POST'])\n",
      "async def interrupt(cell_id: str, request):\n",
      "    \"\"\"Signal abort for an active stream.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique cell identifier.\n",
      "    \n",
      "    Returns:\n",
      "        \"OK\" acknowledgment string.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        data = await request.json()\n",
      "        notebook = data.get('notebook', 'untitled')\n",
      "    except:\n",
      "        notebook = 'untitled'\n",
      "    stream_key = f\"{notebook}:{cell_id}\"\n",
      "    if stream_key in active_streams:\n",
      "        active_streams[stream_key]['abort'] = True\n",
      "    return \"OK\"\n",
      "    \n",
      "\n",
      "# %% ../nbs/main.ipynb 8\n",
      "@rt('/execute_prompt/{cell_id}')\n",
      "async def exe_prompt(cell_id: str, request): \n",
      "    \"\"\"Execute LLM prompt with notebook context via SSE.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique cell identifier.\n",
      "        request: FastHTML request with JSON body containing:\n",
      "            - prompt: User's prompt text.\n",
      "            - context: List of cell dicts for history.\n",
      "    \n",
      "    Returns:\n",
      "        SSE StreamingResponse yielding LLM chunks.\n",
      "    \"\"\"\n",
      "\n",
      "    data = await request.json() \n",
      "\n",
      "    notebook = data.get('notebook', 'untitled')\n",
      "    stream_key = f\"{notebook}:{cell_id}\" \n",
      "\n",
      "    prompt = data['prompt']\n",
      "    cell_dict_list = data.get('context', [])\n",
      "    \n",
      "    cells = reconstruct_cells_from_history(cell_dict_list)\n",
      "    ipynb_list = [cell.to_ipynb() for cell in cells]\n",
      "    chat_history = prepare_chat_history(ipynb_list)\n",
      "    \n",
      "    stream = SSEStream(stream_key)\n",
      "    \n",
      "    def run():\n",
      "        for msg in send_llm_request(prompt, history=chat_history):\n",
      "            if stream.aborted(): break\n",
      "            stream.text(msg)\n",
      "        stream.done()\n",
      "    \n",
      "    asyncio.create_task(asyncio.to_thread(run))\n",
      "    return stream.response()\n",
      "\n",
      "\n",
      "# %% ../nbs/main.ipynb 10\n",
      "@rt('/execute_code/{cell_id}')\n",
      "async def exe_code(cell_id: str, request):\n",
      "    \"\"\"Execute Python code in Unreal Engine via SSE.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique cell identifier.\n",
      "        request: FastHTML request with JSON body containing:\n",
      "            - code: Python code string to execute.\n",
      "    \n",
      "    Returns:\n",
      "        SSE StreamingResponse yielding kernel output messages.\n",
      "    \"\"\"\n",
      "\n",
      "    data = await request.json()\n",
      "    notebook = data.get('notebook', 'untitled')\n",
      "    stream_key = f\"{notebook}:{cell_id}\" \n",
      "\n",
      "    stream = SSEStream(stream_key)\n",
      "    \n",
      "    def run():\n",
      "        response = requests.post(f'{KERNEL_URL}/execute', json={'code': data['code']}, stream=True, timeout=(5, 60))\n",
      "        for line in response.iter_lines():\n",
      "            if stream.aborted(): break\n",
      "            if line.startswith(b'data: '):\n",
      "                stream.output(json.loads(line[6:]))  # ← output() not raw()\n",
      "        stream.done()\n",
      "    \n",
      "    asyncio.create_task(asyncio.to_thread(run))\n",
      "    return stream.response()\n",
      "\n",
      "\n",
      "# %% ../nbs/main.ipynb 12\n",
      "@rt('/agent_tool_build/{cell_id}', methods=['POST'])\n",
      "async def agent_stream(cell_id: str, request):\n",
      "    \"\"\"Run agent code generation loop with tool calling via SSE.\n",
      "    \n",
      "    Args:\n",
      "        cell_id: Unique cell identifier.\n",
      "        request: FastHTML request with JSON body containing:\n",
      "            - prompt: Code generation request.\n",
      "            - existing_code: Optional code to modify.\n",
      "            - context: List of cell dicts for history.\n",
      "    \n",
      "    Returns:\n",
      "        SSE StreamingResponse yielding agent progress (tags, text, outputs).\n",
      "    \"\"\"\n",
      "    data = await request.json()\n",
      "    notebook = data.get('notebook', 'untitled')\n",
      "    stream_key = f\"{notebook}:{cell_id}\" \n",
      "\n",
      "    stream = SSEStream(stream_key)\n",
      "    def run_chat():\n",
      "        PROMPT = data['prompt']\n",
      "\n",
      "        existing_code = data.get('existing_code')\n",
      "        cell_dict_list = data.get('context', [])  # ← Add this\n",
      "\n",
      "        # Convert to chat history like prompt cells do\n",
      "        cells = reconstruct_cells_from_history(cell_dict_list)\n",
      "        ipynb_list = [cell.to_ipynb() for cell in cells]\n",
      "        chat_history = prepare_chat_history(ipynb_list)\n",
      "\n",
      "        if existing_code:\n",
      "            CODE = existing_code  # Initialize CODE with existing\n",
      "            PROMPT = f\"Modify this code: {existing_code}\\n\\nRequest: {data['prompt']}\"\n",
      "        else:\n",
      "            CODE = \"\"\n",
      "            PROMPT = data['prompt']\n",
      "        \n",
      "\n",
      "        CHAT = lisette.Chat(MODEL, SYS_PROMPT)\n",
      "        CHAT.hist += chat_history\n",
      "        CHAT.hist.append( {\"role\":\"assistant\", \"content\":PROMPT})\n",
      "\n",
      "        a_tools = AgentTools(stream, CHAT, PROMPT,cell_id, code=CODE, print_updates=False)\n",
      "        tools = a_tools.get_tools()\n",
      "        \n",
      "        chat = lisette.Chat(MODEL, SYS_PROMPT, tools=tools)\n",
      "        chat.hist += chat_history\n",
      "\n",
      "\n",
      "        gen = chat(PROMPT, max_steps=15)\n",
      "        for _ in gen:\n",
      "            if stream.aborted():\n",
      "                break\n",
      "        print(\"Chat loop finished!\") \n",
      "        time.sleep(0.1) \n",
      "        stream.done()\n",
      "    \n",
      "    asyncio.create_task(asyncio.to_thread(run_chat))\n",
      "    return stream.response()\n",
      "    \n",
      "\n",
      "# %% ../nbs/main.ipynb 14\n",
      "def Toolbar(title):\n",
      "    return Div(\n",
      "\n",
      "        Div(\n",
      "            Input(value=title, cls=\"text-xl font-bold text-white notebook-name bg-transparent border-none outline-none focus:outline-none flex-1\"),\n",
      "            Script(\"\"\"\n",
      "                document.querySelector('.notebook-name').addEventListener('blur', (e) => {\n",
      "                    const name = e.target.value || 'untitled';\n",
      "                    history.replaceState(null, '', `/notebook/${name}.ipynb`);\n",
      "                });\n",
      "            \"\"\"),\n",
      "            cls=\"flex flex-1 items-center\"\n",
      "        ),\n",
      "        Div(\n",
      "            Button(\"➕ Markdown\", \n",
      "                   hx_post=\"/add_cell/markdown\",\n",
      "                   hx_target=\"#notebook-container\",\n",
      "                   hx_swap=\"beforeend\",\n",
      "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"), \n",
      "            Button(\"➕ Code\", \n",
      "                   hx_post=\"/add_cell/code\",\n",
      "                   hx_target=\"#notebook-container\",\n",
      "                   hx_swap=\"beforeend\",\n",
      "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"),  \n",
      "            Button(\"➕ Prompt\", \n",
      "                   hx_post=\"/add_cell/prompt\",\n",
      "                   hx_target=\"#notebook-container\",\n",
      "                   hx_swap=\"beforeend\",\n",
      "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"),  \n",
      "            Button(\"➕ Agent\", \n",
      "                   hx_post=\"/add_cell/agent\",\n",
      "                   hx_target=\"#notebook-container\",\n",
      "                   hx_swap=\"beforeend\",\n",
      "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"), \n",
      "            cls=\"flex gap-2\"\n",
      "        ),\n",
      "        cls=\"flex justify-between p-4 bg-[#0d0d0d]\"  # ← Changed from #0d0d0d to pure black\n",
      "    )\n",
      "\n",
      "@rt('/add_cell/{cell_type}')\n",
      "def add_cell(cell_type: str):\n",
      "    \"\"\"Create and return a new cell of the specified type.\n",
      "    \n",
      "    Args:\n",
      "        cell_type: One of 'markdown', 'code', 'prompt', or 'agent'.\n",
      "        \n",
      "    Returns:\n",
      "        Ren\n",
      "    \"\"\"\n",
      "    if cell_type == 'markdown':\n",
      "        new_cell = MarkdownCell(\"\")\n",
      "    elif cell_type == 'code':\n",
      "        new_cell = CodeCell(\"\")\n",
      "    elif cell_type == 'prompt':\n",
      "        new_cell = PromptCell(\"\")\n",
      "    elif cell_type == 'agent':\n",
      "        new_cell = AgentCell(\"\")\n",
      "    else:\n",
      "        return \"Invalid cell type\"\n",
      "    \n",
      "    return new_cell.render()\n",
      "\n",
      "\n",
      "# %% ../nbs/main.ipynb 16\n",
      "@rt('/notebook/{notebook_file}')\n",
      "def load_notebook(notebook_file:str): \n",
      "    \"\"\"Load a Jupyter Notebook file and render its cells.\"\"\"\n",
      "\n",
      "    if not os.path.exists(notebook_file):\n",
      "        rendered_cells = []\n",
      "        print ('Notebook Not Found:',notebook_file)\n",
      "\n",
      "    else:\n",
      "        cells = []\n",
      "        with open(notebook_file, 'r', encoding='utf-8') as f:\n",
      "            notebook = json.load(f)\n",
      "            cells = notebook['cells']\n",
      "        \n",
      "        cell_objects = [reconstruct_ipynb_cell(cell) for cell in cells]\n",
      "        rendered_cells = [cell.render() for cell in cell_objects]\n",
      "\n",
      "\n",
      "    return Title(\"Unreal LLM Sandbox\"),Body(\n",
      "        Toolbar(notebook_file.split('.ipynb')[0]),\n",
      "        #sty,\n",
      "        Style(CSS),\n",
      "        Div(  *rendered_cells,\n",
      "            cls='px-5',  \n",
      "            id='notebook-container' \n",
      "        )\n",
      "    )\n",
      "\n",
      "@rt('/save_notebook/{notebook_file}', methods=['POST'])\n",
      "async def save_notebook(notebook_file: str, request):\n",
      "    \"\"\"Save notebook cells to a Jupyter .ipynb file.\n",
      "    \n",
      "    Args:\n",
      "        notebook_file: Filename to save to.\n",
      "        request: Request with JSON body containing 'cells' list.\n",
      "    \n",
      "    Returns:\n",
      "        JSON with status message.\n",
      "    \"\"\"\n",
      "    data = await request.json()\n",
      "    cell_dict_list = data.get('cells', [])\n",
      "    \n",
      "    # Reconstruct cell objects and convert to ipynb format\n",
      "    cells = reconstruct_cells_from_history(cell_dict_list)\n",
      "    ipynb_cells = [cell.to_ipynb() for cell in cells]\n",
      "    \n",
      "    # Build notebook structure\n",
      "    notebook = {\n",
      "        \"nbformat\": 4,\n",
      "        \"nbformat_minor\": 5,\n",
      "        \"metadata\": {\n",
      "            \"kernelspec\": {\n",
      "                \"display_name\": \"Python 3\",\n",
      "                \"language\": \"python\",\n",
      "                \"name\": \"python3\"\n",
      "            }\n",
      "        },\n",
      "        \"cells\": ipynb_cells\n",
      "    }\n",
      "    \n",
      "    with open(notebook_file, 'w', encoding='utf-8') as f:\n",
      "        json.dump(notebook, f, indent=2, ensure_ascii=False)\n",
      "    \n",
      "    return {\"status\": \"saved\", \"file\": notebook_file}\n",
      "    \n",
      "\n",
      "# %% ../nbs/main.ipynb 17\n",
      "import uvicorn\n",
      "\n",
      "def start_server():\n",
      "    uvicorn.run(app, host='0.0.0.0', port=5001)\n",
      "if __name__ == \"__main__\":\n",
      "    start_server()\n",
      "    \n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/kernel.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/kernel.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['strip_ansi', 'format_kernel_stream', 'execute_unreal_code', 'convert_to_accumulated']\n",
      "\n",
      "# %% ../nbs/kernel.ipynb 2\n",
      "import re\n",
      "import copy\n",
      "import requests\n",
      "\n",
      "from .app_config import KERNEL_URL\n",
      "\n",
      "\n",
      "# %% ../nbs/kernel.ipynb 3\n",
      "def strip_ansi(text):\n",
      "    \"\"\"Remove ANSI escape codes from text.\n",
      "    \n",
      "    Args:\n",
      "        text: String potentially containing ANSI color/formatting codes.\n",
      "        \n",
      "    Returns:\n",
      "        String with all ANSI escape sequences removed.\n",
      "    \"\"\"\n",
      "    return re.sub(r'\\x1b\\[[0-9;]*m', '', text)\n",
      "    \n",
      "\n",
      "def format_kernel_stream(json_response, clean_ansi=True ):\n",
      "    \"\"\"Format raw kernel response into clean, consolidated messages.\n",
      "    \n",
      "    Merges consecutive stream messages of the same type and optionally\n",
      "    strips ANSI codes from error tracebacks.\n",
      "    \n",
      "    Args:\n",
      "        json_response: Dict with 'messages' key containing kernel output.\n",
      "        clean_ansi: If True, remove ANSI codes from tracebacks.\n",
      "        \n",
      "    Returns:\n",
      "        List of formatted message dicts with consolidated streams.\n",
      "    \"\"\"    \n",
      "    formatted_response = []\n",
      "    prev_name = None\n",
      "    prev_type = None\n",
      "    \n",
      "    for msg in json_response.get('messages', []):\n",
      "        msg_copy = copy.deepcopy(msg)\n",
      "        \n",
      "        if msg['msg_type'] == 'error':\n",
      "            if clean_ansi:\n",
      "                tb = msg_copy['content']['traceback']\n",
      "                msg_copy['content']['traceback'] = ['\\n'.join([strip_ansi(line) for line in tb])]\n",
      "\n",
      "        appended = False\n",
      "        if msg['msg_type'] == 'stream':\n",
      "            if prev_type == msg['msg_type'] and prev_name == msg['content']['name']:\n",
      "                formatted_response[-1]['content']['text'] += msg['content']['text']\n",
      "                appended = True\n",
      "\n",
      "        if not appended:\n",
      "            formatted_response.append(msg_copy)\n",
      "\n",
      "        prev_type = msg['msg_type']\n",
      "        if msg['msg_type'] == 'stream':\n",
      "            prev_name = msg['content']['name']\n",
      "\n",
      "    return formatted_response\n",
      "\n",
      "\n",
      "def execute_unreal_code(code):\n",
      "    \"\"\" \n",
      "    Execute Python code in the Unreal Engine kernel via ngrok.\n",
      "    \n",
      "    Args:\n",
      "        code (str): Python code to execute in Unreal\n",
      "        \n",
      "    Returns:\n",
      "        list: Formatted kernel messages containing:\n",
      "            - 'stream' messages with stdout/stderr output\n",
      "            - 'error' messages with exception name, value, and cleaned traceback\n",
      "    \"\"\"\n",
      "    \n",
      "    try:\n",
      "        response = requests.post(\n",
      "            f'{KERNEL_URL}/execute_sync',\n",
      "            json={'code': code},\n",
      "            timeout=30\n",
      "        )\n",
      "        json_response = response.json()\n",
      "\n",
      "    except (requests.RequestException, requests.Timeout) as e:\n",
      "        # Return error in same format as kernel errors\n",
      "        error_msg = [{\"msg_type\": \"error\", \"content\": {\"ename\": \"KernelError\", \"evalue\": str(e), \"traceback\": []}}]\n",
      "        return error_msg, error_msg\n",
      "\n",
      "    print (json_response)\n",
      "    return format_kernel_stream(json_response), format_kernel_stream(json_response,clean_ansi=False)\n",
      "\n",
      "def convert_to_accumulated(json_response):\n",
      "    \"\"\"\n",
      "    Convert Python kernel response messages to JavaScript accumulated output format.\n",
      "    \n",
      "    Transforms a list of Jupyter kernel messages into the format expected by the\n",
      "    frontend's output rendering system. Merges consecutive stream outputs of the\n",
      "    same type (stdout/stderr).\n",
      "    \n",
      "    Args:\n",
      "        json_response: List of dicts with 'msg_type' and 'content' keys from unreal_llm_sandbox.kernel.\n",
      "    \n",
      "    Returns:\n",
      "        List of accumulated output dicts with 'output_type' and type-specific fields.\n",
      "    \"\"\"\n",
      "    accumulated = []\n",
      "    for msg in json_response:\n",
      "        t = msg['msg_type']\n",
      "        c = msg['content']\n",
      "        if t == 'stream':\n",
      "            # Check if we can merge with previous\n",
      "            if accumulated and accumulated[-1].get('output_type') == 'stream' and accumulated[-1].get('name') == c['name']:\n",
      "                accumulated[-1]['text'].append(c['text'])\n",
      "            else:\n",
      "                accumulated.append({'output_type': 'stream',\n",
      "                                    'name': c['name'],\n",
      "                                    'text': [c['text']]})\n",
      "        elif t == 'execute_result':\n",
      "            accumulated.append({'output_type': 'execute_result',\n",
      "                                 'data': c['data'],\n",
      "                                 'execution_count': c.get('execution_count')})\n",
      "        elif t == 'error':\n",
      "            accumulated.append({'output_type': 'error', \n",
      "                                'ename': c['ename'],\n",
      "                                'evalue': c['evalue'],\n",
      "                                'traceback': c['traceback']})\n",
      "    return accumulated\n",
      "    \n",
      "\n",
      "\n",
      "============================================================\n",
      "../unreal_llm_sandbox/scripts.py\n",
      "============================================================\n",
      "# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/scripts.ipynb.\n",
      "\n",
      "# %% auto 0\n",
      "__all__ = ['CELL_SCRIPT', 'HEIGHT_ADJ_SCRIPT', 'CELL_FOCUS_SCRIPT', 'AGENT_SCRIPT', 'CODE_CELL_SCRIPT']\n",
      "\n",
      "# %% ../nbs/scripts.ipynb 2\n",
      "CELL_SCRIPT = \"\"\"\n",
      "console.log('CODE_CELL_SCRIPT loaded successfully!');\n",
      "\n",
      "window.cellOutputs = window.cellOutputs || {};\n",
      "\n",
      "\n",
      "/**\n",
      " * Toggles the 'minimized' class on a cell element to collapse or expand it.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the cell to toggle.\n",
      " */\n",
      " function toggleMinimize(cellId){\n",
      "    const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    cell.classList.toggle('minimized');\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Retrieves the code content from a Monaco editor instance within a cell.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the cell containing the Monaco editor.\n",
      " * @returns {string} The current text content of the Monaco editor model.\n",
      " */\n",
      " function getMonacoContent(cellId){\n",
      "    const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    const monaco_container = cell.querySelector('.monaco-editor');\n",
      "    const monaco_editor = monaco_container.querySelector('.monaco-editor');\n",
      "    const monaco_model = monaco.editor.getModels().find(\n",
      "        m => m.uri.toString() === monaco_editor.dataset.uri\n",
      "    );\n",
      "    const monaco_code = monaco_model.getValue();\n",
      "    return monaco_code;\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Clears both the output store and output display elements within a cell.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the cell to clear.\n",
      " */\n",
      "function clearOutput(cellId) {\n",
      "    const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    const cell_type = cell.getAttribute('data-cell-type');\n",
      "\n",
      "    // Clear Output Store\n",
      "    // For code cells, initialize with empty array\n",
      "    if (cell_type == 'code' || cell_type == 'prompt')\n",
      "    {\n",
      "        const output_store = cell.querySelector('.output-store');    \n",
      "        if (cell_type === 'code') {\n",
      "            output_store.textContent = \"[]\";\n",
      "        }\n",
      "        else if (cell_type === 'prompt') {\n",
      "            output_store.textContent = \"\";\n",
      "        }\n",
      "\n",
      "        // Clear Output Display\n",
      "        const output_display = cell.querySelector('.output-display');\n",
      "        output_display.textContent = \"\";\n",
      "    }\n",
      "\n",
      "    else if (cell_type === 'agent') {\n",
      "        const output_store_llm = cell.querySelector('.output-store-llm');    \n",
      "        const output_store_code = cell.querySelector('.output-store-code');    \n",
      "\n",
      "        output_store_llm.textContent = \"\";\n",
      "        output_store_code.textContent = \"[]\";\n",
      "\n",
      "        const output_display_llm = cell.querySelector('.output-display-llm');\n",
      "        output_display_llm.textContent = \"\";\n",
      "        const output_display_code = cell.querySelector('.output-display-code');\n",
      "        output_display_code.textContent = \"\";\n",
      "\n",
      "    }\n",
      "}\n",
      "\n",
      "/**\n",
      " * Executes a prompt cell by sending its content to the LLM endpoint and streaming the response.\n",
      " * Clears previous output, gathers conversation context from unreal_llm_sandbox.cells above, and renders\n",
      " * the streamed response into the cell's output area.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the prompt cell to execute.\n",
      " */\n",
      "function executePromptCell(cellId)\n",
      "{\n",
      "    // Clear Cell\n",
      "    clearOutput(cellId);\n",
      "\n",
      "    // Get Output Area to Write To\n",
      "    const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    const output_store = cell.querySelector('[class=\"output-store\"]');\n",
      "\n",
      "    // Turn Off Edit Mode\n",
      "    const toggle_edit = cell.querySelector('.toggle-edit');\n",
      "    toggle_edit.checked = false;\n",
      "\n",
      "    // Prep Data\n",
      "    const chat_history = gatherCellsForLLM(cellId);\n",
      "\n",
      "    const prompt = extractCellInput(cellId);\n",
      "    \n",
      "    const notebook_name = document.querySelector('.notebook-name')?.value || 'untitled';\n",
      "\n",
      "    const chat_data = {\n",
      "        'prompt': prompt,\n",
      "        'context': chat_history,\n",
      "        'notebook': notebook_name \n",
      "    };\n",
      "\n",
      "    (async () => {\n",
      "    const { fetchEventSource } = await import('https://esm.sh/@microsoft/fetch-event-source@2.0.1');\n",
      "    await fetchEventSource(`/execute_prompt/${cellId}`, {\n",
      "        method: 'POST',\n",
      "        headers: {'Content-Type': 'application/json'},\n",
      "        body: JSON.stringify(chat_data),\n",
      "        onmessage(ev) {\n",
      "            try {\n",
      "                const packet = JSON.parse(ev.data);\n",
      "                if (packet.type === 'text') {\n",
      "                    output_store.textContent += packet.data;\n",
      "                }\n",
      "            } catch(error) {\n",
      "                output_store.textContent += `\\n ** Error In Stream ** \\n`;\n",
      "            }\n",
      "        },\n",
      "        onerror(error) {\n",
      "            output_store.textContent += `\\n ** Connection of Server Error ** \\n` ;\n",
      "            console.error(error);\n",
      "        },\n",
      "    });\n",
      "    })();\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Extracts the input content from a cell based on its type.\n",
      " * For code cells, retrieves content from the Monaco editor.\n",
      " * For other cell types (note/prompt), retrieves content from the textarea.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the cell to extract input from.\n",
      " * @returns {string} The text content of the cell's input area.\n",
      " */\n",
      "function extractCellInput(cellId)\n",
      "{\n",
      "    const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    const cell_type = cell.getAttribute('data-cell-type');\n",
      "    \n",
      "    if (cell_type == 'code')\n",
      "        {\n",
      "            return getMonacoContent(cell.getAttribute('data-cell-id'));\n",
      "        }\n",
      "    else\n",
      "        {\n",
      "            const textarea = cell.querySelector(\"textarea\");\n",
      "            return textarea.value;\n",
      "        }\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Executes a code cell by sending its content to the backend for execution via SSE stream.\n",
      " * Clears previous output, retrieves code from the Monaco editor, and streams\n",
      " * execution results back to the cell's output area.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the code cell to execute.\n",
      " */\n",
      "function executeCell(cellId)\n",
      "{\n",
      "    // Clear Output\n",
      "    clearOutput(cellId);\n",
      "\n",
      "    /// Prep Monaco\n",
      "    const code = getMonacoContent(cellId);\n",
      "\n",
      "    const notebook_name = document.querySelector('.notebook-name')?.value || 'untitled';\n",
      "\n",
      "    const code_data = {\n",
      "        'code':code,\n",
      "        'notebook': notebook_name \n",
      "    };\n",
      "\n",
      "    // Send Post and Start Stream\n",
      "    (async () => {\n",
      "    const { fetchEventSource } = await import('https://esm.sh/@microsoft/fetch-event-source@2.0.1');\n",
      "    await fetchEventSource(`/execute_code/${cellId}`, {\n",
      "        method: 'POST',\n",
      "        headers: {'Content-Type': 'application/json'},\n",
      "        body: JSON.stringify(code_data),\n",
      "        onmessage(ev) {\n",
      "            const packet = JSON.parse(ev.data);\n",
      "            if (packet.type === 'output') {\n",
      "                accumulateOutput(cellId, packet.data);  // packet.data contains kernel msg\n",
      "            }\n",
      "        },\n",
      "        onerror(err) {\n",
      "            console.error('Stream error:', err);\n",
      "            throw err; // stops retry\n",
      "        }\n",
      "    });\n",
      "    })();\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Accumulates streamed execution output into a cell's output store.\n",
      " * Handles different Jupyter message types (stream, execute_result, display_data, error)\n",
      " * and merges consecutive stream outputs of the same name (stdout/stderr) into a single entry.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the cell to accumulate output for.\n",
      " * @param {Object} data_dict - The incoming message from the execution stream.\n",
      " * @param {string} data_dict.msg_type - Type of message: 'stream', 'execute_result', 'display_data', or 'error'.\n",
      " * @param {Object} data_dict.content - The message payload, structure varies by msg_type.\n",
      " */\n",
      "function accumulateOutput(cellId,data_dict)\n",
      "{\n",
      "        //data_dict = JSON.parse(ev.data);\n",
      "\n",
      "        // Get cell and output\n",
      "        const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "        const output_store = cell.querySelector('.output-store');\n",
      "\n",
      "        let accumulated_data = [];\n",
      "        // Unpack content\n",
      "        if (output_store.textContent)\n",
      "        {\n",
      "            accumulated_data = JSON.parse(output_store.textContent);\n",
      "        }\n",
      "\n",
      "        let acc_len = accumulated_data.length;\n",
      "\n",
      "        let prev_msg_type = null;\n",
      "        // store previous message type\n",
      "        if (acc_len > 0)\n",
      "        {\n",
      "            prev_msg_type = accumulated_data[acc_len-1]['output_type'];\n",
      "        }\n",
      "\n",
      "        if (data_dict['msg_type'] == 'stream')\n",
      "        {\n",
      "            let added = false;\n",
      "            if (prev_msg_type == 'stream')\n",
      "            {\n",
      "                // Append to the same list if text stream\n",
      "                if (accumulated_data[acc_len-1]['name'] == data_dict['content']['name'] )\n",
      "                {\n",
      "                    accumulated_data[acc_len-1]['text'].push(data_dict['content']['text']);\n",
      "                    added = true;\n",
      "                }\n",
      "\n",
      "            }\n",
      "            if (!added)\n",
      "            {\n",
      "            accumulated_data.push( {'output_type':'stream',\n",
      "                                'name':data_dict['content']['name'],\n",
      "                                'text':[data_dict['content']['text']]});\n",
      "\n",
      "            }\n",
      "\n",
      "        }\n",
      "        else if (data_dict['msg_type'] == 'execute_result')\n",
      "        {\n",
      "            accumulated_data.push( {'output_type':'execute_result',\n",
      "                                'data':data_dict['content']['data'],\n",
      "                                'execution_count':data_dict['content']['execution_count']});\n",
      "        }\n",
      "        else if (data_dict['msg_type'] == 'display_data')\n",
      "        {\n",
      "            accumulated_data.push( {'output_type':'display_data',\n",
      "                                'data':data_dict['content']['data']});\n",
      "        }\n",
      "        else if (data_dict['msg_type'] == 'error')\n",
      "        {\n",
      "            accumulated_data.push( {'output_type':'error',\n",
      "                                'ename':data_dict['content']['ename'],\n",
      "                                'evalue':data_dict['content']['evalue'],\n",
      "                                'traceback':data_dict['content']['traceback']});\n",
      "        }\n",
      "        output_store.textContent = JSON.stringify(accumulated_data);\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Renders the output of a prompt cell by parsing its stored markdown content\n",
      " * and displaying the formatted HTML with syntax highlighting.\n",
      " * Retrieves raw markdown from the output store, converts it to HTML using marked.js,\n",
      " * and applies Prism.js syntax highlighting to any code blocks.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the prompt cell to render.\n",
      " */\n",
      "function renderOutputPrompt(cellId,tag='')\n",
      "{\n",
      "    cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    output_store = cell.querySelector('.output-store'+tag);\n",
      "    output_display = cell.querySelector('.output-display'+tag);\n",
      "    markdown = marked.parse(output_store.textContent);\n",
      "    output_display.innerHTML = ''\n",
      "    if (markdown)\n",
      "    {\n",
      "        output_display.innerHTML = markdown;\n",
      "        Prism.highlightAllUnder(output_display);\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Converts a Jupyter-style MIME bundle into renderable HTML.\n",
      " * Checks for image formats (PNG, JPEG), HTML, and plain text in priority order,\n",
      " * returning the appropriate HTML string for display.\n",
      " * \n",
      " * @param {Object} data - A MIME bundle object with keys like 'image/png', 'text/html', etc.\n",
      " * @returns {string|undefined} HTML string for the highest-priority format found, or undefined if none match.\n",
      " */\n",
      "function renderData(data)\n",
      "{\n",
      "   if (data.hasOwnProperty(\"image/png\")){\n",
      "      return `<img src=\"data:image/png;base64,${data['image/png']}\">`;\n",
      "   }\n",
      "   else if (data.hasOwnProperty(\"image/jpeg\")){\n",
      "      return `<img src=\"data:image/jpeg;base64,${data['image/jpeg']}\">`;\n",
      "   }\n",
      "   else if (data.hasOwnProperty(\"text/html\")){\n",
      "      return data['text/html'];\n",
      "   }\n",
      "   else if (data.hasOwnProperty(\"text/plain\")){\n",
      "      return `<div class=\"result-output\">${data['text/plain']}</div>`;\n",
      "   }\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Renders the accumulated execution output for a code cell by parsing the stored JSON\n",
      " * and converting it to displayable HTML. Handles multiple Jupyter output types:\n",
      " * - stream: Concatenates text chunks into a single div (stdout/stderr)\n",
      " * - execute_result/display_data: Delegates to renderData() for MIME bundle rendering\n",
      " * - error: Formats exception name, value, and ANSI-colored traceback\n",
      " * \n",
      " * Uses AnsiUp to convert ANSI escape codes in tracebacks to styled HTML.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the code cell to render output for.\n",
      " */\n",
      "function renderOutput(cellId, tag='')\n",
      "{\n",
      "    ansi_up = new AnsiUp();\n",
      "    const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    const output_store = cell.querySelector('.output-store'+tag);\n",
      "    const output_display = cell.querySelector('.output-display'+tag);\n",
      "\n",
      "    const data = JSON.parse(output_store.textContent)\n",
      "\n",
      "    let out_html = ''\n",
      "\n",
      "    for (i = 0; i < data.length; i++)\n",
      "        {\n",
      "            if (data[i]['output_type'] == 'stream')\n",
      "            {\n",
      "                const text_list = data[i]['text'];\n",
      "                const text_len = text_list.length;\n",
      "\n",
      "                out_html += '<div class=\"stream-output\">';\n",
      "                for (s = 0; s < text_len; s++  )\n",
      "                    {\n",
      "                         out_html += text_list[s];\n",
      "                    }\n",
      "                out_html += `</div>`;\n",
      "            }\n",
      "            else if (data[i]['output_type'] == 'execute_result' || data[i]['output_type'] == 'display_data' )\n",
      "            {\n",
      "                out_html += renderData(data[i]['data']);\n",
      "            }\n",
      "            else if (data[i]['output_type'] == 'error')\n",
      "            {\n",
      "                const trace_list = data[i]['traceback'];\n",
      "                const trace_len = trace_list.length;\n",
      "\n",
      "                // out_html += `<div class=\"error-name\">${data[i].ename}: ${data[i].evalue}</div>`;\n",
      "                out_html += '<pre class=\"traceback\">';\n",
      "                for (s = 0; s < trace_len; s++  )\n",
      "                    {\n",
      "                         out_html += ansi_up.ansi_to_html(trace_list[s]);\n",
      "                         out_html += `\\n`;\n",
      "                    }\n",
      "                out_html += '</pre>';\n",
      "\n",
      "            }\n",
      "\n",
      "        }\n",
      "    output_display.innerHTML = out_html; \n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Removes a cell element from the DOM by its unique identifier.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the cell to delete.\n",
      " */\n",
      " function deleteCell(cellId) {\n",
      "    document.querySelector(`[data-cell-id=\"${cellId}\"]`).remove();\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Moves a cell down by swapping its position with its next sibling element.\n",
      " * If no next sibling exists, the cell remains in place.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the cell to move down.\n",
      " */\n",
      " function moveDown(cellId){\n",
      "    const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    // Check Sibling\n",
      "    const sibling = cell.nextElementSibling;\n",
      "    if (sibling){\n",
      "        cell.parentNode.insertBefore(sibling,cell);\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Moves a cell up by swapping its position with its previous sibling element.\n",
      " * If no previous sibling exists, the cell remains in place.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the cell to move up.\n",
      " */\n",
      "function moveUp(cellId){\n",
      "    const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    \n",
      "    // Check Sibling\n",
      "    const sibling = cell.previousElementSibling;\n",
      "    if (sibling){\n",
      "        cell.parentNode.insertBefore(cell,sibling);\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Gathers all cells above a given cell and formats them for LLM context.\n",
      " * Collects each cell's id, type, source content, and outputs until reaching the target cell.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the cell to stop at (exclusive).\n",
      " * @returns {Array<Object>} Array of cell objects with cell_id, cell_type, source, and outputs.\n",
      " */\n",
      "function gatherCellsForLLM(cellId){\n",
      "    let cell_out_list = [];\n",
      "    const cells = document.querySelectorAll('[data-cell-id]');\n",
      "    for (let i = 0; i < cells.length; i++){\n",
      "\n",
      "        const cell = cells[i];\n",
      "        const id = cell.getAttribute('data-cell-id');\n",
      "        const type = cell.getAttribute('data-cell-type');\n",
      "        const input = extractCellInput(id);\n",
      "        const output = extractCellOutput(id);\n",
      "\n",
      "        if (cellId == id)\n",
      "        {\n",
      "            break;\n",
      "        }\n",
      "    \n",
      "        const cell_dict = {'cell_id':id,\n",
      "                    'cell_type':type,\n",
      "                    'source':input,\n",
      "                    'outputs':output,\n",
      "                    };\n",
      "        cell_out_list.push(cell_dict);\n",
      "    }\n",
      "    return cell_out_list;\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Extracts the output content from a cell based on its type.\n",
      " * For code cells, parses JSON from the output store.\n",
      " * For prompt cells, returns the raw text content.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the cell.\n",
      " * @returns {Array|string|null} Parsed output array for code cells, string for prompt cells, null otherwise.\n",
      " */\n",
      "function extractCellOutput(cellId){\n",
      "    const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    const cell_type = cell.getAttribute('data-cell-type');\n",
      "    const output_store = cell.querySelector('.output-store');\n",
      "    \n",
      "    if (cell_type == 'code')\n",
      "        {\n",
      "            try{\n",
      "                return JSON.parse(output_store.textContent);\n",
      "            }catch{\n",
      "                return [];\n",
      "            }\n",
      "        }\n",
      "    else if (cell_type == 'prompt')\n",
      "        {\n",
      "            return output_store.textContent;\n",
      "        }\n",
      "    else if (cell_type == 'agent')\n",
      "    {\n",
      "        return getMonacoContent(cellId);\n",
      "    }\n",
      "        \n",
      "    else{\n",
      "        return null;\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Sets up a MutationObserver to watch a cell's output store for changes\n",
      " * and automatically re-renders the output when changes are detected.\n",
      " * Handles both code cells (renderOutput) and prompt cells (renderPromptOutput).\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the cell to watch.\n",
      " */\n",
      "function watchOutputStore(cellId) {\n",
      "    const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    const cell_type = cell.getAttribute('data-cell-type');\n",
      "\n",
      "    // Throttle render to ~15fps\n",
      "    let renderPending = false;\n",
      "    function throttledRender(fn) {\n",
      "        if (renderPending) return;\n",
      "        renderPending = true;\n",
      "        setTimeout(() => {\n",
      "            fn();\n",
      "            renderPending = false;\n",
      "        }, 30);\n",
      "    }\n",
      "\n",
      "    const config = { characterData: true, childList: true, subtree: true };\n",
      "\n",
      "    // Initial render\n",
      "    if (cell_type == 'code') {\n",
      "        renderOutput(cellId);\n",
      "    } else if (cell_type == 'prompt') {\n",
      "        renderOutputPrompt(cellId);\n",
      "    } else if (cell_type == 'agent') {\n",
      "        renderOutputPrompt(cellId, '-llm');\n",
      "        renderOutput(cellId, '-code');\n",
      "    }\n",
      "\n",
      "    // Set up observers\n",
      "    if (cell_type == 'code') {\n",
      "        const output_store = cell.querySelector('.output-store');\n",
      "        new MutationObserver(() => throttledRender(() => renderOutput(cellId)))\n",
      "            .observe(output_store, config);\n",
      "    } else if (cell_type == 'prompt') {\n",
      "        const output_store = cell.querySelector('.output-store');\n",
      "        new MutationObserver(() => throttledRender(() => renderOutputPrompt(cellId)))\n",
      "            .observe(output_store, config);\n",
      "    } else if (cell_type == 'agent') {\n",
      "        const output_store_llm = cell.querySelector('.output-store-llm');\n",
      "        const output_store_code = cell.querySelector('.output-store-code');\n",
      "        new MutationObserver(() => throttledRender(() => renderOutput(cellId, '-code')))\n",
      "            .observe(output_store_code, config);\n",
      "        new MutationObserver(() => throttledRender(() => renderOutputPrompt(cellId, '-llm')))\n",
      "            .observe(output_store_llm, config);\n",
      "    }\n",
      "}\n",
      "\n",
      "async function saveNotebook(filename) {\n",
      "    const cells = gatherCellsForLLM(null);  // null = gather all cells\n",
      "    await fetch(`/save_notebook/${filename}`, {\n",
      "        method: 'POST',\n",
      "        headers: {'Content-Type': 'application/json'},\n",
      "        body: JSON.stringify({cells: cells})\n",
      "    });\n",
      "    console.log('Notebook saved!');\n",
      "}\n",
      "\n",
      "setInterval(() => {\n",
      "    const notebookName = document.querySelector('.notebook-name')?.value || 'untitled';\n",
      "    saveNotebook(notebookName+'.ipynb');\n",
      "}, 2000);\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "# %% ../nbs/scripts.ipynb 3\n",
      "HEIGHT_ADJ_SCRIPT=\"\"\"\n",
      "document.addEventListener('DOMContentLoaded', () => {\n",
      "    // Adjust all textareas on load + input\n",
      "    document.querySelectorAll('textarea[class*=\"content-edit\"]').forEach(textarea => {\n",
      "        textarea.style.height = 'auto';\n",
      "        textarea.style.height = Math.min(textarea.scrollHeight, 500) + 'px';\n",
      "        \n",
      "        textarea.addEventListener('input', () => {\n",
      "            textarea.style.height = 'auto';\n",
      "            textarea.style.height = Math.min(textarea.scrollHeight, 500) + 'px';\n",
      "        });\n",
      "    });\n",
      "\n",
      "    // Adjust when toggling to edit mode\n",
      "    document.querySelectorAll('.toggle-edit').forEach(checkbox => {  // Changed selector\n",
      "        checkbox.addEventListener('change', () => {\n",
      "            if (checkbox.checked) {\n",
      "                const cell = checkbox.closest('[data-cell-id]');  // Changed - find parent cell\n",
      "                const textarea = cell?.querySelector('textarea.content-edit');  // Changed\n",
      "                if (textarea) {\n",
      "                    textarea.style.height = 'auto';\n",
      "                    textarea.style.height = Math.min(textarea.scrollHeight, 500) + 'px';\n",
      "                }\n",
      "            }\n",
      "        });\n",
      "    });\n",
      "});\n",
      "\"\"\"\n",
      "\n",
      "CELL_FOCUS_SCRIPT = \"\"\"\n",
      "let currentFocusedCellId = null;\n",
      "\n",
      "document.addEventListener('click', (e) => {\n",
      "    const cell = e.target.closest('[data-cell-id]');  // Changed from [type=\"cell\"]\n",
      "    \n",
      "    // Remove outline from all cells\n",
      "    document.querySelectorAll('[data-cell-id]').forEach(c => {  // Changed\n",
      "        c.style.outline = 'none';\n",
      "    });\n",
      "    \n",
      "    // Add outline to clicked cell\n",
      "    if (cell) {\n",
      "        cell.style.outline = '2px solid #3b82f6';\n",
      "        cell.style.outlineOffset = '-8px';\n",
      "        cell.style.borderRadius = '16px';\n",
      "        currentFocusedCellId = cell.dataset.cellId;  // Changed from cell.id\n",
      "    }\n",
      "    document.querySelectorAll('.toggle-edit').forEach(t => {  // Changed selector\n",
      "        const tCell = t.closest('[data-cell-id]');\n",
      "        if (tCell && tCell.dataset.cellId !== cell?.dataset.cellId) {\n",
      "            t.checked = false;\n",
      "        }\n",
      "    });\n",
      "    const isContentArea = e.target.closest('.markdown-body') || \n",
      "                        e.target.closest('textarea[class*=\"content-edit\"]');\n",
      "\n",
      "    if (isContentArea && cell) {\n",
      "        const toggleCheckbox = cell.querySelector('.toggle-edit');  // Changed - find within cell\n",
      "        if (toggleCheckbox) {\n",
      "            toggleCheckbox.checked = true;\n",
      "            toggleCheckbox.dispatchEvent(new Event('change'));\n",
      "        }\n",
      "    }\n",
      "});\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "# %% ../nbs/scripts.ipynb 4\n",
      "AGENT_SCRIPT =\"\"\"\n",
      "\n",
      "/**\n",
      " * Retrieves the code content from a Monaco editor instance within a cell.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the cell containing the Monaco editor.\n",
      " * @returns {string} The current text content of the Monaco editor model.\n",
      " */\n",
      "function setMonacoContent(cellId, txt) {\n",
      "    const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    const monaco_container = cell.querySelector('.monaco-editor');\n",
      "\n",
      "    // 1. Get the URI (ensure you grab it from the correct element in your DOM)\n",
      "    const uri = monaco_container.dataset.uri || \n",
      "                monaco_container.querySelector('[data-uri]')?.dataset.uri;\n",
      "\n",
      "    const monaco_model = monaco.editor.getModels().find(\n",
      "        m => m.uri.toString() === uri\n",
      "    );\n",
      "\n",
      "    if (monaco_model) {\n",
      "        monaco_model.setValue(txt);\n",
      "\n",
      "        // 2. Find the editor instance attached to this model\n",
      "        const editorInstance = monaco.editor.getEditors().find(\n",
      "            e => e.getModel() === monaco_model\n",
      "        );\n",
      "\n",
      "        // 3. Use the REAL method to scroll to the last line\n",
      "        if (editorInstance) {\n",
      "            editorInstance.revealLine(monaco_model.getLineCount());\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "\n",
      "/**\n",
      " * Executes a prompt cell by sending its content to the LLM endpoint and streaming the response.\n",
      " * Clears previous output, gathers conversation context from unreal_llm_sandbox.cells above, and renders\n",
      " * the streamed response into the cell's output area.\n",
      " * \n",
      " * @param {string} cellId - The unique identifier of the prompt cell to execute.\n",
      " */\n",
      "function executeAgentCell(cellId)\n",
      "{\n",
      "    // Clear Cell\n",
      "    clearOutput(cellId);\n",
      "\n",
      "\n",
      "    const error_text = `\\n ** Error In Stream ** \\n` ;\n",
      "    // Get Output Area to Write To\n",
      "    const cell = document.querySelector(`[data-cell-id=\"${cellId}\"]`);\n",
      "    const output_store_llm = cell.querySelector('[class=\"output-store-llm\"]');\n",
      "    const output_store_code = cell.querySelector('[class=\"output-store-code\"]');\n",
      "    const status_div = cell.querySelector('#status');\n",
      "    const iteration_div = cell.querySelector('#iteration');\n",
      "    const output_display_llm = cell.querySelector('.output-display-llm');\n",
      "    const output_display_code = cell.querySelector('.output-display-code');\n",
      "\n",
      "\n",
      "    // Turn Off Edit Mode\n",
      "    const toggle_edit = cell.querySelector('.toggle-edit');\n",
      "    toggle_edit.checked = false;\n",
      "\n",
      "    // Prep Data\n",
      "\n",
      "    const prompt = extractCellInput(cellId);\n",
      "    const existingCode = getMonacoContent(cellId);\n",
      "    const hasCode = existingCode && existingCode.trim().length > 0;\n",
      "\n",
      "    const chat_history = gatherCellsForLLM(cellId);\n",
      "\n",
      "    const notebook_name = document.querySelector('.notebook-name')?.value || 'untitled';\n",
      "\n",
      "    const chat_data = {\n",
      "        'prompt': prompt,\n",
      "        'existing_code': hasCode ? existingCode : null,\n",
      "        'context': chat_history  ,\n",
      "        'notebook': notebook_name \n",
      "    };\n",
      "    \n",
      "    setMonacoContent(cellId,'')\n",
      "\n",
      "    let tag;\n",
      "    let iter = 0;\n",
      "    (async () => {\n",
      "    const { fetchEventSource } = await import('https://esm.sh/@microsoft/fetch-event-source@2.0.1');\n",
      "    await fetchEventSource(`/agent_tool_build/${cellId}`, {\n",
      "        method: 'POST',\n",
      "        headers: {'Content-Type': 'application/json'},\n",
      "        body: JSON.stringify(chat_data),\n",
      "        onclose() {\n",
      "        throw new Error('Stream closed');  // Prevents retry\n",
      "        },\n",
      "        onmessage(ev) {\n",
      "\n",
      "\n",
      "            // Try to recieve packet\n",
      "            try{\n",
      "\n",
      "                const packet = JSON.parse(ev.data)\n",
      "                const { type, data } = packet;\n",
      "\n",
      "                //////////////////////\n",
      "                // Set GUI Tags / Labels\n",
      "                //////////////////////\n",
      "                if (type == 'tag')\n",
      "                {\n",
      "                    if ( data.includes('review-box'))\n",
      "                    {\n",
      "                        status_div.textContent = 'Reviewing Unit Test';\n",
      "                        tag = 'llm';\n",
      "                        output_store_llm.textContent = ''\n",
      "                    }\n",
      "                    if (data.includes('code-box' ))\n",
      "                    {\n",
      "                        iter += 1\n",
      "                        iteration_div.textContent = 'Iteration: '+iter.toString();\n",
      "                        \n",
      "                        status_div.classList.remove('complete');\n",
      "                        status_div.classList.add('running');\n",
      "                        status_div.textContent = 'Writing Code';\n",
      "\n",
      "                        // When finished successfully\n",
      "\n",
      "                        tag = 'code';\n",
      "                        setMonacoContent(cellId,'')\n",
      "\n",
      "                    }\n",
      "                    if (data.includes('unit-box' ))\n",
      "                    {\n",
      "                        status_div.textContent = 'Exectuting Unit Test';\n",
      "                        tag = 'unit';\n",
      "                  \n",
      "                    }\n",
      "                    if (data.includes( 'DONE')) \n",
      "                    {\n",
      "                        status_div.classList.remove('running');\n",
      "                        status_div.classList.add('complete');\n",
      "                        status_div.textContent = 'Code Approved!';\n",
      "                        throw new Error('Stream complete');  // Stops retry\n",
      "                    }\n",
      "                    if (data.includes( 'tool-websearch')) \n",
      "                    {\n",
      "                        status_div.classList.remove('complete');\n",
      "                        status_div.classList.add('running');\n",
      "                        status_div.textContent = 'Searching Web';\n",
      "\n",
      "                    }\n",
      "                    if (data.includes( 'tool-readurl')) \n",
      "                    {\n",
      "                        status_div.textContent = 'Checking Website';\n",
      "\n",
      "                    }\n",
      "                }\n",
      "                ///////////////////////\n",
      "                //  Accumulate Stream\n",
      "                ///////////////////////\n",
      "                else if( type == 'text')\n",
      "                {\n",
      "                    // accumulate stream\n",
      "                    if  (tag == 'llm')\n",
      "                    {\n",
      "                        output_store_llm.textContent += data ;\n",
      "                        output_display_llm.scrollTop = output_display_llm.scrollHeight;\n",
      "                    }\n",
      "                    else if  (tag == 'code')\n",
      "                    {\n",
      "                        const code = getMonacoContent(cellId);\n",
      "                        setMonacoContent(cellId,code+data);\n",
      "                    }\n",
      "\n",
      "                }\n",
      "                else if(type == 'output')\n",
      "                {\n",
      "                        // Unit doesnt stream atm so we replace\n",
      "                        output_store_code.textContent = JSON.stringify(data);\n",
      "                        requestAnimationFrame(() => {\n",
      "                            output_display_code.scrollTop = output_display_code.scrollHeight;\n",
      "                        });\n",
      "                }\n",
      "\n",
      "            }\n",
      "            // Print error \n",
      "            catch(error){\n",
      "                if (error.message === 'Stream complete') throw error; \n",
      "\n",
      "                if  (tag == 'llm')\n",
      "                {\n",
      "                    output_store_llm.textContent += error_text ;\n",
      "                }\n",
      "                else if  (tag == 'code')\n",
      "                {\n",
      "                    const code = getMonacoContent(cellId);\n",
      "                    setMonacoContent(cellId,code+error_text);\n",
      "                }\n",
      "                else if  (tag == 'unit')\n",
      "                {\n",
      "                    // Unit doesnt stream atm so we replace\n",
      "                    output_store_code.textContent = JSON.stringify([{\n",
      "                        output_type: 'error',\n",
      "                        ename: 'StreamError',\n",
      "                        evalue: 'Error in stream',\n",
      "                        traceback: [error_text]\n",
      "                    }]);\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        onerror(error) {\n",
      "\n",
      "            throw error;  // Throwing from onerror stops retry\n",
      "\n",
      "        },\n",
      "    });\n",
      "    })();\n",
      "}\n",
      "\"\"\"\n",
      "\n",
      "CODE_CELL_SCRIPT = CELL_SCRIPT + AGENT_SCRIPT\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| notest\n",
    "#| eval: false\n",
    "#| hide\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../unreal_llm_sandbox/')\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "import big_project_helper as bph\n",
    "\n",
    "bph.display_project_contents('unreal_llm_sandbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp main\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768fa881",
   "metadata": {},
   "source": [
    "## Imports & FastHTML App Setup\n",
    "- Imports core modules: json, asyncio, requests, lisette, fasthtml\n",
    "- Imports local modules: config, scripts, cells, streaming, kernel, notebook_io, llm, agent\n",
    "- Sets up DaisyUI headers with Tailwind, Prism, Monaco editor, and marked.js\n",
    "- Initializes FastHTML app with JupyUvi server\n",
    "\n",
    "*Auto-Summary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json\n",
    "import asyncio\n",
    "import requests\n",
    "import lisette\n",
    "import time\n",
    "\n",
    "from fasthtml.common import *\n",
    "from fasthtml.jupyter import JupyUvi\n",
    "from starlette.staticfiles import StaticFiles\n",
    "\n",
    "from unreal_llm_sandbox.app_config import MODEL, KERNEL_URL, NOTEBOOK_SYS_PROMPT\n",
    "from unreal_llm_sandbox.cells import MarkdownCell, CodeCell, PromptCell, AgentCell\n",
    "from unreal_llm_sandbox.streaming import SSEStream, active_streams\n",
    "from unreal_llm_sandbox.kernel import execute_unreal_code, convert_to_accumulated\n",
    "from unreal_llm_sandbox.notebook_io import reconstruct_cells_from_history, prepare_chat_history, reconstruct_ipynb_cell\n",
    "from unreal_llm_sandbox.llm import RemoteToolLLM, send_llm_request\n",
    "from unreal_llm_sandbox.agent import AgentTools, SYS_PROMPT\n",
    "from unreal_llm_sandbox.scripts import CODE_CELL_SCRIPT, HEIGHT_ADJ_SCRIPT, CELL_FOCUS_SCRIPT\n",
    "\n",
    "from fasthtml.common import *\n",
    "import importlib.resources\n",
    "import unreal_llm_sandbox\n",
    "\n",
    "# 1. Helper function to read the text content of your files\n",
    "def get_static(fname):\n",
    "    # This looks inside: unreal_llm_sandbox/static/\n",
    "    ref = importlib.resources.files(unreal_llm_sandbox) / 'static' / fname\n",
    "    return ref.read_text()\n",
    "\n",
    "\n",
    "daisy_hdrs =[\n",
    "Link(href='https://cdn.jsdelivr.net/npm/daisyui@5', rel='stylesheet', type='text/css'),\n",
    "Script(src='https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4'),\n",
    "Link(rel=\"stylesheet\", href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-okaidia.min.css\"),\n",
    "Link(rel=\"stylesheet\", href=\"https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/5.5.1/github-markdown.min.css\"),\n",
    "Script (src ='https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js'),\n",
    "Script (src ='https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js'),\n",
    "Script(src='https://cdn.jsdelivr.net/npm/marked/marked.min.js'),\n",
    "Script(get_static('cells.js')),\n",
    "Script(src=\"https://cdn.jsdelivr.net/npm/ansi_up@5/ansi_up.min.js\"),\n",
    "Script(src=\"https://cdn.jsdelivr.net/npm/monaco-editor@latest/min/vs/loader.js\"),\n",
    "Script(\"\"\"\n",
    "require.config({ paths: { 'vs': 'https://cdn.jsdelivr.net/npm/monaco-editor@latest/min/vs' }});\n",
    "\"\"\"),\n",
    "Script(src=\"https://unpkg.com/htmx.org/dist/ext/sse.js\")]\n",
    "\n",
    "\n",
    "# FastHTML app setup + daisy_hdrs (the big Style/Script list)\n",
    "app = FastHTML(hdrs=daisy_hdrs)\n",
    "#app.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\n",
    "\n",
    "rt = app.route\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4eed96",
   "metadata": {},
   "source": [
    "## Stream Interrupt Route\n",
    "- `POST /interrupt/{cell_id}` - Signals abort for active SSE streams\n",
    "- Uses notebook:cell_id composite key for stream identification\n",
    "\n",
    "*Auto-Summary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c021a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@rt('/interrupt/{cell_id}', methods=['POST'])\n",
    "async def interrupt(cell_id: str, request):\n",
    "    \"\"\"Signal abort for an active stream.\n",
    "    \n",
    "    Args:\n",
    "        cell_id: Unique cell identifier.\n",
    "    \n",
    "    Returns:\n",
    "        \"OK\" acknowledgment string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = await request.json()\n",
    "        notebook = data.get('notebook', 'untitled')\n",
    "    except:\n",
    "        notebook = 'untitled'\n",
    "    stream_key = f\"{notebook}:{cell_id}\"\n",
    "    if stream_key in active_streams:\n",
    "        active_streams[stream_key]['abort'] = True\n",
    "    return \"OK\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d731e",
   "metadata": {},
   "source": [
    "## LLM Prompt Execution Route\n",
    "- `GET /execute_prompt/{cell_id}` - Executes LLM prompts with notebook context\n",
    "- Converts cell history to chat format and streams response via SSE\n",
    "\n",
    "*Auto-Summary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61155ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@rt('/execute_prompt/{cell_id}')\n",
    "async def exe_prompt(cell_id: str, request): \n",
    "    \"\"\"Execute LLM prompt with notebook context via SSE.\n",
    "    \n",
    "    Args:\n",
    "        cell_id: Unique cell identifier.\n",
    "        request: FastHTML request with JSON body containing:\n",
    "            - prompt: User's prompt text.\n",
    "            - context: List of cell dicts for history.\n",
    "    \n",
    "    Returns:\n",
    "        SSE StreamingResponse yielding LLM chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    data = await request.json() \n",
    "\n",
    "    notebook = data.get('notebook', 'untitled')\n",
    "    stream_key = f\"{notebook}:{cell_id}\" \n",
    "\n",
    "    prompt = data['prompt']\n",
    "    cell_dict_list = data.get('context', [])\n",
    "    \n",
    "    cells = reconstruct_cells_from_history(cell_dict_list)\n",
    "    ipynb_list = [cell.to_ipynb() for cell in cells]\n",
    "    chat_history = prepare_chat_history(ipynb_list)\n",
    "    \n",
    "    stream = SSEStream(stream_key)\n",
    "    \n",
    "    def run():\n",
    "        for msg in send_llm_request(prompt, history=chat_history):\n",
    "            if stream.aborted(): break\n",
    "            stream.text(msg)\n",
    "        stream.done()\n",
    "    \n",
    "    asyncio.create_task(asyncio.to_thread(run))\n",
    "    return stream.response()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf469c2b",
   "metadata": {},
   "source": [
    "## Code Execution Route\n",
    "- `GET /execute_code/{cell_id}` - Executes Python code in Unreal Engine kernel\n",
    "- Streams kernel output messages via SSE\n",
    "\n",
    "*Auto-Summary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f016726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@rt('/execute_code/{cell_id}')\n",
    "async def exe_code(cell_id: str, request):\n",
    "    \"\"\"Execute Python code in Unreal Engine via SSE.\n",
    "    \n",
    "    Args:\n",
    "        cell_id: Unique cell identifier.\n",
    "        request: FastHTML request with JSON body containing:\n",
    "            - code: Python code string to execute.\n",
    "    \n",
    "    Returns:\n",
    "        SSE StreamingResponse yielding kernel output messages.\n",
    "    \"\"\"\n",
    "\n",
    "    data = await request.json()\n",
    "    notebook = data.get('notebook', 'untitled')\n",
    "    stream_key = f\"{notebook}:{cell_id}\" \n",
    "\n",
    "    stream = SSEStream(stream_key)\n",
    "    \n",
    "    def run():\n",
    "        response = requests.post(f'{KERNEL_URL}/execute', json={'code': data['code']}, stream=True, timeout=(5, 60))\n",
    "        for line in response.iter_lines():\n",
    "            if stream.aborted(): break\n",
    "            if line.startswith(b'data: '):\n",
    "                stream.output(json.loads(line[6:]))  # ← output() not raw()\n",
    "        stream.done()\n",
    "    \n",
    "    asyncio.create_task(asyncio.to_thread(run))\n",
    "    return stream.response()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294112f3",
   "metadata": {},
   "source": [
    "## Agent Tool Builder Route\n",
    "- `POST /agent_tool_build/{cell_id}` - Runs agentic code generation loop\n",
    "- Supports tool calling, code improvement iterations, and unit testing\n",
    "- Streams progress (tags, text, outputs) via SSE\n",
    "\n",
    "*Auto-Summary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be35b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@rt('/agent_tool_build/{cell_id}', methods=['POST'])\n",
    "async def agent_stream(cell_id: str, request):\n",
    "    \"\"\"Run agent code generation loop with tool calling via SSE.\n",
    "    \n",
    "    Args:\n",
    "        cell_id: Unique cell identifier.\n",
    "        request: FastHTML request with JSON body containing:\n",
    "            - prompt: Code generation request.\n",
    "            - existing_code: Optional code to modify.\n",
    "            - context: List of cell dicts for history.\n",
    "    \n",
    "    Returns:\n",
    "        SSE StreamingResponse yielding agent progress (tags, text, outputs).\n",
    "    \"\"\"\n",
    "    data = await request.json()\n",
    "    notebook = data.get('notebook', 'untitled')\n",
    "    stream_key = f\"{notebook}:{cell_id}\" \n",
    "\n",
    "    stream = SSEStream(stream_key)\n",
    "    def run_chat():\n",
    "        PROMPT = data['prompt']\n",
    "\n",
    "        existing_code = data.get('existing_code')\n",
    "        cell_dict_list = data.get('context', [])  # ← Add this\n",
    "\n",
    "        # Convert to chat history like prompt cells do\n",
    "        cells = reconstruct_cells_from_history(cell_dict_list)\n",
    "        ipynb_list = [cell.to_ipynb() for cell in cells]\n",
    "        chat_history = prepare_chat_history(ipynb_list)\n",
    "\n",
    "        if existing_code:\n",
    "            CODE = existing_code  # Initialize CODE with existing\n",
    "            PROMPT = f\"Modify this code: {existing_code}\\n\\nRequest: {data['prompt']}\"\n",
    "        else:\n",
    "            CODE = \"\"\n",
    "            PROMPT = data['prompt']\n",
    "        \n",
    "\n",
    "        CHAT = lisette.Chat(MODEL, SYS_PROMPT)\n",
    "        CHAT.hist += chat_history\n",
    "        CHAT.hist.append( {\"role\":\"assistant\", \"content\":PROMPT})\n",
    "\n",
    "        a_tools = AgentTools(stream, CHAT, PROMPT,cell_id, code=CODE, print_updates=False)\n",
    "        tools = a_tools.get_tools()\n",
    "        \n",
    "        chat = lisette.Chat(MODEL, SYS_PROMPT, tools=tools)\n",
    "        chat.hist += chat_history\n",
    "\n",
    "\n",
    "        gen = chat(PROMPT, max_steps=15)\n",
    "        for _ in gen:\n",
    "            if stream.aborted():\n",
    "                break\n",
    "        print(\"Chat loop finished!\") \n",
    "        time.sleep(0.1) \n",
    "        stream.done()\n",
    "    \n",
    "    asyncio.create_task(asyncio.to_thread(run_chat))\n",
    "    return stream.response()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866191e",
   "metadata": {},
   "source": [
    "## Styling & Toolbar UI\n",
    "- Defines dark theme CSS styles for markdown body and content areas\n",
    "- `Toolbar()` component with notebook name input and cell type buttons\n",
    "- `GET /add_cell/{cell_type}` - Creates new cells (markdown, code, prompt, agent)\n",
    "\n",
    "*Auto-Summary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d496e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def Toolbar(title):\n",
    "    return Div(\n",
    "\n",
    "        Div(\n",
    "            Input(value=title, cls=\"text-xl font-bold text-white notebook-name bg-transparent border-none outline-none focus:outline-none flex-1\"),\n",
    "            Script(\"\"\"\n",
    "                document.querySelector('.notebook-name').addEventListener('blur', (e) => {\n",
    "                    const name = e.target.value || 'untitled';\n",
    "                    history.replaceState(null, '', `/notebook/${name}.ipynb`);\n",
    "                });\n",
    "            \"\"\"),\n",
    "            cls=\"flex flex-1 items-center\"\n",
    "        ),\n",
    "        Div(\n",
    "            Button(\"➕ Markdown\", \n",
    "                   hx_post=\"/add_cell/markdown\",\n",
    "                   hx_target=\"#notebook-container\",\n",
    "                   hx_swap=\"beforeend\",\n",
    "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"), \n",
    "            Button(\"➕ Code\", \n",
    "                   hx_post=\"/add_cell/code\",\n",
    "                   hx_target=\"#notebook-container\",\n",
    "                   hx_swap=\"beforeend\",\n",
    "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"),  \n",
    "            Button(\"➕ Prompt\", \n",
    "                   hx_post=\"/add_cell/prompt\",\n",
    "                   hx_target=\"#notebook-container\",\n",
    "                   hx_swap=\"beforeend\",\n",
    "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"),  \n",
    "            Button(\"➕ Agent\", \n",
    "                   hx_post=\"/add_cell/agent\",\n",
    "                   hx_target=\"#notebook-container\",\n",
    "                   hx_swap=\"beforeend\",\n",
    "                   cls=\"btn btn-sm bg-gray-700 hover:bg-gray-600 text-white border-gray-600 shadow-none\"), \n",
    "            cls=\"flex gap-2\"\n",
    "        ),\n",
    "        cls=\"flex justify-between p-4 bg-[#0d0d0d]\"  # ← Changed from #0d0d0d to pure black\n",
    "    )\n",
    "\n",
    "@rt('/add_cell/{cell_type}')\n",
    "def add_cell(cell_type: str):\n",
    "    \"\"\"Create and return a new cell of the specified type.\n",
    "    \n",
    "    Args:\n",
    "        cell_type: One of 'markdown', 'code', 'prompt', or 'agent'.\n",
    "        \n",
    "    Returns:\n",
    "        Ren\n",
    "    \"\"\"\n",
    "    if cell_type == 'markdown':\n",
    "        new_cell = MarkdownCell(\"\")\n",
    "    elif cell_type == 'code':\n",
    "        new_cell = CodeCell(\"\")\n",
    "    elif cell_type == 'prompt':\n",
    "        new_cell = PromptCell(\"\")\n",
    "    elif cell_type == 'agent':\n",
    "        new_cell = AgentCell(\"\")\n",
    "    else:\n",
    "        return \"Invalid cell type\"\n",
    "    \n",
    "    return new_cell.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ccf151",
   "metadata": {},
   "source": [
    "## Notebook Load & Save Routes\r\n",
    "- `GET /notebook/{notebook_file}` - Loads .ipynb file and renders cells with toolbar\r\n",
    "- `POST /save_notebook/{notebook_file}` - Saves cells to Jupyter notebook format\r\n",
    "\r\n",
    "*Auto-Summary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@rt('/notebook/{notebook_file}')\n",
    "def load_notebook(notebook_file:str): \n",
    "    \"\"\"Load a Jupyter Notebook file and render its cells.\"\"\"\n",
    "\n",
    "    if not os.path.exists(notebook_file):\n",
    "        rendered_cells = []\n",
    "        print ('Notebook Not Found:',notebook_file)\n",
    "\n",
    "    else:\n",
    "        cells = []\n",
    "        with open(notebook_file, 'r', encoding='utf-8') as f:\n",
    "            notebook = json.load(f)\n",
    "            cells = notebook['cells']\n",
    "        \n",
    "        cell_objects = [reconstruct_ipynb_cell(cell) for cell in cells]\n",
    "        rendered_cells = [cell.render() for cell in cell_objects]\n",
    "\n",
    "\n",
    "    return Title(\"Unreal LLM Sandbox\"),Body(\n",
    "        Toolbar(notebook_file.split('.ipynb')[0]),\n",
    "        Style(get_static('styles.css')),\n",
    "        Div(  *rendered_cells,\n",
    "            cls='px-5',  \n",
    "            id='notebook-container' \n",
    "        )\n",
    "    )\n",
    "\n",
    "@rt('/save_notebook/{notebook_file}', methods=['POST'])\n",
    "async def save_notebook(notebook_file: str, request):\n",
    "    \"\"\"Save notebook cells to a Jupyter .ipynb file.\n",
    "    \n",
    "    Args:\n",
    "        notebook_file: Filename to save to.\n",
    "        request: Request with JSON body containing 'cells' list.\n",
    "    \n",
    "    Returns:\n",
    "        JSON with status message.\n",
    "    \"\"\"\n",
    "    data = await request.json()\n",
    "    cell_dict_list = data.get('cells', [])\n",
    "    \n",
    "    # Reconstruct cell objects and convert to ipynb format\n",
    "    cells = reconstruct_cells_from_history(cell_dict_list)\n",
    "    ipynb_cells = [cell.to_ipynb() for cell in cells]\n",
    "    \n",
    "    # Build notebook structure\n",
    "    notebook = {\n",
    "        \"nbformat\": 4,\n",
    "        \"nbformat_minor\": 5,\n",
    "        \"metadata\": {\n",
    "            \"kernelspec\": {\n",
    "                \"display_name\": \"Python 3\",\n",
    "                \"language\": \"python\",\n",
    "                \"name\": \"python3\"\n",
    "            }\n",
    "        },\n",
    "        \"cells\": ipynb_cells\n",
    "    }\n",
    "    \n",
    "    with open(notebook_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(notebook, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    return {\"status\": \"saved\", \"file\": notebook_file}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184db627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import uvicorn\n",
    "\n",
    "def start_server():\n",
    "    uvicorn.run(app, host='0.0.0.0', port=5001)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b008b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m",
      "\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#| eval: false\u001b[39;00m",
      "\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:",
      "\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mstart_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m",
      "",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mstart_server\u001b[39m\u001b[34m()\u001b[39m",
      "\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart_server\u001b[39m():",
      "\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43muvicorn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m0.0.0.0\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5001\u001b[39;49m\u001b[43m)\u001b[49m",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/uvicorn/main.py:594\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, timeout_worker_healthcheck, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[39m",
      "\u001b[32m    592\u001b[39m         Multiprocess(config, target=server.run, sockets=[sock]).run()",
      "\u001b[32m    593\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:",
      "\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m         \u001b[43mserver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m",
      "\u001b[32m    595\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:",
      "\u001b[32m    596\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# pragma: full coverage\u001b[39;00m",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/uvicorn/server.py:67\u001b[39m, in \u001b[36mServer.run\u001b[39m\u001b[34m(self, sockets)\u001b[39m",
      "\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket.socket] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:",
      "\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[43m=\u001b[49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loop_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m",
      "",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/asyncio/runners.py:191\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m",
      "\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m",
      "\u001b[32m    162\u001b[39m ",
      "\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m",
      "\u001b[32m    188\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m",
      "\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:",
      "\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m",
      "\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(",
      "\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)",
      "\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:",
      "\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)",
      "",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "#| eval: false\r\n",
    "if __name__ == \"__main__\":\r\n",
    "    start_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad491efc",
   "metadata": {},
   "source": [
    "# For Notebook Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\r\n",
    "from fasthtml.jupyter import JupyUvi\r\n",
    "server = JupyUvi(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31226d7f",
   "metadata": {},
   "source": [
    "# Reflect\n",
    "- How does this relate to the larger project? List the other components and how they communicate with this one. \n",
    "- What improvements do you see that can obviously be made here? \n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "🧠🧠🧠🧠🧠🧠🧠🧠🧠\n",
    "\n",
    "## How This Relates to the Larger Project\n",
    "\n",
    "This is a **Jupyter-like notebook web app** that connects to an **Unreal Engine 5.6** Python kernel. The components:\n",
    "\n",
    "| Component | Role | Communication |\n",
    "|-----------|------|---------------|\n",
    "| `main.py` (FastHTML routes) | Web server, SSE streaming | HTTP/SSE to browser, HTTP to Unreal kernel |\n",
    "| `cells.py` | Cell rendering (Markdown, Code, Prompt, Agent) | Generates HTML for frontend |\n",
    "| `kernel.py` | Unreal Engine bridge | HTTP POST to `KERNEL_URL` for code execution |\n",
    "| `agent.py` | Agentic code generation loop | Uses `lisette` for tool-calling LLM |\n",
    "| `llm.py` | LLM chat with tool execution | LiteLLM + remote tool calls to Unreal |\n",
    "| `streaming.py` | SSE queue management | Async queue → StreamingResponse |\n",
    "| `notebook_io.py` | ipynb ↔ cell conversion | JSON parsing/serialization |\n",
    "| `scripts.py` | Frontend JavaScript | Handles Monaco, cell execution, SSE consumption |\n",
    "\n",
    "## Obvious Improvements\n",
    "\n",
    "1. **Error handling** - Many `try/except` blocks swallow errors silently or use bare `except:`\n",
    "2. **Hardcoded `MODEL = 'gpt-5.2'`** - Should be configurable/validated\n",
    "3. **No authentication** - Anyone can execute code on the Unreal kernel\n",
    "4. **Duplicate code** - `RemoteToolLLM` and `AgentTools` both implement tool execution\n",
    "5. **Magic strings** - Separators like `PROMPT_SPLIT` are fragile; could use structured metadata\n",
    "6. **JavaScript in Python strings** - `scripts.py` is hard to maintain; could be separate `.js` files\n",
    "7. **No rate limiting** on kernel execution or LLM calls\n",
    "\n",
    "Which area would you like to explore further?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e09d37e",
   "metadata": {},
   "source": [
    "# Consolidating CSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(\"static\").mkdir(exist_ok=True)\n",
    "\n",
    "css = \"\"\"\n",
    ".markdown-body { \n",
    "    background-color: bg-gray-900 !important; \n",
    "}\n",
    ".markdown-body ul { \n",
    "    list-style-type: disc !important; \n",
    "    padding-left: 2em !important; \n",
    "}\n",
    ".markdown-body ol { \n",
    "    list-style-type: decimal !important; \n",
    "    padding-left: 2em !important; \n",
    "}\n",
    "[data-cell-id].minimized .output-display-llm,\n",
    "[data-cell-id].minimized .output-display-code {\n",
    "    display: none !important;\n",
    "}\n",
    "[data-cell-id].minimized .content-edit,\n",
    "[data-cell-id].minimized .content-render,\n",
    "[data-cell-id].minimized .output-display,\n",
    "[data-cell-id].minimized .text-gray-400 {\n",
    "    display: none;\n",
    "}\n",
    "[data-cell-id].minimized .content-edit,\n",
    "[data-cell-id].minimized .content-render {\n",
    "    display: none !important;\n",
    "}\n",
    "[data-cell-id].minimized .monaco-editor,\n",
    "[data-cell-id].minimized .content-edit,\n",
    "[data-cell-id].minimized .content-render,\n",
    "[data-cell-id].minimized .output-display {\n",
    "    max-height: 0 !important;\n",
    "    overflow: hidden;\n",
    "}\n",
    "[data-cell-id].minimized .bg-gray-800 {\n",
    "    opacity: 0.5 !important;\n",
    "}\n",
    "body {\n",
    "    background-color: #070707 !important;  /* 95% black = 5% brightness */\n",
    "}\n",
    ".markdown-body { \n",
    "    background-color: bg-gray-900 !important;\n",
    "    font-size: 0.825rem !important;  /* ← Smaller base size */\n",
    "}\n",
    ".markdown-body h1 { font-size: 1.25rem !important; }\n",
    ".markdown-body h2 { font-size: 1.1rem !important; }\n",
    ".markdown-body h3 { font-size: 1.0rem !important; }\n",
    ".markdown-body ul, .markdown-body ol { \n",
    "    list-style-type: disc !important; \n",
    "    padding-left: 2em !important;\n",
    "    font-size: 0.825rem !important;  /* ← Match body */\n",
    "}\n",
    ".content-edit {\n",
    "    font-size: 0.825rem !important;  /* ← Textarea size */\n",
    "}\n",
    "\n",
    ".content-render {\n",
    "    background-color: #1a1a1a  !important;  /* ← Medium grey for rendered input */\n",
    "}\n",
    ".running { color: #ef4444 !important; }\n",
    ".complete { color: #22c55e !important; }\n",
    "#notebook-container {\n",
    "    height: calc(100vh - 64px); \n",
    "    overflow-y: auto;\n",
    ".toggle-edit:checked ~ .content-edit { display: block; }\n",
    ".toggle-edit:checked ~ .content-render { display: none; }\n",
    ".toggle-edit:not(:checked) ~ .content-edit { display: none; }\n",
    ".toggle-edit:not(:checked) ~ .content-render { display: block; }\n",
    "\"\"\"\n",
    "\n",
    "Path(\"static/styles.css\").write_text(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c2127",
   "metadata": {},
   "source": [
    "# Consolidating JS"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
